Training: Epoch[001/040] Iteration[010/381] Loss: 6.6225 Acc:0.31%
Training: Epoch[001/040] Iteration[020/381] Loss: 6.6204 Acc:0.16%
Training: Epoch[001/040] Iteration[030/381] Loss: 6.6136 Acc:0.73%
Training: Epoch[001/040] Iteration[040/381] Loss: 6.6120 Acc:0.70%
Training: Epoch[001/040] Iteration[050/381] Loss: 6.6090 Acc:0.88%
Training: Epoch[001/040] Iteration[060/381] Loss: 6.6014 Acc:0.99%
Training: Epoch[001/040] Iteration[070/381] Loss: 6.5954 Acc:1.12%
Training: Epoch[001/040] Iteration[080/381] Loss: 6.5941 Acc:1.33%
Training: Epoch[001/040] Iteration[090/381] Loss: 6.5906 Acc:1.46%
Training: Epoch[001/040] Iteration[100/381] Loss: 6.5856 Acc:1.62%
Training: Epoch[001/040] Iteration[110/381] Loss: 6.5814 Acc:1.76%
Training: Epoch[001/040] Iteration[120/381] Loss: 6.5733 Acc:2.14%
Training: Epoch[001/040] Iteration[130/381] Loss: 6.5726 Acc:2.45%
Training: Epoch[001/040] Iteration[140/381] Loss: 6.5563 Acc:2.92%
Training: Epoch[001/040] Iteration[150/381] Loss: 6.5606 Acc:3.08%
Training: Epoch[001/040] Iteration[160/381] Loss: 6.5520 Acc:3.34%
Training: Epoch[001/040] Iteration[170/381] Loss: 6.5581 Acc:3.42%
Training: Epoch[001/040] Iteration[180/381] Loss: 6.5327 Acc:3.65%
Training: Epoch[001/040] Iteration[190/381] Loss: 6.5381 Acc:3.82%
Training: Epoch[001/040] Iteration[200/381] Loss: 6.5329 Acc:4.03%
Training: Epoch[001/040] Iteration[210/381] Loss: 6.5279 Acc:4.23%
Training: Epoch[001/040] Iteration[220/381] Loss: 6.5266 Acc:4.33%
Training: Epoch[001/040] Iteration[230/381] Loss: 6.5099 Acc:4.50%
Training: Epoch[001/040] Iteration[240/381] Loss: 6.5142 Acc:4.62%
Training: Epoch[001/040] Iteration[250/381] Loss: 6.4954 Acc:4.90%
Training: Epoch[001/040] Iteration[260/381] Loss: 6.4922 Acc:5.08%
Training: Epoch[001/040] Iteration[270/381] Loss: 6.4921 Acc:5.10%
Training: Epoch[001/040] Iteration[280/381] Loss: 6.4810 Acc:5.27%
Training: Epoch[001/040] Iteration[290/381] Loss: 6.4828 Acc:5.32%
Training: Epoch[001/040] Iteration[300/381] Loss: 6.4642 Acc:5.51%
Training: Epoch[001/040] Iteration[310/381] Loss: 6.4597 Acc:5.60%
Training: Epoch[001/040] Iteration[320/381] Loss: 6.4464 Acc:5.77%
Training: Epoch[001/040] Iteration[330/381] Loss: 6.4407 Acc:5.98%
Training: Epoch[001/040] Iteration[340/381] Loss: 6.4089 Acc:6.23%
Training: Epoch[001/040] Iteration[350/381] Loss: 6.4122 Acc:6.37%
Training: Epoch[001/040] Iteration[360/381] Loss: 6.4058 Acc:6.44%
Training: Epoch[001/040] Iteration[370/381] Loss: 6.4000 Acc:6.55%
Training: Epoch[001/040] Iteration[380/381] Loss: 6.3692 Acc:6.65%
Valid set Accuracy:5.19%
Training: Epoch[002/040] Iteration[010/381] Loss: 6.2807 Acc:9.69%
Training: Epoch[002/040] Iteration[020/381] Loss: 6.0139 Acc:7.50%
Training: Epoch[002/040] Iteration[030/381] Loss: 5.5204 Acc:6.67%
Training: Epoch[002/040] Iteration[040/381] Loss: 5.1433 Acc:7.42%
Training: Epoch[002/040] Iteration[050/381] Loss: 4.8169 Acc:8.62%
Training: Epoch[002/040] Iteration[060/381] Loss: 4.5357 Acc:9.84%
Training: Epoch[002/040] Iteration[070/381] Loss: 4.3595 Acc:10.80%
Training: Epoch[002/040] Iteration[080/381] Loss: 4.1056 Acc:11.95%
Training: Epoch[002/040] Iteration[090/381] Loss: 4.0337 Acc:12.81%
Training: Epoch[002/040] Iteration[100/381] Loss: 3.9519 Acc:14.03%
Training: Epoch[002/040] Iteration[110/381] Loss: 3.6473 Acc:15.28%
Training: Epoch[002/040] Iteration[120/381] Loss: 3.6729 Acc:16.35%
Training: Epoch[002/040] Iteration[130/381] Loss: 3.3591 Acc:17.72%
Training: Epoch[002/040] Iteration[140/381] Loss: 2.9038 Acc:19.31%
Training: Epoch[002/040] Iteration[150/381] Loss: 2.8144 Acc:20.58%
Training: Epoch[002/040] Iteration[160/381] Loss: 3.3143 Acc:21.31%
Training: Epoch[002/040] Iteration[170/381] Loss: 2.9349 Acc:22.26%
Training: Epoch[002/040] Iteration[180/381] Loss: 2.5340 Acc:23.58%
Training: Epoch[002/040] Iteration[190/381] Loss: 2.7496 Acc:24.56%
Training: Epoch[002/040] Iteration[200/381] Loss: 2.6110 Acc:25.55%
Training: Epoch[002/040] Iteration[210/381] Loss: 2.5589 Acc:26.38%
Training: Epoch[002/040] Iteration[220/381] Loss: 2.4248 Acc:27.24%
Training: Epoch[002/040] Iteration[230/381] Loss: 2.2601 Acc:28.22%
Training: Epoch[002/040] Iteration[240/381] Loss: 2.2224 Acc:29.24%
Training: Epoch[002/040] Iteration[250/381] Loss: 1.9724 Acc:30.28%
Training: Epoch[002/040] Iteration[260/381] Loss: 2.1996 Acc:31.06%
Training: Epoch[002/040] Iteration[270/381] Loss: 2.0721 Acc:31.82%
Training: Epoch[002/040] Iteration[280/381] Loss: 1.9576 Acc:32.61%
Training: Epoch[002/040] Iteration[290/381] Loss: 1.6991 Acc:33.60%
Training: Epoch[002/040] Iteration[300/381] Loss: 1.8965 Acc:34.28%
Training: Epoch[002/040] Iteration[310/381] Loss: 1.8356 Acc:35.12%
Training: Epoch[002/040] Iteration[320/381] Loss: 1.8688 Acc:35.69%
Training: Epoch[002/040] Iteration[330/381] Loss: 1.6493 Acc:36.42%
Training: Epoch[002/040] Iteration[340/381] Loss: 1.6065 Acc:37.14%
Training: Epoch[002/040] Iteration[350/381] Loss: 1.8143 Acc:37.69%
Training: Epoch[002/040] Iteration[360/381] Loss: 1.6232 Acc:38.29%
Training: Epoch[002/040] Iteration[370/381] Loss: 1.3667 Acc:39.06%
Training: Epoch[002/040] Iteration[380/381] Loss: 1.5609 Acc:39.64%
Training: Epoch[003/040] Iteration[010/381] Loss: 1.0540 Acc:71.88%
Training: Epoch[003/040] Iteration[020/381] Loss: 1.1019 Acc:72.19%
Training: Epoch[003/040] Iteration[030/381] Loss: 1.1568 Acc:71.35%
Training: Epoch[003/040] Iteration[040/381] Loss: 0.9927 Acc:71.72%
Training: Epoch[003/040] Iteration[050/381] Loss: 1.1558 Acc:71.19%
Training: Epoch[003/040] Iteration[060/381] Loss: 0.9668 Acc:71.93%
Training: Epoch[003/040] Iteration[070/381] Loss: 1.0271 Acc:72.10%
Training: Epoch[003/040] Iteration[080/381] Loss: 0.9860 Acc:72.85%
Training: Epoch[003/040] Iteration[090/381] Loss: 1.0178 Acc:72.81%
Training: Epoch[003/040] Iteration[100/381] Loss: 0.8573 Acc:73.19%
Training: Epoch[003/040] Iteration[110/381] Loss: 1.0522 Acc:73.41%
Training: Epoch[003/040] Iteration[120/381] Loss: 1.1923 Acc:72.89%
Training: Epoch[003/040] Iteration[130/381] Loss: 1.1040 Acc:72.91%
Training: Epoch[003/040] Iteration[140/381] Loss: 0.9454 Acc:73.10%
Training: Epoch[003/040] Iteration[150/381] Loss: 1.0923 Acc:72.96%
Training: Epoch[003/040] Iteration[160/381] Loss: 0.7581 Acc:73.50%
Training: Epoch[003/040] Iteration[170/381] Loss: 0.9087 Acc:73.64%
Training: Epoch[003/040] Iteration[180/381] Loss: 0.9661 Acc:73.77%
Training: Epoch[003/040] Iteration[190/381] Loss: 0.9765 Acc:73.83%
Training: Epoch[003/040] Iteration[200/381] Loss: 0.9159 Acc:73.94%
Training: Epoch[003/040] Iteration[210/381] Loss: 0.8954 Acc:74.06%
Training: Epoch[003/040] Iteration[220/381] Loss: 0.8481 Acc:74.29%
Training: Epoch[003/040] Iteration[230/381] Loss: 0.8525 Acc:74.44%
Training: Epoch[003/040] Iteration[240/381] Loss: 0.9051 Acc:74.52%
Training: Epoch[003/040] Iteration[250/381] Loss: 0.9470 Acc:74.45%
Training: Epoch[003/040] Iteration[260/381] Loss: 0.7525 Acc:74.63%
Training: Epoch[003/040] Iteration[270/381] Loss: 0.7485 Acc:74.77%
Training: Epoch[003/040] Iteration[280/381] Loss: 0.7537 Acc:74.99%
Training: Epoch[003/040] Iteration[290/381] Loss: 0.9068 Acc:75.08%
Training: Epoch[003/040] Iteration[300/381] Loss: 0.6369 Acc:75.34%
Training: Epoch[003/040] Iteration[310/381] Loss: 0.8149 Acc:75.38%
Training: Epoch[003/040] Iteration[320/381] Loss: 0.7865 Acc:75.50%
Training: Epoch[003/040] Iteration[330/381] Loss: 0.6937 Acc:75.58%
Training: Epoch[003/040] Iteration[340/381] Loss: 0.5659 Acc:75.84%
Training: Epoch[003/040] Iteration[350/381] Loss: 0.7010 Acc:75.91%
Training: Epoch[003/040] Iteration[360/381] Loss: 0.8198 Acc:75.98%
Training: Epoch[003/040] Iteration[370/381] Loss: 0.7050 Acc:76.11%
Training: Epoch[003/040] Iteration[380/381] Loss: 0.7791 Acc:76.28%
Valid set Accuracy:67.11%
Training: Epoch[004/040] Iteration[010/381] Loss: 0.4552 Acc:85.94%
Training: Epoch[004/040] Iteration[020/381] Loss: 0.5514 Acc:84.53%
Training: Epoch[004/040] Iteration[030/381] Loss: 0.5228 Acc:85.62%
Training: Epoch[004/040] Iteration[040/381] Loss: 0.4517 Acc:86.17%
Training: Epoch[004/040] Iteration[050/381] Loss: 0.4461 Acc:86.44%
Training: Epoch[004/040] Iteration[060/381] Loss: 0.4145 Acc:86.46%
Training: Epoch[004/040] Iteration[070/381] Loss: 0.4213 Acc:86.61%
Training: Epoch[004/040] Iteration[080/381] Loss: 0.5220 Acc:86.56%
Training: Epoch[004/040] Iteration[090/381] Loss: 0.4210 Acc:86.74%
Training: Epoch[004/040] Iteration[100/381] Loss: 0.5589 Acc:86.44%
Training: Epoch[004/040] Iteration[110/381] Loss: 0.4452 Acc:86.65%
Training: Epoch[004/040] Iteration[120/381] Loss: 0.4738 Acc:86.90%
Training: Epoch[004/040] Iteration[130/381] Loss: 0.5237 Acc:86.73%
Training: Epoch[004/040] Iteration[140/381] Loss: 0.4624 Acc:86.81%
Training: Epoch[004/040] Iteration[150/381] Loss: 0.4368 Acc:86.88%
Training: Epoch[004/040] Iteration[160/381] Loss: 0.4092 Acc:87.09%
Training: Epoch[004/040] Iteration[170/381] Loss: 0.5389 Acc:87.10%
Training: Epoch[004/040] Iteration[180/381] Loss: 0.3589 Acc:87.26%
Training: Epoch[004/040] Iteration[190/381] Loss: 0.3857 Acc:87.35%
Training: Epoch[004/040] Iteration[200/381] Loss: 0.4328 Acc:87.33%
Training: Epoch[004/040] Iteration[210/381] Loss: 0.6279 Acc:87.17%
Training: Epoch[004/040] Iteration[220/381] Loss: 0.4791 Acc:87.22%
Training: Epoch[004/040] Iteration[230/381] Loss: 0.5795 Acc:87.12%
Training: Epoch[004/040] Iteration[240/381] Loss: 0.4103 Acc:87.17%
Training: Epoch[004/040] Iteration[250/381] Loss: 0.4053 Acc:87.21%
Training: Epoch[004/040] Iteration[260/381] Loss: 0.4220 Acc:87.25%
Training: Epoch[004/040] Iteration[270/381] Loss: 0.4272 Acc:87.30%
Training: Epoch[004/040] Iteration[280/381] Loss: 0.4870 Acc:87.23%
Training: Epoch[004/040] Iteration[290/381] Loss: 0.4154 Acc:87.25%
Training: Epoch[004/040] Iteration[300/381] Loss: 0.4659 Acc:87.22%
Training: Epoch[004/040] Iteration[310/381] Loss: 0.3272 Acc:87.30%
Training: Epoch[004/040] Iteration[320/381] Loss: 0.4910 Acc:87.24%
Training: Epoch[004/040] Iteration[330/381] Loss: 0.4179 Acc:87.25%
Training: Epoch[004/040] Iteration[340/381] Loss: 0.4191 Acc:87.24%
Training: Epoch[004/040] Iteration[350/381] Loss: 0.4154 Acc:87.30%
Training: Epoch[004/040] Iteration[360/381] Loss: 0.3491 Acc:87.39%
Training: Epoch[004/040] Iteration[370/381] Loss: 0.4215 Acc:87.35%
Training: Epoch[004/040] Iteration[380/381] Loss: 0.4819 Acc:87.34%
Training: Epoch[005/040] Iteration[010/381] Loss: 0.2509 Acc:91.88%
Training: Epoch[005/040] Iteration[020/381] Loss: 0.2421 Acc:91.72%
Training: Epoch[005/040] Iteration[030/381] Loss: 0.2435 Acc:91.98%
Training: Epoch[005/040] Iteration[040/381] Loss: 0.3597 Acc:91.56%
Training: Epoch[005/040] Iteration[050/381] Loss: 0.3100 Acc:91.31%
Training: Epoch[005/040] Iteration[060/381] Loss: 0.4034 Acc:91.04%
Training: Epoch[005/040] Iteration[070/381] Loss: 0.2157 Acc:91.56%
Training: Epoch[005/040] Iteration[080/381] Loss: 0.3018 Acc:91.48%
Training: Epoch[005/040] Iteration[090/381] Loss: 0.2046 Acc:91.67%
Training: Epoch[005/040] Iteration[100/381] Loss: 0.2623 Acc:91.81%
Training: Epoch[005/040] Iteration[110/381] Loss: 0.2806 Acc:91.76%
Training: Epoch[005/040] Iteration[120/381] Loss: 0.2647 Acc:91.77%
Training: Epoch[005/040] Iteration[130/381] Loss: 0.3421 Acc:91.63%
Training: Epoch[005/040] Iteration[140/381] Loss: 0.2997 Acc:91.67%
Training: Epoch[005/040] Iteration[150/381] Loss: 0.1959 Acc:91.85%
Training: Epoch[005/040] Iteration[160/381] Loss: 0.2990 Acc:91.82%
Training: Epoch[005/040] Iteration[170/381] Loss: 0.2368 Acc:91.89%
Training: Epoch[005/040] Iteration[180/381] Loss: 0.2816 Acc:91.91%
Training: Epoch[005/040] Iteration[190/381] Loss: 0.2842 Acc:91.86%
Training: Epoch[005/040] Iteration[200/381] Loss: 0.2678 Acc:91.89%
Training: Epoch[005/040] Iteration[210/381] Loss: 0.2704 Acc:91.77%
Training: Epoch[005/040] Iteration[220/381] Loss: 0.1983 Acc:91.90%
Training: Epoch[005/040] Iteration[230/381] Loss: 0.2359 Acc:91.92%
Training: Epoch[005/040] Iteration[240/381] Loss: 0.4090 Acc:91.84%
Training: Epoch[005/040] Iteration[250/381] Loss: 0.3124 Acc:91.84%
Training: Epoch[005/040] Iteration[260/381] Loss: 0.3344 Acc:91.75%
Training: Epoch[005/040] Iteration[270/381] Loss: 0.2884 Acc:91.72%
Training: Epoch[005/040] Iteration[280/381] Loss: 0.2674 Acc:91.75%
Training: Epoch[005/040] Iteration[290/381] Loss: 0.2750 Acc:91.78%
Training: Epoch[005/040] Iteration[300/381] Loss: 0.2437 Acc:91.79%
Training: Epoch[005/040] Iteration[310/381] Loss: 0.2003 Acc:91.90%
Training: Epoch[005/040] Iteration[320/381] Loss: 0.2134 Acc:91.97%
Training: Epoch[005/040] Iteration[330/381] Loss: 0.2362 Acc:91.98%
Training: Epoch[005/040] Iteration[340/381] Loss: 0.2224 Acc:92.03%
Training: Epoch[005/040] Iteration[350/381] Loss: 0.3045 Acc:92.04%
Training: Epoch[005/040] Iteration[360/381] Loss: 0.3236 Acc:92.05%
Training: Epoch[005/040] Iteration[370/381] Loss: 0.2391 Acc:92.09%
Training: Epoch[005/040] Iteration[380/381] Loss: 0.2672 Acc:92.15%
Valid set Accuracy:80.16%
Training: Epoch[006/040] Iteration[010/381] Loss: 0.1952 Acc:94.38%
Training: Epoch[006/040] Iteration[020/381] Loss: 0.2654 Acc:93.59%
Training: Epoch[006/040] Iteration[030/381] Loss: 0.1575 Acc:94.48%
Training: Epoch[006/040] Iteration[040/381] Loss: 0.1141 Acc:94.92%
Training: Epoch[006/040] Iteration[050/381] Loss: 0.1110 Acc:95.44%
Training: Epoch[006/040] Iteration[060/381] Loss: 0.1481 Acc:95.36%
Training: Epoch[006/040] Iteration[070/381] Loss: 0.1147 Acc:95.49%
Training: Epoch[006/040] Iteration[080/381] Loss: 0.1531 Acc:95.43%
Training: Epoch[006/040] Iteration[090/381] Loss: 0.1137 Acc:95.62%
Training: Epoch[006/040] Iteration[100/381] Loss: 0.1248 Acc:95.59%
Training: Epoch[006/040] Iteration[110/381] Loss: 0.1263 Acc:95.62%
Training: Epoch[006/040] Iteration[120/381] Loss: 0.1619 Acc:95.65%
Training: Epoch[006/040] Iteration[130/381] Loss: 0.1335 Acc:95.62%
Training: Epoch[006/040] Iteration[140/381] Loss: 0.1525 Acc:95.60%
Training: Epoch[006/040] Iteration[150/381] Loss: 0.0870 Acc:95.67%
Training: Epoch[006/040] Iteration[160/381] Loss: 0.1405 Acc:95.68%
Training: Epoch[006/040] Iteration[170/381] Loss: 0.1421 Acc:95.72%
Training: Epoch[006/040] Iteration[180/381] Loss: 0.1863 Acc:95.66%
Training: Epoch[006/040] Iteration[190/381] Loss: 0.1521 Acc:95.67%
Training: Epoch[006/040] Iteration[200/381] Loss: 0.1309 Acc:95.64%
Training: Epoch[006/040] Iteration[210/381] Loss: 0.2106 Acc:95.52%
Training: Epoch[006/040] Iteration[220/381] Loss: 0.1209 Acc:95.53%
Training: Epoch[006/040] Iteration[230/381] Loss: 0.1513 Acc:95.50%
Training: Epoch[006/040] Iteration[240/381] Loss: 0.2239 Acc:95.44%
Training: Epoch[006/040] Iteration[250/381] Loss: 0.2080 Acc:95.40%
Training: Epoch[006/040] Iteration[260/381] Loss: 0.2518 Acc:95.37%
Training: Epoch[006/040] Iteration[270/381] Loss: 0.1581 Acc:95.43%
Training: Epoch[006/040] Iteration[280/381] Loss: 0.2008 Acc:95.38%
Training: Epoch[006/040] Iteration[290/381] Loss: 0.1664 Acc:95.33%
Training: Epoch[006/040] Iteration[300/381] Loss: 0.2170 Acc:95.29%
Training: Epoch[006/040] Iteration[310/381] Loss: 0.2303 Acc:95.22%
Training: Epoch[006/040] Iteration[320/381] Loss: 0.2916 Acc:95.10%
Training: Epoch[006/040] Iteration[330/381] Loss: 0.1592 Acc:95.08%
Training: Epoch[006/040] Iteration[340/381] Loss: 0.2533 Acc:94.98%
Training: Epoch[006/040] Iteration[350/381] Loss: 0.1522 Acc:94.99%
Training: Epoch[006/040] Iteration[360/381] Loss: 0.1437 Acc:95.00%
Training: Epoch[006/040] Iteration[370/381] Loss: 0.1252 Acc:95.03%
Training: Epoch[006/040] Iteration[380/381] Loss: 0.2158 Acc:95.00%
Training: Epoch[007/040] Iteration[010/381] Loss: 0.1106 Acc:97.19%
Training: Epoch[007/040] Iteration[020/381] Loss: 0.1299 Acc:96.56%
Training: Epoch[007/040] Iteration[030/381] Loss: 0.1568 Acc:96.56%
Training: Epoch[007/040] Iteration[040/381] Loss: 0.1010 Acc:96.88%
Training: Epoch[007/040] Iteration[050/381] Loss: 0.1024 Acc:97.00%
Training: Epoch[007/040] Iteration[060/381] Loss: 0.1749 Acc:96.72%
Training: Epoch[007/040] Iteration[070/381] Loss: 0.1048 Acc:96.83%
Training: Epoch[007/040] Iteration[080/381] Loss: 0.0929 Acc:96.88%
Training: Epoch[007/040] Iteration[090/381] Loss: 0.0826 Acc:96.88%
Training: Epoch[007/040] Iteration[100/381] Loss: 0.1680 Acc:96.66%
Training: Epoch[007/040] Iteration[110/381] Loss: 0.1077 Acc:96.70%
Training: Epoch[007/040] Iteration[120/381] Loss: 0.0830 Acc:96.69%
Training: Epoch[007/040] Iteration[130/381] Loss: 0.0633 Acc:96.78%
Training: Epoch[007/040] Iteration[140/381] Loss: 0.1112 Acc:96.79%
Training: Epoch[007/040] Iteration[150/381] Loss: 0.0647 Acc:96.85%
Training: Epoch[007/040] Iteration[160/381] Loss: 0.1490 Acc:96.80%
Training: Epoch[007/040] Iteration[170/381] Loss: 0.1217 Acc:96.80%
Training: Epoch[007/040] Iteration[180/381] Loss: 0.1361 Acc:96.72%
Training: Epoch[007/040] Iteration[190/381] Loss: 0.1391 Acc:96.71%
Training: Epoch[007/040] Iteration[200/381] Loss: 0.0773 Acc:96.77%
Training: Epoch[007/040] Iteration[210/381] Loss: 0.1217 Acc:96.77%
Training: Epoch[007/040] Iteration[220/381] Loss: 0.1127 Acc:96.72%
Training: Epoch[007/040] Iteration[230/381] Loss: 0.0809 Acc:96.71%
Training: Epoch[007/040] Iteration[240/381] Loss: 0.1138 Acc:96.68%
Training: Epoch[007/040] Iteration[250/381] Loss: 0.1341 Acc:96.65%
Training: Epoch[007/040] Iteration[260/381] Loss: 0.1178 Acc:96.63%
Training: Epoch[007/040] Iteration[270/381] Loss: 0.1209 Acc:96.61%
Training: Epoch[007/040] Iteration[280/381] Loss: 0.0751 Acc:96.64%
Training: Epoch[007/040] Iteration[290/381] Loss: 0.1009 Acc:96.66%
Training: Epoch[007/040] Iteration[300/381] Loss: 0.1340 Acc:96.64%
Training: Epoch[007/040] Iteration[310/381] Loss: 0.1236 Acc:96.59%
Training: Epoch[007/040] Iteration[320/381] Loss: 0.1131 Acc:96.57%
Training: Epoch[007/040] Iteration[330/381] Loss: 0.1406 Acc:96.59%
Training: Epoch[007/040] Iteration[340/381] Loss: 0.1834 Acc:96.53%
Training: Epoch[007/040] Iteration[350/381] Loss: 0.1848 Acc:96.49%
Training: Epoch[007/040] Iteration[360/381] Loss: 0.1042 Acc:96.53%
Training: Epoch[007/040] Iteration[370/381] Loss: 0.1310 Acc:96.55%
Training: Epoch[007/040] Iteration[380/381] Loss: 0.0433 Acc:96.60%
Valid set Accuracy:82.29%
Training: Epoch[008/040] Iteration[010/381] Loss: 0.0930 Acc:97.81%
Training: Epoch[008/040] Iteration[020/381] Loss: 0.0866 Acc:97.81%
Training: Epoch[008/040] Iteration[030/381] Loss: 0.1082 Acc:97.50%
Training: Epoch[008/040] Iteration[040/381] Loss: 0.1036 Acc:97.27%
Training: Epoch[008/040] Iteration[050/381] Loss: 0.0856 Acc:97.31%
Training: Epoch[008/040] Iteration[060/381] Loss: 0.0426 Acc:97.55%
Training: Epoch[008/040] Iteration[070/381] Loss: 0.1043 Acc:97.46%
Training: Epoch[008/040] Iteration[080/381] Loss: 0.1538 Acc:97.27%
Training: Epoch[008/040] Iteration[090/381] Loss: 0.1226 Acc:97.15%
Training: Epoch[008/040] Iteration[100/381] Loss: 0.1525 Acc:97.03%
Training: Epoch[008/040] Iteration[110/381] Loss: 0.0698 Acc:97.13%
Training: Epoch[008/040] Iteration[120/381] Loss: 0.0668 Acc:97.19%
Training: Epoch[008/040] Iteration[130/381] Loss: 0.0781 Acc:97.28%
Training: Epoch[008/040] Iteration[140/381] Loss: 0.0532 Acc:97.37%
Training: Epoch[008/040] Iteration[150/381] Loss: 0.0602 Acc:97.42%
Training: Epoch[008/040] Iteration[160/381] Loss: 0.0735 Acc:97.46%
Training: Epoch[008/040] Iteration[170/381] Loss: 0.0961 Acc:97.41%
Training: Epoch[008/040] Iteration[180/381] Loss: 0.0642 Acc:97.47%
Training: Epoch[008/040] Iteration[190/381] Loss: 0.0879 Acc:97.48%
Training: Epoch[008/040] Iteration[200/381] Loss: 0.0829 Acc:97.48%
Training: Epoch[008/040] Iteration[210/381] Loss: 0.0719 Acc:97.50%
Training: Epoch[008/040] Iteration[220/381] Loss: 0.0686 Acc:97.50%
Training: Epoch[008/040] Iteration[230/381] Loss: 0.1019 Acc:97.49%
Training: Epoch[008/040] Iteration[240/381] Loss: 0.0714 Acc:97.50%
Training: Epoch[008/040] Iteration[250/381] Loss: 0.0929 Acc:97.47%
Training: Epoch[008/040] Iteration[260/381] Loss: 0.0438 Acc:97.49%
Training: Epoch[008/040] Iteration[270/381] Loss: 0.0599 Acc:97.51%
Training: Epoch[008/040] Iteration[280/381] Loss: 0.0494 Acc:97.53%
Training: Epoch[008/040] Iteration[290/381] Loss: 0.0922 Acc:97.52%
Training: Epoch[008/040] Iteration[300/381] Loss: 0.1814 Acc:97.43%
Training: Epoch[008/040] Iteration[310/381] Loss: 0.0874 Acc:97.42%
Training: Epoch[008/040] Iteration[320/381] Loss: 0.1495 Acc:97.30%
Training: Epoch[008/040] Iteration[330/381] Loss: 0.1456 Acc:97.23%
Training: Epoch[008/040] Iteration[340/381] Loss: 0.1398 Acc:97.22%
Training: Epoch[008/040] Iteration[350/381] Loss: 0.0486 Acc:97.27%
Training: Epoch[008/040] Iteration[360/381] Loss: 0.1172 Acc:97.26%
Training: Epoch[008/040] Iteration[370/381] Loss: 0.1117 Acc:97.23%
Training: Epoch[008/040] Iteration[380/381] Loss: 0.1046 Acc:97.20%
Training: Epoch[009/040] Iteration[010/381] Loss: 0.0659 Acc:98.12%
Training: Epoch[009/040] Iteration[020/381] Loss: 0.0595 Acc:98.28%
Training: Epoch[009/040] Iteration[030/381] Loss: 0.1137 Acc:97.60%
Training: Epoch[009/040] Iteration[040/381] Loss: 0.0687 Acc:97.58%
Training: Epoch[009/040] Iteration[050/381] Loss: 0.1180 Acc:97.44%
Training: Epoch[009/040] Iteration[060/381] Loss: 0.1059 Acc:97.40%
Training: Epoch[009/040] Iteration[070/381] Loss: 0.0865 Acc:97.59%
Training: Epoch[009/040] Iteration[080/381] Loss: 0.0809 Acc:97.54%
Training: Epoch[009/040] Iteration[090/381] Loss: 0.0367 Acc:97.64%
Training: Epoch[009/040] Iteration[100/381] Loss: 0.1315 Acc:97.53%
Training: Epoch[009/040] Iteration[110/381] Loss: 0.0752 Acc:97.50%
Training: Epoch[009/040] Iteration[120/381] Loss: 0.0876 Acc:97.60%
Training: Epoch[009/040] Iteration[130/381] Loss: 0.0547 Acc:97.72%
Training: Epoch[009/040] Iteration[140/381] Loss: 0.0539 Acc:97.77%
Training: Epoch[009/040] Iteration[150/381] Loss: 0.0857 Acc:97.79%
Training: Epoch[009/040] Iteration[160/381] Loss: 0.0902 Acc:97.83%
Training: Epoch[009/040] Iteration[170/381] Loss: 0.0431 Acc:97.89%
Training: Epoch[009/040] Iteration[180/381] Loss: 0.0796 Acc:97.92%
Training: Epoch[009/040] Iteration[190/381] Loss: 0.0349 Acc:97.99%
Training: Epoch[009/040] Iteration[200/381] Loss: 0.0343 Acc:98.05%
Training: Epoch[009/040] Iteration[210/381] Loss: 0.0419 Acc:98.07%
Training: Epoch[009/040] Iteration[220/381] Loss: 0.0149 Acc:98.14%
Training: Epoch[009/040] Iteration[230/381] Loss: 0.0882 Acc:98.11%
Training: Epoch[009/040] Iteration[240/381] Loss: 0.0541 Acc:98.12%
Training: Epoch[009/040] Iteration[250/381] Loss: 0.0880 Acc:98.06%
Training: Epoch[009/040] Iteration[260/381] Loss: 0.0789 Acc:98.04%
Training: Epoch[009/040] Iteration[270/381] Loss: 0.0502 Acc:98.06%
Training: Epoch[009/040] Iteration[280/381] Loss: 0.1029 Acc:98.02%
Training: Epoch[009/040] Iteration[290/381] Loss: 0.0737 Acc:98.03%
Training: Epoch[009/040] Iteration[300/381] Loss: 0.0678 Acc:98.03%
Training: Epoch[009/040] Iteration[310/381] Loss: 0.1412 Acc:97.98%
Training: Epoch[009/040] Iteration[320/381] Loss: 0.0650 Acc:97.98%
Training: Epoch[009/040] Iteration[330/381] Loss: 0.1373 Acc:97.93%
Training: Epoch[009/040] Iteration[340/381] Loss: 0.1095 Acc:97.91%
Training: Epoch[009/040] Iteration[350/381] Loss: 0.0799 Acc:97.89%
Training: Epoch[009/040] Iteration[360/381] Loss: 0.0901 Acc:97.88%
Training: Epoch[009/040] Iteration[370/381] Loss: 0.1032 Acc:97.87%
Training: Epoch[009/040] Iteration[380/381] Loss: 0.0675 Acc:97.89%
Valid set Accuracy:86.42%
Training: Epoch[010/040] Iteration[010/381] Loss: 0.0302 Acc:99.38%
Training: Epoch[010/040] Iteration[020/381] Loss: 0.0316 Acc:99.06%
Training: Epoch[010/040] Iteration[030/381] Loss: 0.0293 Acc:99.17%
Training: Epoch[010/040] Iteration[040/381] Loss: 0.0367 Acc:99.14%
Training: Epoch[010/040] Iteration[050/381] Loss: 0.0542 Acc:99.12%
Training: Epoch[010/040] Iteration[060/381] Loss: 0.0421 Acc:98.96%
Training: Epoch[010/040] Iteration[070/381] Loss: 0.0540 Acc:98.84%
Training: Epoch[010/040] Iteration[080/381] Loss: 0.0962 Acc:98.71%
Training: Epoch[010/040] Iteration[090/381] Loss: 0.0426 Acc:98.75%
Training: Epoch[010/040] Iteration[100/381] Loss: 0.0418 Acc:98.72%
Training: Epoch[010/040] Iteration[110/381] Loss: 0.0538 Acc:98.66%
Training: Epoch[010/040] Iteration[120/381] Loss: 0.0673 Acc:98.67%
Training: Epoch[010/040] Iteration[130/381] Loss: 0.0657 Acc:98.65%
Training: Epoch[010/040] Iteration[140/381] Loss: 0.0956 Acc:98.48%
Training: Epoch[010/040] Iteration[150/381] Loss: 0.0565 Acc:98.50%
Training: Epoch[010/040] Iteration[160/381] Loss: 0.0880 Acc:98.46%
Training: Epoch[010/040] Iteration[170/381] Loss: 0.0647 Acc:98.36%
Training: Epoch[010/040] Iteration[180/381] Loss: 0.0614 Acc:98.37%
Training: Epoch[010/040] Iteration[190/381] Loss: 0.0499 Acc:98.36%
Training: Epoch[010/040] Iteration[200/381] Loss: 0.0345 Acc:98.38%
Training: Epoch[010/040] Iteration[210/381] Loss: 0.0251 Acc:98.41%
Training: Epoch[010/040] Iteration[220/381] Loss: 0.0417 Acc:98.42%
Training: Epoch[010/040] Iteration[230/381] Loss: 0.0337 Acc:98.44%
Training: Epoch[010/040] Iteration[240/381] Loss: 0.0367 Acc:98.45%
Training: Epoch[010/040] Iteration[250/381] Loss: 0.0784 Acc:98.44%
Training: Epoch[010/040] Iteration[260/381] Loss: 0.0616 Acc:98.39%
Training: Epoch[010/040] Iteration[270/381] Loss: 0.0469 Acc:98.41%
Training: Epoch[010/040] Iteration[280/381] Loss: 0.0724 Acc:98.38%
Training: Epoch[010/040] Iteration[290/381] Loss: 0.0618 Acc:98.36%
Training: Epoch[010/040] Iteration[300/381] Loss: 0.0528 Acc:98.36%
Training: Epoch[010/040] Iteration[310/381] Loss: 0.0716 Acc:98.34%
Training: Epoch[010/040] Iteration[320/381] Loss: 0.0761 Acc:98.33%
Training: Epoch[010/040] Iteration[330/381] Loss: 0.1300 Acc:98.29%
Training: Epoch[010/040] Iteration[340/381] Loss: 0.0374 Acc:98.31%
Training: Epoch[010/040] Iteration[350/381] Loss: 0.0581 Acc:98.31%
Training: Epoch[010/040] Iteration[360/381] Loss: 0.0361 Acc:98.33%
Training: Epoch[010/040] Iteration[370/381] Loss: 0.0474 Acc:98.34%
Training: Epoch[010/040] Iteration[380/381] Loss: 0.0594 Acc:98.31%
Training: Epoch[011/040] Iteration[010/381] Loss: 0.0422 Acc:98.12%
Training: Epoch[011/040] Iteration[020/381] Loss: 0.0610 Acc:97.97%
Training: Epoch[011/040] Iteration[030/381] Loss: 0.1147 Acc:97.81%
Training: Epoch[011/040] Iteration[040/381] Loss: 0.0603 Acc:97.66%
Training: Epoch[011/040] Iteration[050/381] Loss: 0.0859 Acc:97.69%
Training: Epoch[011/040] Iteration[060/381] Loss: 0.0299 Acc:97.92%
Training: Epoch[011/040] Iteration[070/381] Loss: 0.0727 Acc:97.95%
Training: Epoch[011/040] Iteration[080/381] Loss: 0.0283 Acc:98.09%
Training: Epoch[011/040] Iteration[090/381] Loss: 0.0686 Acc:98.06%
Training: Epoch[011/040] Iteration[100/381] Loss: 0.0351 Acc:98.12%
Training: Epoch[011/040] Iteration[110/381] Loss: 0.0568 Acc:98.18%
Training: Epoch[011/040] Iteration[120/381] Loss: 0.0577 Acc:98.20%
Training: Epoch[011/040] Iteration[130/381] Loss: 0.0982 Acc:98.22%
Training: Epoch[011/040] Iteration[140/381] Loss: 0.0508 Acc:98.26%
Training: Epoch[011/040] Iteration[150/381] Loss: 0.0412 Acc:98.31%
Training: Epoch[011/040] Iteration[160/381] Loss: 0.0183 Acc:98.40%
Training: Epoch[011/040] Iteration[170/381] Loss: 0.0517 Acc:98.44%
Training: Epoch[011/040] Iteration[180/381] Loss: 0.0505 Acc:98.44%
Training: Epoch[011/040] Iteration[190/381] Loss: 0.1091 Acc:98.42%
Training: Epoch[011/040] Iteration[200/381] Loss: 0.1287 Acc:98.39%
Training: Epoch[011/040] Iteration[210/381] Loss: 0.0736 Acc:98.38%
Training: Epoch[011/040] Iteration[220/381] Loss: 0.0558 Acc:98.35%
Training: Epoch[011/040] Iteration[230/381] Loss: 0.0311 Acc:98.38%
Training: Epoch[011/040] Iteration[240/381] Loss: 0.0723 Acc:98.33%
Training: Epoch[011/040] Iteration[250/381] Loss: 0.0214 Acc:98.39%
Training: Epoch[011/040] Iteration[260/381] Loss: 0.0690 Acc:98.38%
Training: Epoch[011/040] Iteration[270/381] Loss: 0.0453 Acc:98.40%
Training: Epoch[011/040] Iteration[280/381] Loss: 0.0935 Acc:98.39%
Training: Epoch[011/040] Iteration[290/381] Loss: 0.0581 Acc:98.37%
Training: Epoch[011/040] Iteration[300/381] Loss: 0.0821 Acc:98.38%
Training: Epoch[011/040] Iteration[310/381] Loss: 0.0659 Acc:98.38%
Training: Epoch[011/040] Iteration[320/381] Loss: 0.0570 Acc:98.37%
Training: Epoch[011/040] Iteration[330/381] Loss: 0.0565 Acc:98.35%
Training: Epoch[011/040] Iteration[340/381] Loss: 0.0272 Acc:98.38%
Training: Epoch[011/040] Iteration[350/381] Loss: 0.0712 Acc:98.38%
Training: Epoch[011/040] Iteration[360/381] Loss: 0.0443 Acc:98.39%
Training: Epoch[011/040] Iteration[370/381] Loss: 0.0632 Acc:98.39%
Training: Epoch[011/040] Iteration[380/381] Loss: 0.0683 Acc:98.37%
Valid set Accuracy:87.35%
Training: Epoch[012/040] Iteration[010/381] Loss: 0.0573 Acc:98.75%
Training: Epoch[012/040] Iteration[020/381] Loss: 0.0302 Acc:98.75%
Training: Epoch[012/040] Iteration[030/381] Loss: 0.0583 Acc:98.65%
Training: Epoch[012/040] Iteration[040/381] Loss: 0.0355 Acc:98.75%
Training: Epoch[012/040] Iteration[050/381] Loss: 0.0608 Acc:98.69%
Training: Epoch[012/040] Iteration[060/381] Loss: 0.0781 Acc:98.54%
Training: Epoch[012/040] Iteration[070/381] Loss: 0.0521 Acc:98.44%
Training: Epoch[012/040] Iteration[080/381] Loss: 0.0168 Acc:98.55%
Training: Epoch[012/040] Iteration[090/381] Loss: 0.0784 Acc:98.47%
Training: Epoch[012/040] Iteration[100/381] Loss: 0.0345 Acc:98.56%
Training: Epoch[012/040] Iteration[110/381] Loss: 0.0698 Acc:98.58%
Training: Epoch[012/040] Iteration[120/381] Loss: 0.0522 Acc:98.52%
Training: Epoch[012/040] Iteration[130/381] Loss: 0.0370 Acc:98.58%
Training: Epoch[012/040] Iteration[140/381] Loss: 0.0169 Acc:98.68%
Training: Epoch[012/040] Iteration[150/381] Loss: 0.0192 Acc:98.73%
Training: Epoch[012/040] Iteration[160/381] Loss: 0.0182 Acc:98.77%
Training: Epoch[012/040] Iteration[170/381] Loss: 0.0504 Acc:98.75%
Training: Epoch[012/040] Iteration[180/381] Loss: 0.0307 Acc:98.78%
Training: Epoch[012/040] Iteration[190/381] Loss: 0.0401 Acc:98.80%
Training: Epoch[012/040] Iteration[200/381] Loss: 0.0273 Acc:98.83%
Training: Epoch[012/040] Iteration[210/381] Loss: 0.0295 Acc:98.84%
Training: Epoch[012/040] Iteration[220/381] Loss: 0.0256 Acc:98.84%
Training: Epoch[012/040] Iteration[230/381] Loss: 0.0522 Acc:98.80%
Training: Epoch[012/040] Iteration[240/381] Loss: 0.0224 Acc:98.82%
Training: Epoch[012/040] Iteration[250/381] Loss: 0.0432 Acc:98.80%
Training: Epoch[012/040] Iteration[260/381] Loss: 0.0494 Acc:98.80%
Training: Epoch[012/040] Iteration[270/381] Loss: 0.0223 Acc:98.82%
Training: Epoch[012/040] Iteration[280/381] Loss: 0.0518 Acc:98.81%
Training: Epoch[012/040] Iteration[290/381] Loss: 0.0414 Acc:98.79%
Training: Epoch[012/040] Iteration[300/381] Loss: 0.0400 Acc:98.80%
Training: Epoch[012/040] Iteration[310/381] Loss: 0.0725 Acc:98.79%
Training: Epoch[012/040] Iteration[320/381] Loss: 0.0471 Acc:98.80%
Training: Epoch[012/040] Iteration[330/381] Loss: 0.0617 Acc:98.77%
Training: Epoch[012/040] Iteration[340/381] Loss: 0.0547 Acc:98.76%
Training: Epoch[012/040] Iteration[350/381] Loss: 0.0230 Acc:98.79%
Training: Epoch[012/040] Iteration[360/381] Loss: 0.0492 Acc:98.79%
Training: Epoch[012/040] Iteration[370/381] Loss: 0.0422 Acc:98.81%
Training: Epoch[012/040] Iteration[380/381] Loss: 0.0269 Acc:98.81%
Training: Epoch[013/040] Iteration[010/381] Loss: 0.0585 Acc:98.75%
Training: Epoch[013/040] Iteration[020/381] Loss: 0.0277 Acc:98.91%
Training: Epoch[013/040] Iteration[030/381] Loss: 0.0088 Acc:99.17%
Training: Epoch[013/040] Iteration[040/381] Loss: 0.0367 Acc:99.22%
Training: Epoch[013/040] Iteration[050/381] Loss: 0.0486 Acc:98.88%
Training: Epoch[013/040] Iteration[060/381] Loss: 0.0306 Acc:98.96%
Training: Epoch[013/040] Iteration[070/381] Loss: 0.0392 Acc:98.97%
Training: Epoch[013/040] Iteration[080/381] Loss: 0.0607 Acc:98.95%
Training: Epoch[013/040] Iteration[090/381] Loss: 0.0554 Acc:98.89%
Training: Epoch[013/040] Iteration[100/381] Loss: 0.0134 Acc:98.97%
Training: Epoch[013/040] Iteration[110/381] Loss: 0.0645 Acc:98.89%
Training: Epoch[013/040] Iteration[120/381] Loss: 0.0192 Acc:98.93%
Training: Epoch[013/040] Iteration[130/381] Loss: 0.0236 Acc:98.99%
Training: Epoch[013/040] Iteration[140/381] Loss: 0.0242 Acc:98.97%
Training: Epoch[013/040] Iteration[150/381] Loss: 0.0107 Acc:99.02%
Training: Epoch[013/040] Iteration[160/381] Loss: 0.0114 Acc:99.08%
Training: Epoch[013/040] Iteration[170/381] Loss: 0.0134 Acc:99.10%
Training: Epoch[013/040] Iteration[180/381] Loss: 0.0262 Acc:99.11%
Training: Epoch[013/040] Iteration[190/381] Loss: 0.0061 Acc:99.16%
Training: Epoch[013/040] Iteration[200/381] Loss: 0.0078 Acc:99.19%
Training: Epoch[013/040] Iteration[210/381] Loss: 0.0230 Acc:99.20%
Training: Epoch[013/040] Iteration[220/381] Loss: 0.0406 Acc:99.20%
Training: Epoch[013/040] Iteration[230/381] Loss: 0.0189 Acc:99.20%
Training: Epoch[013/040] Iteration[240/381] Loss: 0.0065 Acc:99.23%
Training: Epoch[013/040] Iteration[250/381] Loss: 0.0064 Acc:99.26%
Training: Epoch[013/040] Iteration[260/381] Loss: 0.0214 Acc:99.28%
Training: Epoch[013/040] Iteration[270/381] Loss: 0.0308 Acc:99.26%
Training: Epoch[013/040] Iteration[280/381] Loss: 0.0129 Acc:99.26%
Training: Epoch[013/040] Iteration[290/381] Loss: 0.0324 Acc:99.25%
Training: Epoch[013/040] Iteration[300/381] Loss: 0.0502 Acc:99.20%
Training: Epoch[013/040] Iteration[310/381] Loss: 0.0458 Acc:99.18%
Training: Epoch[013/040] Iteration[320/381] Loss: 0.0163 Acc:99.19%
Training: Epoch[013/040] Iteration[330/381] Loss: 0.0346 Acc:99.17%
Training: Epoch[013/040] Iteration[340/381] Loss: 0.0523 Acc:99.12%
Training: Epoch[013/040] Iteration[350/381] Loss: 0.0203 Acc:99.12%
Training: Epoch[013/040] Iteration[360/381] Loss: 0.0131 Acc:99.14%
Training: Epoch[013/040] Iteration[370/381] Loss: 0.0330 Acc:99.12%
Training: Epoch[013/040] Iteration[380/381] Loss: 0.0234 Acc:99.12%
Valid set Accuracy:84.55%
Training: Epoch[014/040] Iteration[010/381] Loss: 0.0198 Acc:99.06%
Training: Epoch[014/040] Iteration[020/381] Loss: 0.0071 Acc:99.38%
Training: Epoch[014/040] Iteration[030/381] Loss: 0.0269 Acc:99.38%
Training: Epoch[014/040] Iteration[040/381] Loss: 0.0651 Acc:99.06%
Training: Epoch[014/040] Iteration[050/381] Loss: 0.0786 Acc:98.94%
Training: Epoch[014/040] Iteration[060/381] Loss: 0.1093 Acc:98.96%
Training: Epoch[014/040] Iteration[070/381] Loss: 0.1124 Acc:98.66%
Training: Epoch[014/040] Iteration[080/381] Loss: 0.0738 Acc:98.55%
Training: Epoch[014/040] Iteration[090/381] Loss: 0.0429 Acc:98.61%
Training: Epoch[014/040] Iteration[100/381] Loss: 0.0272 Acc:98.66%
Training: Epoch[014/040] Iteration[110/381] Loss: 0.0348 Acc:98.72%
Training: Epoch[014/040] Iteration[120/381] Loss: 0.0085 Acc:98.83%
Training: Epoch[014/040] Iteration[130/381] Loss: 0.0206 Acc:98.87%
Training: Epoch[014/040] Iteration[140/381] Loss: 0.0239 Acc:98.93%
Training: Epoch[014/040] Iteration[150/381] Loss: 0.0227 Acc:98.92%
Training: Epoch[014/040] Iteration[160/381] Loss: 0.0158 Acc:98.96%
Training: Epoch[014/040] Iteration[170/381] Loss: 0.0083 Acc:99.01%
Training: Epoch[014/040] Iteration[180/381] Loss: 0.0177 Acc:99.05%
Training: Epoch[014/040] Iteration[190/381] Loss: 0.0270 Acc:99.03%
Training: Epoch[014/040] Iteration[200/381] Loss: 0.0081 Acc:99.08%
Training: Epoch[014/040] Iteration[210/381] Loss: 0.0292 Acc:99.11%
Training: Epoch[014/040] Iteration[220/381] Loss: 0.0239 Acc:99.11%
Training: Epoch[014/040] Iteration[230/381] Loss: 0.0321 Acc:99.10%
Training: Epoch[014/040] Iteration[240/381] Loss: 0.0273 Acc:99.10%
Training: Epoch[014/040] Iteration[250/381] Loss: 0.0393 Acc:99.08%
Training: Epoch[014/040] Iteration[260/381] Loss: 0.0276 Acc:99.07%
Training: Epoch[014/040] Iteration[270/381] Loss: 0.1061 Acc:99.03%
Training: Epoch[014/040] Iteration[280/381] Loss: 0.0472 Acc:99.01%
Training: Epoch[014/040] Iteration[290/381] Loss: 0.0894 Acc:98.99%
Training: Epoch[014/040] Iteration[300/381] Loss: 0.0469 Acc:98.94%
Training: Epoch[014/040] Iteration[310/381] Loss: 0.0270 Acc:98.96%
Training: Epoch[014/040] Iteration[320/381] Loss: 0.0156 Acc:98.97%
Training: Epoch[014/040] Iteration[330/381] Loss: 0.0389 Acc:98.97%
Training: Epoch[014/040] Iteration[340/381] Loss: 0.0256 Acc:98.96%
Training: Epoch[014/040] Iteration[350/381] Loss: 0.0220 Acc:98.96%
Training: Epoch[014/040] Iteration[360/381] Loss: 0.0891 Acc:98.90%
Training: Epoch[014/040] Iteration[370/381] Loss: 0.0324 Acc:98.89%
Training: Epoch[014/040] Iteration[380/381] Loss: 0.0161 Acc:98.91%
Training: Epoch[015/040] Iteration[010/381] Loss: 0.0376 Acc:98.12%
Training: Epoch[015/040] Iteration[020/381] Loss: 0.0220 Acc:98.59%
Training: Epoch[015/040] Iteration[030/381] Loss: 0.0721 Acc:98.54%
Training: Epoch[015/040] Iteration[040/381] Loss: 0.0340 Acc:98.52%
Training: Epoch[015/040] Iteration[050/381] Loss: 0.0182 Acc:98.69%
Training: Epoch[015/040] Iteration[060/381] Loss: 0.0149 Acc:98.80%
Training: Epoch[015/040] Iteration[070/381] Loss: 0.0289 Acc:98.75%
Training: Epoch[015/040] Iteration[080/381] Loss: 0.0282 Acc:98.83%
Training: Epoch[015/040] Iteration[090/381] Loss: 0.0114 Acc:98.96%
Training: Epoch[015/040] Iteration[100/381] Loss: 0.0238 Acc:99.03%
Training: Epoch[015/040] Iteration[110/381] Loss: 0.0458 Acc:99.03%
Training: Epoch[015/040] Iteration[120/381] Loss: 0.0514 Acc:99.04%
Training: Epoch[015/040] Iteration[130/381] Loss: 0.0279 Acc:99.04%
Training: Epoch[015/040] Iteration[140/381] Loss: 0.0461 Acc:99.02%
Training: Epoch[015/040] Iteration[150/381] Loss: 0.0522 Acc:98.96%
Training: Epoch[015/040] Iteration[160/381] Loss: 0.0353 Acc:98.93%
Training: Epoch[015/040] Iteration[170/381] Loss: 0.0371 Acc:98.92%
Training: Epoch[015/040] Iteration[180/381] Loss: 0.0502 Acc:98.91%
Training: Epoch[015/040] Iteration[190/381] Loss: 0.0272 Acc:98.93%
Training: Epoch[015/040] Iteration[200/381] Loss: 0.0213 Acc:98.95%
Training: Epoch[015/040] Iteration[210/381] Loss: 0.0389 Acc:98.90%
Training: Epoch[015/040] Iteration[220/381] Loss: 0.0239 Acc:98.93%
Training: Epoch[015/040] Iteration[230/381] Loss: 0.0234 Acc:98.94%
Training: Epoch[015/040] Iteration[240/381] Loss: 0.0396 Acc:98.92%
Training: Epoch[015/040] Iteration[250/381] Loss: 0.0218 Acc:98.94%
Training: Epoch[015/040] Iteration[260/381] Loss: 0.0335 Acc:98.91%
Training: Epoch[015/040] Iteration[270/381] Loss: 0.0360 Acc:98.90%
Training: Epoch[015/040] Iteration[280/381] Loss: 0.0559 Acc:98.88%
Training: Epoch[015/040] Iteration[290/381] Loss: 0.0291 Acc:98.88%
Training: Epoch[015/040] Iteration[300/381] Loss: 0.0824 Acc:98.83%
Training: Epoch[015/040] Iteration[310/381] Loss: 0.0830 Acc:98.82%
Training: Epoch[015/040] Iteration[320/381] Loss: 0.0484 Acc:98.81%
Training: Epoch[015/040] Iteration[330/381] Loss: 0.0696 Acc:98.78%
Training: Epoch[015/040] Iteration[340/381] Loss: 0.1387 Acc:98.73%
Training: Epoch[015/040] Iteration[350/381] Loss: 0.0654 Acc:98.72%
Training: Epoch[015/040] Iteration[360/381] Loss: 0.0270 Acc:98.74%
Training: Epoch[015/040] Iteration[370/381] Loss: 0.0399 Acc:98.75%
Training: Epoch[015/040] Iteration[380/381] Loss: 0.0315 Acc:98.76%
Valid set Accuracy:87.48%
Training: Epoch[016/040] Iteration[010/381] Loss: 0.0166 Acc:99.69%
Training: Epoch[016/040] Iteration[020/381] Loss: 0.0270 Acc:99.69%
Training: Epoch[016/040] Iteration[030/381] Loss: 0.0148 Acc:99.58%
Training: Epoch[016/040] Iteration[040/381] Loss: 0.0361 Acc:99.38%
Training: Epoch[016/040] Iteration[050/381] Loss: 0.0236 Acc:99.31%
Training: Epoch[016/040] Iteration[060/381] Loss: 0.0033 Acc:99.43%
Training: Epoch[016/040] Iteration[070/381] Loss: 0.0118 Acc:99.46%
Training: Epoch[016/040] Iteration[080/381] Loss: 0.0129 Acc:99.49%
Training: Epoch[016/040] Iteration[090/381] Loss: 0.0069 Acc:99.51%
Training: Epoch[016/040] Iteration[100/381] Loss: 0.0100 Acc:99.53%
Training: Epoch[016/040] Iteration[110/381] Loss: 0.0086 Acc:99.55%
Training: Epoch[016/040] Iteration[120/381] Loss: 0.0060 Acc:99.58%
Training: Epoch[016/040] Iteration[130/381] Loss: 0.0257 Acc:99.59%
Training: Epoch[016/040] Iteration[140/381] Loss: 0.0063 Acc:99.60%
Training: Epoch[016/040] Iteration[150/381] Loss: 0.0204 Acc:99.58%
Training: Epoch[016/040] Iteration[160/381] Loss: 0.0227 Acc:99.57%
Training: Epoch[016/040] Iteration[170/381] Loss: 0.0305 Acc:99.58%
Training: Epoch[016/040] Iteration[180/381] Loss: 0.0317 Acc:99.57%
Training: Epoch[016/040] Iteration[190/381] Loss: 0.0210 Acc:99.56%
Training: Epoch[016/040] Iteration[200/381] Loss: 0.0265 Acc:99.55%
Training: Epoch[016/040] Iteration[210/381] Loss: 0.0476 Acc:99.48%
Training: Epoch[016/040] Iteration[220/381] Loss: 0.0172 Acc:99.49%
Training: Epoch[016/040] Iteration[230/381] Loss: 0.0138 Acc:99.48%
Training: Epoch[016/040] Iteration[240/381] Loss: 0.0209 Acc:99.48%
Training: Epoch[016/040] Iteration[250/381] Loss: 0.0414 Acc:99.44%
Training: Epoch[016/040] Iteration[260/381] Loss: 0.0397 Acc:99.44%
Training: Epoch[016/040] Iteration[270/381] Loss: 0.0235 Acc:99.43%
Training: Epoch[016/040] Iteration[280/381] Loss: 0.0394 Acc:99.39%
Training: Epoch[016/040] Iteration[290/381] Loss: 0.0661 Acc:99.35%
Training: Epoch[016/040] Iteration[300/381] Loss: 0.0648 Acc:99.31%
Training: Epoch[016/040] Iteration[310/381] Loss: 0.0436 Acc:99.27%
Training: Epoch[016/040] Iteration[320/381] Loss: 0.0201 Acc:99.28%
Training: Epoch[016/040] Iteration[330/381] Loss: 0.0331 Acc:99.26%
Training: Epoch[016/040] Iteration[340/381] Loss: 0.0457 Acc:99.23%
Training: Epoch[016/040] Iteration[350/381] Loss: 0.1015 Acc:99.20%
Training: Epoch[016/040] Iteration[360/381] Loss: 0.0214 Acc:99.22%
Training: Epoch[016/040] Iteration[370/381] Loss: 0.0465 Acc:99.20%
Training: Epoch[016/040] Iteration[380/381] Loss: 0.0444 Acc:99.20%
Training: Epoch[017/040] Iteration[010/381] Loss: 0.0138 Acc:99.69%
Training: Epoch[017/040] Iteration[020/381] Loss: 0.0171 Acc:99.69%
Training: Epoch[017/040] Iteration[030/381] Loss: 0.0252 Acc:99.48%
Training: Epoch[017/040] Iteration[040/381] Loss: 0.0170 Acc:99.45%
Training: Epoch[017/040] Iteration[050/381] Loss: 0.0291 Acc:99.38%
Training: Epoch[017/040] Iteration[060/381] Loss: 0.0168 Acc:99.32%
Training: Epoch[017/040] Iteration[070/381] Loss: 0.0345 Acc:99.15%
Training: Epoch[017/040] Iteration[080/381] Loss: 0.0354 Acc:99.18%
Training: Epoch[017/040] Iteration[090/381] Loss: 0.0724 Acc:99.17%
Training: Epoch[017/040] Iteration[100/381] Loss: 0.0082 Acc:99.22%
Training: Epoch[017/040] Iteration[110/381] Loss: 0.0131 Acc:99.26%
Training: Epoch[017/040] Iteration[120/381] Loss: 0.0268 Acc:99.24%
Training: Epoch[017/040] Iteration[130/381] Loss: 0.0413 Acc:99.25%
Training: Epoch[017/040] Iteration[140/381] Loss: 0.0272 Acc:99.29%
Training: Epoch[017/040] Iteration[150/381] Loss: 0.0223 Acc:99.29%
Training: Epoch[017/040] Iteration[160/381] Loss: 0.0142 Acc:99.32%
Training: Epoch[017/040] Iteration[170/381] Loss: 0.0317 Acc:99.30%
Training: Epoch[017/040] Iteration[180/381] Loss: 0.0244 Acc:99.31%
Training: Epoch[017/040] Iteration[190/381] Loss: 0.0526 Acc:99.29%
Training: Epoch[017/040] Iteration[200/381] Loss: 0.0392 Acc:99.30%
Training: Epoch[017/040] Iteration[210/381] Loss: 0.0184 Acc:99.30%
Training: Epoch[017/040] Iteration[220/381] Loss: 0.0093 Acc:99.32%
Training: Epoch[017/040] Iteration[230/381] Loss: 0.0064 Acc:99.35%
Training: Epoch[017/040] Iteration[240/381] Loss: 0.0136 Acc:99.36%
Training: Epoch[017/040] Iteration[250/381] Loss: 0.0020 Acc:99.39%
Training: Epoch[017/040] Iteration[260/381] Loss: 0.0057 Acc:99.40%
Training: Epoch[017/040] Iteration[270/381] Loss: 0.0053 Acc:99.41%
Training: Epoch[017/040] Iteration[280/381] Loss: 0.0089 Acc:99.41%
Training: Epoch[017/040] Iteration[290/381] Loss: 0.0073 Acc:99.43%
Training: Epoch[017/040] Iteration[300/381] Loss: 0.0029 Acc:99.45%
Training: Epoch[017/040] Iteration[310/381] Loss: 0.0075 Acc:99.46%
Training: Epoch[017/040] Iteration[320/381] Loss: 0.0107 Acc:99.46%
Training: Epoch[017/040] Iteration[330/381] Loss: 0.0219 Acc:99.47%
Training: Epoch[017/040] Iteration[340/381] Loss: 0.0132 Acc:99.48%
Training: Epoch[017/040] Iteration[350/381] Loss: 0.0375 Acc:99.47%
Training: Epoch[017/040] Iteration[360/381] Loss: 0.0210 Acc:99.47%
Training: Epoch[017/040] Iteration[370/381] Loss: 0.0491 Acc:99.44%
Training: Epoch[017/040] Iteration[380/381] Loss: 0.0230 Acc:99.45%
Valid set Accuracy:88.68%
Training: Epoch[018/040] Iteration[010/381] Loss: 0.0253 Acc:99.38%
Training: Epoch[018/040] Iteration[020/381] Loss: 0.0058 Acc:99.53%
Training: Epoch[018/040] Iteration[030/381] Loss: 0.0248 Acc:99.38%
Training: Epoch[018/040] Iteration[040/381] Loss: 0.0291 Acc:99.38%
Training: Epoch[018/040] Iteration[050/381] Loss: 0.0351 Acc:99.31%
Training: Epoch[018/040] Iteration[060/381] Loss: 0.0136 Acc:99.38%
Training: Epoch[018/040] Iteration[070/381] Loss: 0.0033 Acc:99.46%
Training: Epoch[018/040] Iteration[080/381] Loss: 0.0270 Acc:99.41%
Training: Epoch[018/040] Iteration[090/381] Loss: 0.0270 Acc:99.44%
Training: Epoch[018/040] Iteration[100/381] Loss: 0.0231 Acc:99.47%
Training: Epoch[018/040] Iteration[110/381] Loss: 0.0036 Acc:99.52%
Training: Epoch[018/040] Iteration[120/381] Loss: 0.0369 Acc:99.45%
Training: Epoch[018/040] Iteration[130/381] Loss: 0.0121 Acc:99.50%
Training: Epoch[018/040] Iteration[140/381] Loss: 0.0857 Acc:99.44%
Training: Epoch[018/040] Iteration[150/381] Loss: 0.0180 Acc:99.46%
Training: Epoch[018/040] Iteration[160/381] Loss: 0.0172 Acc:99.47%
Training: Epoch[018/040] Iteration[170/381] Loss: 0.0050 Acc:99.50%
Training: Epoch[018/040] Iteration[180/381] Loss: 0.0078 Acc:99.51%
Training: Epoch[018/040] Iteration[190/381] Loss: 0.0784 Acc:99.46%
Training: Epoch[018/040] Iteration[200/381] Loss: 0.0139 Acc:99.47%
Training: Epoch[018/040] Iteration[210/381] Loss: 0.0160 Acc:99.48%
Training: Epoch[018/040] Iteration[220/381] Loss: 0.0084 Acc:99.49%
Training: Epoch[018/040] Iteration[230/381] Loss: 0.0030 Acc:99.51%
Training: Epoch[018/040] Iteration[240/381] Loss: 0.0146 Acc:99.49%
Training: Epoch[018/040] Iteration[250/381] Loss: 0.0090 Acc:99.50%
Training: Epoch[018/040] Iteration[260/381] Loss: 0.0033 Acc:99.52%
Training: Epoch[018/040] Iteration[270/381] Loss: 0.0069 Acc:99.53%
Training: Epoch[018/040] Iteration[280/381] Loss: 0.0149 Acc:99.53%
Training: Epoch[018/040] Iteration[290/381] Loss: 0.0397 Acc:99.54%
Training: Epoch[018/040] Iteration[300/381] Loss: 0.0159 Acc:99.53%
Training: Epoch[018/040] Iteration[310/381] Loss: 0.0026 Acc:99.55%
Training: Epoch[018/040] Iteration[320/381] Loss: 0.0035 Acc:99.56%
Training: Epoch[018/040] Iteration[330/381] Loss: 0.0040 Acc:99.57%
Training: Epoch[018/040] Iteration[340/381] Loss: 0.0073 Acc:99.58%
Training: Epoch[018/040] Iteration[350/381] Loss: 0.0043 Acc:99.59%
Training: Epoch[018/040] Iteration[360/381] Loss: 0.0024 Acc:99.60%
Training: Epoch[018/040] Iteration[370/381] Loss: 0.0037 Acc:99.61%
Training: Epoch[018/040] Iteration[380/381] Loss: 0.0107 Acc:99.61%
Training: Epoch[019/040] Iteration[010/381] Loss: 0.0203 Acc:99.69%
Training: Epoch[019/040] Iteration[020/381] Loss: 0.0027 Acc:99.84%
Training: Epoch[019/040] Iteration[030/381] Loss: 0.0074 Acc:99.79%
Training: Epoch[019/040] Iteration[040/381] Loss: 0.0015 Acc:99.84%
Training: Epoch[019/040] Iteration[050/381] Loss: 0.0049 Acc:99.88%
Training: Epoch[019/040] Iteration[060/381] Loss: 0.0055 Acc:99.84%
Training: Epoch[019/040] Iteration[070/381] Loss: 0.0031 Acc:99.87%
Training: Epoch[019/040] Iteration[080/381] Loss: 0.0010 Acc:99.88%
Training: Epoch[019/040] Iteration[090/381] Loss: 0.0018 Acc:99.90%
Training: Epoch[019/040] Iteration[100/381] Loss: 0.0017 Acc:99.91%
Training: Epoch[019/040] Iteration[110/381] Loss: 0.0007 Acc:99.91%
Training: Epoch[019/040] Iteration[120/381] Loss: 0.0013 Acc:99.92%
Training: Epoch[019/040] Iteration[130/381] Loss: 0.0005 Acc:99.93%
Training: Epoch[019/040] Iteration[140/381] Loss: 0.0020 Acc:99.93%
Training: Epoch[019/040] Iteration[150/381] Loss: 0.0010 Acc:99.94%
Training: Epoch[019/040] Iteration[160/381] Loss: 0.0046 Acc:99.92%
Training: Epoch[019/040] Iteration[170/381] Loss: 0.0015 Acc:99.93%
Training: Epoch[019/040] Iteration[180/381] Loss: 0.0012 Acc:99.93%
Training: Epoch[019/040] Iteration[190/381] Loss: 0.0011 Acc:99.93%
Training: Epoch[019/040] Iteration[200/381] Loss: 0.0003 Acc:99.94%
Training: Epoch[019/040] Iteration[210/381] Loss: 0.0042 Acc:99.93%
Training: Epoch[019/040] Iteration[220/381] Loss: 0.0004 Acc:99.93%
Training: Epoch[019/040] Iteration[230/381] Loss: 0.0016 Acc:99.93%
Training: Epoch[019/040] Iteration[240/381] Loss: 0.0024 Acc:99.93%
Training: Epoch[019/040] Iteration[250/381] Loss: 0.0017 Acc:99.94%
Training: Epoch[019/040] Iteration[260/381] Loss: 0.0004 Acc:99.94%
Training: Epoch[019/040] Iteration[270/381] Loss: 0.0004 Acc:99.94%
Training: Epoch[019/040] Iteration[280/381] Loss: 0.0070 Acc:99.93%
Training: Epoch[019/040] Iteration[290/381] Loss: 0.0301 Acc:99.92%
Training: Epoch[019/040] Iteration[300/381] Loss: 0.0023 Acc:99.93%
Training: Epoch[019/040] Iteration[310/381] Loss: 0.0054 Acc:99.93%
Training: Epoch[019/040] Iteration[320/381] Loss: 0.0123 Acc:99.92%
Training: Epoch[019/040] Iteration[330/381] Loss: 0.0028 Acc:99.92%
Training: Epoch[019/040] Iteration[340/381] Loss: 0.0091 Acc:99.92%
Training: Epoch[019/040] Iteration[350/381] Loss: 0.0210 Acc:99.91%
Training: Epoch[019/040] Iteration[360/381] Loss: 0.0030 Acc:99.91%
Training: Epoch[019/040] Iteration[370/381] Loss: 0.0093 Acc:99.91%
Training: Epoch[019/040] Iteration[380/381] Loss: 0.0020 Acc:99.91%
Valid set Accuracy:89.48%
Training: Epoch[020/040] Iteration[010/381] Loss: 0.0011 Acc:100.00%
Training: Epoch[020/040] Iteration[020/381] Loss: 0.0028 Acc:100.00%
Training: Epoch[020/040] Iteration[030/381] Loss: 0.0027 Acc:100.00%
Training: Epoch[020/040] Iteration[040/381] Loss: 0.0006 Acc:100.00%
Training: Epoch[020/040] Iteration[050/381] Loss: 0.0003 Acc:100.00%
Training: Epoch[020/040] Iteration[060/381] Loss: 0.0069 Acc:99.95%
Training: Epoch[020/040] Iteration[070/381] Loss: 0.0030 Acc:99.96%
Training: Epoch[020/040] Iteration[080/381] Loss: 0.0008 Acc:99.96%
Training: Epoch[020/040] Iteration[090/381] Loss: 0.0031 Acc:99.97%
Training: Epoch[020/040] Iteration[100/381] Loss: 0.0014 Acc:99.97%
Training: Epoch[020/040] Iteration[110/381] Loss: 0.0009 Acc:99.97%
Training: Epoch[020/040] Iteration[120/381] Loss: 0.0016 Acc:99.97%
Training: Epoch[020/040] Iteration[130/381] Loss: 0.0002 Acc:99.98%
Training: Epoch[020/040] Iteration[140/381] Loss: 0.0002 Acc:99.98%
Training: Epoch[020/040] Iteration[150/381] Loss: 0.0002 Acc:99.98%
Training: Epoch[020/040] Iteration[160/381] Loss: 0.0003 Acc:99.98%
Training: Epoch[020/040] Iteration[170/381] Loss: 0.0026 Acc:99.96%
Training: Epoch[020/040] Iteration[180/381] Loss: 0.0008 Acc:99.97%
Training: Epoch[020/040] Iteration[190/381] Loss: 0.0037 Acc:99.95%
Training: Epoch[020/040] Iteration[200/381] Loss: 0.0037 Acc:99.95%
Training: Epoch[020/040] Iteration[210/381] Loss: 0.0028 Acc:99.96%
Training: Epoch[020/040] Iteration[220/381] Loss: 0.0224 Acc:99.94%
Training: Epoch[020/040] Iteration[230/381] Loss: 0.0042 Acc:99.93%
Training: Epoch[020/040] Iteration[240/381] Loss: 0.0083 Acc:99.92%
Training: Epoch[020/040] Iteration[250/381] Loss: 0.0039 Acc:99.92%
Training: Epoch[020/040] Iteration[260/381] Loss: 0.0195 Acc:99.92%
Training: Epoch[020/040] Iteration[270/381] Loss: 0.0051 Acc:99.91%
Training: Epoch[020/040] Iteration[280/381] Loss: 0.0083 Acc:99.90%
Training: Epoch[020/040] Iteration[290/381] Loss: 0.0084 Acc:99.89%
Training: Epoch[020/040] Iteration[300/381] Loss: 0.0222 Acc:99.89%
Training: Epoch[020/040] Iteration[310/381] Loss: 0.0037 Acc:99.89%
Training: Epoch[020/040] Iteration[320/381] Loss: 0.0066 Acc:99.88%
Training: Epoch[020/040] Iteration[330/381] Loss: 0.0019 Acc:99.89%
Training: Epoch[020/040] Iteration[340/381] Loss: 0.0119 Acc:99.87%
Training: Epoch[020/040] Iteration[350/381] Loss: 0.0049 Acc:99.88%
Training: Epoch[020/040] Iteration[360/381] Loss: 0.0115 Acc:99.86%
Training: Epoch[020/040] Iteration[370/381] Loss: 0.0175 Acc:99.84%
Training: Epoch[020/040] Iteration[380/381] Loss: 0.0308 Acc:99.83%
Training: Epoch[021/040] Iteration[010/381] Loss: 0.0505 Acc:99.06%
Training: Epoch[021/040] Iteration[020/381] Loss: 0.0722 Acc:98.75%
Training: Epoch[021/040] Iteration[030/381] Loss: 0.0350 Acc:98.65%
Training: Epoch[021/040] Iteration[040/381] Loss: 0.0211 Acc:98.91%
Training: Epoch[021/040] Iteration[050/381] Loss: 0.0248 Acc:98.88%
Training: Epoch[021/040] Iteration[060/381] Loss: 0.0247 Acc:98.85%
Training: Epoch[021/040] Iteration[070/381] Loss: 0.0336 Acc:98.88%
Training: Epoch[021/040] Iteration[080/381] Loss: 0.0169 Acc:98.95%
Training: Epoch[021/040] Iteration[090/381] Loss: 0.0161 Acc:99.03%
Training: Epoch[021/040] Iteration[100/381] Loss: 0.0282 Acc:99.03%
Training: Epoch[021/040] Iteration[110/381] Loss: 0.0543 Acc:99.06%
Training: Epoch[021/040] Iteration[120/381] Loss: 0.0321 Acc:99.06%
Training: Epoch[021/040] Iteration[130/381] Loss: 0.0304 Acc:99.01%
Training: Epoch[021/040] Iteration[140/381] Loss: 0.1032 Acc:99.02%
Training: Epoch[021/040] Iteration[150/381] Loss: 0.0368 Acc:99.06%
Training: Epoch[021/040] Iteration[160/381] Loss: 0.0230 Acc:99.08%
Training: Epoch[021/040] Iteration[170/381] Loss: 0.0111 Acc:99.10%
Training: Epoch[021/040] Iteration[180/381] Loss: 0.0546 Acc:99.10%
Training: Epoch[021/040] Iteration[190/381] Loss: 0.0275 Acc:99.10%
Training: Epoch[021/040] Iteration[200/381] Loss: 0.0086 Acc:99.14%
Training: Epoch[021/040] Iteration[210/381] Loss: 0.0131 Acc:99.15%
Training: Epoch[021/040] Iteration[220/381] Loss: 0.0060 Acc:99.19%
Training: Epoch[021/040] Iteration[230/381] Loss: 0.0071 Acc:99.23%
Training: Epoch[021/040] Iteration[240/381] Loss: 0.0106 Acc:99.23%
Training: Epoch[021/040] Iteration[250/381] Loss: 0.0018 Acc:99.26%
Training: Epoch[021/040] Iteration[260/381] Loss: 0.0008 Acc:99.29%
Training: Epoch[021/040] Iteration[270/381] Loss: 0.0019 Acc:99.32%
Training: Epoch[021/040] Iteration[280/381] Loss: 0.0035 Acc:99.34%
Training: Epoch[021/040] Iteration[290/381] Loss: 0.0042 Acc:99.36%
Training: Epoch[021/040] Iteration[300/381] Loss: 0.0083 Acc:99.36%
Training: Epoch[021/040] Iteration[310/381] Loss: 0.0026 Acc:99.39%
Training: Epoch[021/040] Iteration[320/381] Loss: 0.0029 Acc:99.40%
Training: Epoch[021/040] Iteration[330/381] Loss: 0.0012 Acc:99.42%
Training: Epoch[021/040] Iteration[340/381] Loss: 0.0062 Acc:99.42%
Training: Epoch[021/040] Iteration[350/381] Loss: 0.0076 Acc:99.43%
Training: Epoch[021/040] Iteration[360/381] Loss: 0.0053 Acc:99.44%
Training: Epoch[021/040] Iteration[370/381] Loss: 0.0046 Acc:99.45%
Training: Epoch[021/040] Iteration[380/381] Loss: 0.0061 Acc:99.46%
Valid set Accuracy:87.88%
Training: Epoch[022/040] Iteration[010/381] Loss: 0.0019 Acc:100.00%
Training: Epoch[022/040] Iteration[020/381] Loss: 0.0012 Acc:100.00%
Training: Epoch[022/040] Iteration[030/381] Loss: 0.0008 Acc:100.00%
Training: Epoch[022/040] Iteration[040/381] Loss: 0.0076 Acc:99.92%
Training: Epoch[022/040] Iteration[050/381] Loss: 0.0028 Acc:99.94%
Training: Epoch[022/040] Iteration[060/381] Loss: 0.0079 Acc:99.90%
Training: Epoch[022/040] Iteration[070/381] Loss: 0.0078 Acc:99.87%
Training: Epoch[022/040] Iteration[080/381] Loss: 0.0038 Acc:99.88%
Training: Epoch[022/040] Iteration[090/381] Loss: 0.0221 Acc:99.76%
Training: Epoch[022/040] Iteration[100/381] Loss: 0.0235 Acc:99.69%
Training: Epoch[022/040] Iteration[110/381] Loss: 0.0048 Acc:99.72%
Training: Epoch[022/040] Iteration[120/381] Loss: 0.0108 Acc:99.71%
Training: Epoch[022/040] Iteration[130/381] Loss: 0.0040 Acc:99.74%
Training: Epoch[022/040] Iteration[140/381] Loss: 0.0057 Acc:99.75%
Training: Epoch[022/040] Iteration[150/381] Loss: 0.0034 Acc:99.77%
Training: Epoch[022/040] Iteration[160/381] Loss: 0.0084 Acc:99.75%
Training: Epoch[022/040] Iteration[170/381] Loss: 0.0034 Acc:99.76%
Training: Epoch[022/040] Iteration[180/381] Loss: 0.0083 Acc:99.76%
Training: Epoch[022/040] Iteration[190/381] Loss: 0.0015 Acc:99.77%
Training: Epoch[022/040] Iteration[200/381] Loss: 0.0133 Acc:99.77%
Training: Epoch[022/040] Iteration[210/381] Loss: 0.0119 Acc:99.76%
Training: Epoch[022/040] Iteration[220/381] Loss: 0.0115 Acc:99.76%
Training: Epoch[022/040] Iteration[230/381] Loss: 0.0062 Acc:99.76%
Training: Epoch[022/040] Iteration[240/381] Loss: 0.0396 Acc:99.74%
Training: Epoch[022/040] Iteration[250/381] Loss: 0.0038 Acc:99.75%
Training: Epoch[022/040] Iteration[260/381] Loss: 0.0041 Acc:99.76%
Training: Epoch[022/040] Iteration[270/381] Loss: 0.0366 Acc:99.73%
Training: Epoch[022/040] Iteration[280/381] Loss: 0.0068 Acc:99.72%
Training: Epoch[022/040] Iteration[290/381] Loss: 0.0096 Acc:99.72%
Training: Epoch[022/040] Iteration[300/381] Loss: 0.0238 Acc:99.72%
Training: Epoch[022/040] Iteration[310/381] Loss: 0.0044 Acc:99.73%
Training: Epoch[022/040] Iteration[320/381] Loss: 0.0196 Acc:99.73%
Training: Epoch[022/040] Iteration[330/381] Loss: 0.0506 Acc:99.71%
Training: Epoch[022/040] Iteration[340/381] Loss: 0.0172 Acc:99.71%
Training: Epoch[022/040] Iteration[350/381] Loss: 0.0049 Acc:99.71%
Training: Epoch[022/040] Iteration[360/381] Loss: 0.0044 Acc:99.72%
Training: Epoch[022/040] Iteration[370/381] Loss: 0.0070 Acc:99.73%
Training: Epoch[022/040] Iteration[380/381] Loss: 0.0034 Acc:99.74%
Training: Epoch[023/040] Iteration[010/381] Loss: 0.0008 Acc:100.00%
Training: Epoch[023/040] Iteration[020/381] Loss: 0.0065 Acc:99.84%
Training: Epoch[023/040] Iteration[030/381] Loss: 0.0008 Acc:99.90%
Training: Epoch[023/040] Iteration[040/381] Loss: 0.0040 Acc:99.84%
Training: Epoch[023/040] Iteration[050/381] Loss: 0.0005 Acc:99.88%
Training: Epoch[023/040] Iteration[060/381] Loss: 0.0059 Acc:99.84%
Training: Epoch[023/040] Iteration[070/381] Loss: 0.0124 Acc:99.78%
Training: Epoch[023/040] Iteration[080/381] Loss: 0.0072 Acc:99.77%
Training: Epoch[023/040] Iteration[090/381] Loss: 0.0033 Acc:99.76%
Training: Epoch[023/040] Iteration[100/381] Loss: 0.0008 Acc:99.78%
Training: Epoch[023/040] Iteration[110/381] Loss: 0.0018 Acc:99.80%
Training: Epoch[023/040] Iteration[120/381] Loss: 0.0022 Acc:99.82%
Training: Epoch[023/040] Iteration[130/381] Loss: 0.0039 Acc:99.81%
Training: Epoch[023/040] Iteration[140/381] Loss: 0.0017 Acc:99.82%
Training: Epoch[023/040] Iteration[150/381] Loss: 0.0013 Acc:99.83%
Training: Epoch[023/040] Iteration[160/381] Loss: 0.0428 Acc:99.80%
Training: Epoch[023/040] Iteration[170/381] Loss: 0.0075 Acc:99.80%
Training: Epoch[023/040] Iteration[180/381] Loss: 0.0176 Acc:99.76%
Training: Epoch[023/040] Iteration[190/381] Loss: 0.0187 Acc:99.74%
Training: Epoch[023/040] Iteration[200/381] Loss: 0.0122 Acc:99.73%
Training: Epoch[023/040] Iteration[210/381] Loss: 0.0247 Acc:99.72%
Training: Epoch[023/040] Iteration[220/381] Loss: 0.0157 Acc:99.72%
Training: Epoch[023/040] Iteration[230/381] Loss: 0.0162 Acc:99.71%
Training: Epoch[023/040] Iteration[240/381] Loss: 0.0054 Acc:99.71%
Training: Epoch[023/040] Iteration[250/381] Loss: 0.0131 Acc:99.71%
Training: Epoch[023/040] Iteration[260/381] Loss: 0.0066 Acc:99.71%
Training: Epoch[023/040] Iteration[270/381] Loss: 0.0147 Acc:99.69%
Training: Epoch[023/040] Iteration[280/381] Loss: 0.0094 Acc:99.69%
Training: Epoch[023/040] Iteration[290/381] Loss: 0.0176 Acc:99.68%
Training: Epoch[023/040] Iteration[300/381] Loss: 0.0256 Acc:99.67%
Training: Epoch[023/040] Iteration[310/381] Loss: 0.0224 Acc:99.66%
Training: Epoch[023/040] Iteration[320/381] Loss: 0.0047 Acc:99.67%
Training: Epoch[023/040] Iteration[330/381] Loss: 0.0373 Acc:99.65%
Training: Epoch[023/040] Iteration[340/381] Loss: 0.0154 Acc:99.63%
Training: Epoch[023/040] Iteration[350/381] Loss: 0.0028 Acc:99.64%
Training: Epoch[023/040] Iteration[360/381] Loss: 0.0244 Acc:99.63%
Training: Epoch[023/040] Iteration[370/381] Loss: 0.0164 Acc:99.62%
Training: Epoch[023/040] Iteration[380/381] Loss: 0.0268 Acc:99.61%
Valid set Accuracy:88.55%
Training: Epoch[024/040] Iteration[010/381] Loss: 0.0092 Acc:100.00%
Training: Epoch[024/040] Iteration[020/381] Loss: 0.0024 Acc:100.00%
Training: Epoch[024/040] Iteration[030/381] Loss: 0.0124 Acc:99.90%
Training: Epoch[024/040] Iteration[040/381] Loss: 0.0019 Acc:99.92%
Training: Epoch[024/040] Iteration[050/381] Loss: 0.0049 Acc:99.88%
Training: Epoch[024/040] Iteration[060/381] Loss: 0.0148 Acc:99.79%
Training: Epoch[024/040] Iteration[070/381] Loss: 0.0526 Acc:99.69%
Training: Epoch[024/040] Iteration[080/381] Loss: 0.0015 Acc:99.73%
Training: Epoch[024/040] Iteration[090/381] Loss: 0.0036 Acc:99.76%
Training: Epoch[024/040] Iteration[100/381] Loss: 0.0192 Acc:99.72%
Training: Epoch[024/040] Iteration[110/381] Loss: 0.0450 Acc:99.66%
Training: Epoch[024/040] Iteration[120/381] Loss: 0.0097 Acc:99.66%
Training: Epoch[024/040] Iteration[130/381] Loss: 0.0095 Acc:99.69%
Training: Epoch[024/040] Iteration[140/381] Loss: 0.0074 Acc:99.69%
Training: Epoch[024/040] Iteration[150/381] Loss: 0.0153 Acc:99.69%
Training: Epoch[024/040] Iteration[160/381] Loss: 0.0101 Acc:99.69%
Training: Epoch[024/040] Iteration[170/381] Loss: 0.0019 Acc:99.71%
Training: Epoch[024/040] Iteration[180/381] Loss: 0.0014 Acc:99.72%
Training: Epoch[024/040] Iteration[190/381] Loss: 0.0025 Acc:99.74%
Training: Epoch[024/040] Iteration[200/381] Loss: 0.0056 Acc:99.73%
Training: Epoch[024/040] Iteration[210/381] Loss: 0.0053 Acc:99.73%
Training: Epoch[024/040] Iteration[220/381] Loss: 0.0088 Acc:99.73%
Training: Epoch[024/040] Iteration[230/381] Loss: 0.0006 Acc:99.74%
Training: Epoch[024/040] Iteration[240/381] Loss: 0.0648 Acc:99.71%
Training: Epoch[024/040] Iteration[250/381] Loss: 0.0057 Acc:99.72%
Training: Epoch[024/040] Iteration[260/381] Loss: 0.0066 Acc:99.74%
Training: Epoch[024/040] Iteration[270/381] Loss: 0.0028 Acc:99.75%
Training: Epoch[024/040] Iteration[280/381] Loss: 0.0029 Acc:99.75%
Training: Epoch[024/040] Iteration[290/381] Loss: 0.0039 Acc:99.76%
Training: Epoch[024/040] Iteration[300/381] Loss: 0.0060 Acc:99.76%
Training: Epoch[024/040] Iteration[310/381] Loss: 0.0018 Acc:99.77%
Training: Epoch[024/040] Iteration[320/381] Loss: 0.0163 Acc:99.77%
Training: Epoch[024/040] Iteration[330/381] Loss: 0.0012 Acc:99.77%
Training: Epoch[024/040] Iteration[340/381] Loss: 0.0026 Acc:99.78%
Training: Epoch[024/040] Iteration[350/381] Loss: 0.0047 Acc:99.79%
Training: Epoch[024/040] Iteration[360/381] Loss: 0.0008 Acc:99.79%
Training: Epoch[024/040] Iteration[370/381] Loss: 0.0014 Acc:99.80%
Training: Epoch[024/040] Iteration[380/381] Loss: 0.0013 Acc:99.80%
Training: Epoch[025/040] Iteration[010/381] Loss: 0.0021 Acc:100.00%
Training: Epoch[025/040] Iteration[020/381] Loss: 0.0006 Acc:100.00%
Training: Epoch[025/040] Iteration[030/381] Loss: 0.0009 Acc:100.00%
Training: Epoch[025/040] Iteration[040/381] Loss: 0.0008 Acc:100.00%
Training: Epoch[025/040] Iteration[050/381] Loss: 0.0029 Acc:99.94%
Training: Epoch[025/040] Iteration[060/381] Loss: 0.0007 Acc:99.95%
Training: Epoch[025/040] Iteration[070/381] Loss: 0.0026 Acc:99.96%
Training: Epoch[025/040] Iteration[080/381] Loss: 0.0008 Acc:99.96%
Training: Epoch[025/040] Iteration[090/381] Loss: 0.0302 Acc:99.93%
Training: Epoch[025/040] Iteration[100/381] Loss: 0.0142 Acc:99.91%
Training: Epoch[025/040] Iteration[110/381] Loss: 0.0004 Acc:99.91%
Training: Epoch[025/040] Iteration[120/381] Loss: 0.0025 Acc:99.92%
Training: Epoch[025/040] Iteration[130/381] Loss: 0.0023 Acc:99.93%
Training: Epoch[025/040] Iteration[140/381] Loss: 0.0012 Acc:99.93%
Training: Epoch[025/040] Iteration[150/381] Loss: 0.0008 Acc:99.94%
Training: Epoch[025/040] Iteration[160/381] Loss: 0.0006 Acc:99.94%
Training: Epoch[025/040] Iteration[170/381] Loss: 0.0068 Acc:99.93%
Training: Epoch[025/040] Iteration[180/381] Loss: 0.0011 Acc:99.93%
Training: Epoch[025/040] Iteration[190/381] Loss: 0.0009 Acc:99.93%
Training: Epoch[025/040] Iteration[200/381] Loss: 0.0008 Acc:99.94%
Training: Epoch[025/040] Iteration[210/381] Loss: 0.0059 Acc:99.93%
Training: Epoch[025/040] Iteration[220/381] Loss: 0.0012 Acc:99.93%
Training: Epoch[025/040] Iteration[230/381] Loss: 0.0009 Acc:99.93%
Training: Epoch[025/040] Iteration[240/381] Loss: 0.0003 Acc:99.93%
Training: Epoch[025/040] Iteration[250/381] Loss: 0.0013 Acc:99.94%
Training: Epoch[025/040] Iteration[260/381] Loss: 0.0022 Acc:99.94%
Training: Epoch[025/040] Iteration[270/381] Loss: 0.0005 Acc:99.94%
Training: Epoch[025/040] Iteration[280/381] Loss: 0.0003 Acc:99.94%
Training: Epoch[025/040] Iteration[290/381] Loss: 0.0006 Acc:99.95%
Training: Epoch[025/040] Iteration[300/381] Loss: 0.0002 Acc:99.95%
Training: Epoch[025/040] Iteration[310/381] Loss: 0.0018 Acc:99.95%
Training: Epoch[025/040] Iteration[320/381] Loss: 0.0034 Acc:99.94%
Training: Epoch[025/040] Iteration[330/381] Loss: 0.0004 Acc:99.94%
Training: Epoch[025/040] Iteration[340/381] Loss: 0.0023 Acc:99.94%
Training: Epoch[025/040] Iteration[350/381] Loss: 0.0004 Acc:99.95%
Training: Epoch[025/040] Iteration[360/381] Loss: 0.0004 Acc:99.95%
Training: Epoch[025/040] Iteration[370/381] Loss: 0.0006 Acc:99.95%
Training: Epoch[025/040] Iteration[380/381] Loss: 0.0327 Acc:99.94%
Valid set Accuracy:90.95%
Training: Epoch[026/040] Iteration[010/381] Loss: 0.0005 Acc:100.00%
Training: Epoch[026/040] Iteration[020/381] Loss: 0.0020 Acc:100.00%
Training: Epoch[026/040] Iteration[030/381] Loss: 0.0047 Acc:100.00%
Training: Epoch[026/040] Iteration[040/381] Loss: 0.0010 Acc:100.00%
Training: Epoch[026/040] Iteration[050/381] Loss: 0.0022 Acc:100.00%
Training: Epoch[026/040] Iteration[060/381] Loss: 0.0005 Acc:100.00%
Training: Epoch[026/040] Iteration[070/381] Loss: 0.0017 Acc:100.00%
Training: Epoch[026/040] Iteration[080/381] Loss: 0.0005 Acc:100.00%
Training: Epoch[026/040] Iteration[090/381] Loss: 0.0009 Acc:100.00%
Training: Epoch[026/040] Iteration[100/381] Loss: 0.0004 Acc:100.00%
Training: Epoch[026/040] Iteration[110/381] Loss: 0.0003 Acc:100.00%
Training: Epoch[026/040] Iteration[120/381] Loss: 0.0004 Acc:100.00%
Training: Epoch[026/040] Iteration[130/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[026/040] Iteration[140/381] Loss: 0.0219 Acc:99.98%
Training: Epoch[026/040] Iteration[150/381] Loss: 0.0005 Acc:99.98%
Training: Epoch[026/040] Iteration[160/381] Loss: 0.0002 Acc:99.98%
Training: Epoch[026/040] Iteration[170/381] Loss: 0.0002 Acc:99.98%
Training: Epoch[026/040] Iteration[180/381] Loss: 0.0030 Acc:99.97%
Training: Epoch[026/040] Iteration[190/381] Loss: 0.0005 Acc:99.97%
Training: Epoch[026/040] Iteration[200/381] Loss: 0.0010 Acc:99.97%
Training: Epoch[026/040] Iteration[210/381] Loss: 0.0004 Acc:99.97%
Training: Epoch[026/040] Iteration[220/381] Loss: 0.0038 Acc:99.97%
Training: Epoch[026/040] Iteration[230/381] Loss: 0.0002 Acc:99.97%
Training: Epoch[026/040] Iteration[240/381] Loss: 0.0004 Acc:99.97%
Training: Epoch[026/040] Iteration[250/381] Loss: 0.0074 Acc:99.96%
Training: Epoch[026/040] Iteration[260/381] Loss: 0.0001 Acc:99.96%
Training: Epoch[026/040] Iteration[270/381] Loss: 0.0003 Acc:99.97%
Training: Epoch[026/040] Iteration[280/381] Loss: 0.0008 Acc:99.97%
Training: Epoch[026/040] Iteration[290/381] Loss: 0.0005 Acc:99.97%
Training: Epoch[026/040] Iteration[300/381] Loss: 0.0002 Acc:99.97%
Training: Epoch[026/040] Iteration[310/381] Loss: 0.0003 Acc:99.97%
Training: Epoch[026/040] Iteration[320/381] Loss: 0.0006 Acc:99.97%
Training: Epoch[026/040] Iteration[330/381] Loss: 0.0002 Acc:99.97%
Training: Epoch[026/040] Iteration[340/381] Loss: 0.0002 Acc:99.97%
Training: Epoch[026/040] Iteration[350/381] Loss: 0.0002 Acc:99.97%
Training: Epoch[026/040] Iteration[360/381] Loss: 0.0002 Acc:99.97%
Training: Epoch[026/040] Iteration[370/381] Loss: 0.0004 Acc:99.97%
Training: Epoch[026/040] Iteration[380/381] Loss: 0.0001 Acc:99.98%
Training: Epoch[027/040] Iteration[010/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[027/040] Iteration[020/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[027/040] Iteration[030/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[027/040] Iteration[040/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[027/040] Iteration[050/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[027/040] Iteration[060/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[027/040] Iteration[070/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[027/040] Iteration[080/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[027/040] Iteration[090/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[027/040] Iteration[100/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[027/040] Iteration[110/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[027/040] Iteration[120/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[027/040] Iteration[130/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[027/040] Iteration[140/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[027/040] Iteration[150/381] Loss: 0.0194 Acc:99.98%
Training: Epoch[027/040] Iteration[160/381] Loss: 0.0007 Acc:99.98%
Training: Epoch[027/040] Iteration[170/381] Loss: 0.0004 Acc:99.98%
Training: Epoch[027/040] Iteration[180/381] Loss: 0.0018 Acc:99.98%
Training: Epoch[027/040] Iteration[190/381] Loss: 0.0011 Acc:99.98%
Training: Epoch[027/040] Iteration[200/381] Loss: 0.0009 Acc:99.98%
Training: Epoch[027/040] Iteration[210/381] Loss: 0.0019 Acc:99.99%
Training: Epoch[027/040] Iteration[220/381] Loss: 0.0166 Acc:99.97%
Training: Epoch[027/040] Iteration[230/381] Loss: 0.0003 Acc:99.97%
Training: Epoch[027/040] Iteration[240/381] Loss: 0.0002 Acc:99.97%
Training: Epoch[027/040] Iteration[250/381] Loss: 0.0004 Acc:99.98%
Training: Epoch[027/040] Iteration[260/381] Loss: 0.0017 Acc:99.98%
Training: Epoch[027/040] Iteration[270/381] Loss: 0.0005 Acc:99.98%
Training: Epoch[027/040] Iteration[280/381] Loss: 0.0022 Acc:99.98%
Training: Epoch[027/040] Iteration[290/381] Loss: 0.0003 Acc:99.98%
Training: Epoch[027/040] Iteration[300/381] Loss: 0.0001 Acc:99.98%
Training: Epoch[027/040] Iteration[310/381] Loss: 0.0002 Acc:99.98%
Training: Epoch[027/040] Iteration[320/381] Loss: 0.0002 Acc:99.98%
Training: Epoch[027/040] Iteration[330/381] Loss: 0.0002 Acc:99.98%
Training: Epoch[027/040] Iteration[340/381] Loss: 0.0002 Acc:99.98%
Training: Epoch[027/040] Iteration[350/381] Loss: 0.0001 Acc:99.98%
Training: Epoch[027/040] Iteration[360/381] Loss: 0.0001 Acc:99.98%
Training: Epoch[027/040] Iteration[370/381] Loss: 0.0007 Acc:99.98%
Training: Epoch[027/040] Iteration[380/381] Loss: 0.0001 Acc:99.98%
Valid set Accuracy:90.28%
Training: Epoch[028/040] Iteration[010/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[020/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[030/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[028/040] Iteration[040/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[050/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[060/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[028/040] Iteration[070/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[080/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[090/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[100/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[028/040] Iteration[110/381] Loss: 0.0003 Acc:100.00%
Training: Epoch[028/040] Iteration[120/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[028/040] Iteration[130/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[140/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[150/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[160/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[170/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[180/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[028/040] Iteration[190/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[200/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[210/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[028/040] Iteration[220/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[028/040] Iteration[230/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[240/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[250/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[260/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[270/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[280/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[290/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[028/040] Iteration[300/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[310/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[320/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[330/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[340/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[028/040] Iteration[350/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/040] Iteration[360/381] Loss: 0.0006 Acc:100.00%
Training: Epoch[028/040] Iteration[370/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[028/040] Iteration[380/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/040] Iteration[010/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[029/040] Iteration[020/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/040] Iteration[030/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/040] Iteration[040/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/040] Iteration[050/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/040] Iteration[060/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/040] Iteration[070/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[029/040] Iteration[080/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/040] Iteration[090/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[029/040] Iteration[100/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[029/040] Iteration[110/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[029/040] Iteration[120/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[029/040] Iteration[130/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/040] Iteration[140/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[029/040] Iteration[150/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[029/040] Iteration[160/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/040] Iteration[170/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/040] Iteration[180/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[029/040] Iteration[190/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/040] Iteration[200/381] Loss: 0.0005 Acc:100.00%
Training: Epoch[029/040] Iteration[210/381] Loss: 0.0007 Acc:100.00%
Training: Epoch[029/040] Iteration[220/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/040] Iteration[230/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[029/040] Iteration[240/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/040] Iteration[250/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[029/040] Iteration[260/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[029/040] Iteration[270/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/040] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[029/040] Iteration[290/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/040] Iteration[300/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/040] Iteration[310/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/040] Iteration[320/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/040] Iteration[330/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/040] Iteration[340/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[029/040] Iteration[350/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[029/040] Iteration[360/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/040] Iteration[370/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/040] Iteration[380/381] Loss: 0.0001 Acc:100.00%
Valid set Accuracy:91.34%
Training: Epoch[030/040] Iteration[010/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/040] Iteration[020/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/040] Iteration[030/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/040] Iteration[040/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/040] Iteration[050/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/040] Iteration[060/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/040] Iteration[070/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/040] Iteration[080/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/040] Iteration[090/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/040] Iteration[100/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/040] Iteration[110/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/040] Iteration[120/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/040] Iteration[130/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/040] Iteration[140/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/040] Iteration[150/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/040] Iteration[160/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[030/040] Iteration[170/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/040] Iteration[180/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/040] Iteration[190/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/040] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/040] Iteration[210/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/040] Iteration[220/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/040] Iteration[230/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/040] Iteration[240/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/040] Iteration[250/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/040] Iteration[260/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/040] Iteration[270/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/040] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/040] Iteration[290/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/040] Iteration[300/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[030/040] Iteration[310/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/040] Iteration[320/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/040] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/040] Iteration[340/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/040] Iteration[350/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/040] Iteration[360/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/040] Iteration[370/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/040] Iteration[380/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[010/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/040] Iteration[020/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/040] Iteration[030/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[040/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[050/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/040] Iteration[060/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/040] Iteration[070/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[080/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/040] Iteration[090/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[100/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[110/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[120/381] Loss: 0.0003 Acc:100.00%
Training: Epoch[031/040] Iteration[130/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[140/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[150/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[160/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[170/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[180/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/040] Iteration[190/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[210/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[220/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[230/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[240/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[250/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/040] Iteration[260/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[270/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[290/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/040] Iteration[300/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[310/381] Loss: 0.0003 Acc:100.00%
Training: Epoch[031/040] Iteration[320/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[340/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[350/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[360/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/040] Iteration[370/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/040] Iteration[380/381] Loss: 0.0000 Acc:100.00%
Valid set Accuracy:92.01%
Training: Epoch[032/040] Iteration[010/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[020/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[030/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[040/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[050/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[060/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[070/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[032/040] Iteration[080/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[090/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[032/040] Iteration[100/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[110/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[032/040] Iteration[120/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[032/040] Iteration[130/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[140/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[150/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[160/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[170/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[180/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[032/040] Iteration[190/381] Loss: 0.0003 Acc:100.00%
Training: Epoch[032/040] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[210/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[220/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[230/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[240/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[250/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[260/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[270/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[290/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[300/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[310/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[320/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[340/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[350/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[032/040] Iteration[360/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[370/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/040] Iteration[380/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[010/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[020/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[030/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[040/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[033/040] Iteration[050/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[060/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[070/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[033/040] Iteration[080/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[090/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[100/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[110/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[120/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[130/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[033/040] Iteration[140/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[150/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[160/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[170/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[180/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[190/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[033/040] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[210/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[220/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[230/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[240/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[250/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[033/040] Iteration[260/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[270/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[290/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[300/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[310/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[320/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[340/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[350/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[033/040] Iteration[360/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[370/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/040] Iteration[380/381] Loss: 0.0000 Acc:100.00%
Valid set Accuracy:92.14%
Training: Epoch[034/040] Iteration[010/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[020/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[030/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[040/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[050/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[034/040] Iteration[060/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[070/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[080/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[090/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[100/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[110/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[120/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[130/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[140/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[034/040] Iteration[150/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[160/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[170/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[180/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[190/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[210/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[220/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[230/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[240/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[034/040] Iteration[250/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[260/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[270/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[290/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[300/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[310/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[320/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[340/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[350/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[360/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[370/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/040] Iteration[380/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[010/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[020/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[035/040] Iteration[030/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[040/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[050/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[060/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[070/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[080/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[090/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[100/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[110/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[120/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[130/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[140/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[150/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[035/040] Iteration[160/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[170/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[180/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[190/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[210/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[220/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[230/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[240/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[035/040] Iteration[250/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[260/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[270/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[290/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[300/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[310/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[320/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[340/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[350/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[360/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[370/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/040] Iteration[380/381] Loss: 0.0000 Acc:100.00%
Valid set Accuracy:92.14%
Training: Epoch[036/040] Iteration[010/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[020/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[030/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[040/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[050/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[060/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[070/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[080/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[036/040] Iteration[090/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[100/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[110/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[120/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[130/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[140/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[150/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[160/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[170/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[180/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[190/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[210/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[220/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[230/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[240/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[250/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[260/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[270/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[290/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[300/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[310/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[320/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[340/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[350/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[360/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[370/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/040] Iteration[380/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[010/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[020/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[030/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[040/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[050/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[060/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[070/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[080/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[090/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[100/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[110/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[120/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[130/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[140/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[150/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[160/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[170/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[180/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[190/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[210/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[220/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[230/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[240/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[250/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[260/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[270/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[290/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[300/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[310/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[320/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[340/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[350/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[360/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[370/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/040] Iteration[380/381] Loss: 0.0000 Acc:100.00%
Valid set Accuracy:92.01%
Training: Epoch[038/040] Iteration[010/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[020/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[030/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[040/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[050/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[060/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[038/040] Iteration[070/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[080/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[090/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[100/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[110/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[120/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[130/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[140/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[150/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[160/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[038/040] Iteration[170/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[180/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[190/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[210/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[220/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[230/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[240/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[250/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[260/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[270/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[290/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[300/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[310/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[320/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[340/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[350/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[360/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[370/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/040] Iteration[380/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[010/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[020/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[030/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[040/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[050/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[060/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[070/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[080/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[090/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[100/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[110/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[120/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[130/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[140/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[150/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[160/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[170/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[180/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[190/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[210/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[220/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[230/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[240/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[039/040] Iteration[250/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[260/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[270/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[290/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[300/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[310/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[320/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[340/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[350/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[360/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[370/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/040] Iteration[380/381] Loss: 0.0000 Acc:100.00%
Valid set Accuracy:92.01%
Training: Epoch[040/040] Iteration[010/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[020/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[030/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[040/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[050/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[060/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[070/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[080/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[090/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[100/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[110/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[120/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[130/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[140/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[150/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[160/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[170/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[180/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[190/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[210/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[220/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[230/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[240/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[250/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[260/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[270/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[280/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[040/040] Iteration[290/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[300/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[310/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[320/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[340/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[350/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[360/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[370/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/040] Iteration[380/381] Loss: 0.0000 Acc:100.00%
