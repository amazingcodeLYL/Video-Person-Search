Training: Epoch[001/100] Iteration[010/381] Loss: 6.6227 Acc:0.31%
Training: Epoch[001/100] Iteration[020/381] Loss: 6.6209 Acc:0.31%
Training: Epoch[001/100] Iteration[030/381] Loss: 6.6164 Acc:0.42%
Training: Epoch[001/100] Iteration[040/381] Loss: 6.6110 Acc:0.47%
Training: Epoch[001/100] Iteration[050/381] Loss: 6.6089 Acc:0.62%
Training: Epoch[001/100] Iteration[060/381] Loss: 6.6053 Acc:0.94%
Training: Epoch[001/100] Iteration[070/381] Loss: 6.6005 Acc:1.25%
Training: Epoch[001/100] Iteration[080/381] Loss: 6.5958 Acc:1.45%
Training: Epoch[001/100] Iteration[090/381] Loss: 6.5875 Acc:1.60%
Training: Epoch[001/100] Iteration[100/381] Loss: 6.5912 Acc:1.66%
Training: Epoch[001/100] Iteration[110/381] Loss: 6.5796 Acc:1.88%
Training: Epoch[001/100] Iteration[120/381] Loss: 6.5751 Acc:1.90%
Training: Epoch[001/100] Iteration[130/381] Loss: 6.5739 Acc:2.19%
Training: Epoch[001/100] Iteration[140/381] Loss: 6.5711 Acc:2.28%
Training: Epoch[001/100] Iteration[150/381] Loss: 6.5557 Acc:2.54%
Training: Epoch[001/100] Iteration[160/381] Loss: 6.5616 Acc:2.66%
Training: Epoch[001/100] Iteration[170/381] Loss: 6.5564 Acc:2.89%
Training: Epoch[001/100] Iteration[180/381] Loss: 6.5484 Acc:3.04%
Training: Epoch[001/100] Iteration[190/381] Loss: 6.5506 Acc:3.11%
Training: Epoch[001/100] Iteration[200/381] Loss: 6.5391 Acc:3.27%
Training: Epoch[001/100] Iteration[210/381] Loss: 6.5306 Acc:3.38%
Training: Epoch[001/100] Iteration[220/381] Loss: 6.5224 Acc:3.57%
Training: Epoch[001/100] Iteration[230/381] Loss: 6.5165 Acc:3.78%
Training: Epoch[001/100] Iteration[240/381] Loss: 6.5095 Acc:3.98%
Training: Epoch[001/100] Iteration[250/381] Loss: 6.5090 Acc:4.10%
Training: Epoch[001/100] Iteration[260/381] Loss: 6.5103 Acc:4.22%
Training: Epoch[001/100] Iteration[270/381] Loss: 6.4905 Acc:4.40%
Training: Epoch[001/100] Iteration[280/381] Loss: 6.4861 Acc:4.60%
Training: Epoch[001/100] Iteration[290/381] Loss: 6.4808 Acc:4.75%
Training: Epoch[001/100] Iteration[300/381] Loss: 6.4567 Acc:4.89%
Training: Epoch[001/100] Iteration[310/381] Loss: 6.4520 Acc:5.08%
Training: Epoch[001/100] Iteration[320/381] Loss: 6.4495 Acc:5.29%
Training: Epoch[001/100] Iteration[330/381] Loss: 6.4571 Acc:5.43%
Training: Epoch[001/100] Iteration[340/381] Loss: 6.4347 Acc:5.57%
Training: Epoch[001/100] Iteration[350/381] Loss: 6.4115 Acc:5.71%
Training: Epoch[001/100] Iteration[360/381] Loss: 6.4227 Acc:5.82%
Training: Epoch[001/100] Iteration[370/381] Loss: 6.4046 Acc:5.88%
Training: Epoch[001/100] Iteration[380/381] Loss: 6.3948 Acc:6.04%
Valid set Accuracy:5.33%
Training: Epoch[002/100] Iteration[010/381] Loss: 6.2967 Acc:12.81%
Training: Epoch[002/100] Iteration[020/381] Loss: 6.0707 Acc:9.84%
Training: Epoch[002/100] Iteration[030/381] Loss: 5.7234 Acc:7.81%
Training: Epoch[002/100] Iteration[040/381] Loss: 5.1450 Acc:8.98%
Training: Epoch[002/100] Iteration[050/381] Loss: 5.1732 Acc:9.06%
Training: Epoch[002/100] Iteration[060/381] Loss: 4.5486 Acc:10.16%
Training: Epoch[002/100] Iteration[070/381] Loss: 4.4538 Acc:11.38%
Training: Epoch[002/100] Iteration[080/381] Loss: 4.2412 Acc:12.38%
Training: Epoch[002/100] Iteration[090/381] Loss: 3.9992 Acc:13.16%
Training: Epoch[002/100] Iteration[100/381] Loss: 4.0350 Acc:13.88%
Training: Epoch[002/100] Iteration[110/381] Loss: 3.7605 Acc:15.14%
Training: Epoch[002/100] Iteration[120/381] Loss: 3.5616 Acc:16.35%
Training: Epoch[002/100] Iteration[130/381] Loss: 3.6777 Acc:17.26%
Training: Epoch[002/100] Iteration[140/381] Loss: 2.8620 Acc:19.00%
Training: Epoch[002/100] Iteration[150/381] Loss: 3.1658 Acc:19.94%
Training: Epoch[002/100] Iteration[160/381] Loss: 2.7984 Acc:21.07%
Training: Epoch[002/100] Iteration[170/381] Loss: 2.9010 Acc:22.13%
Training: Epoch[002/100] Iteration[180/381] Loss: 2.9032 Acc:23.12%
Training: Epoch[002/100] Iteration[190/381] Loss: 2.5409 Acc:24.23%
Training: Epoch[002/100] Iteration[200/381] Loss: 2.3742 Acc:25.41%
Training: Epoch[002/100] Iteration[210/381] Loss: 2.3322 Acc:26.49%
Training: Epoch[002/100] Iteration[220/381] Loss: 2.2562 Acc:27.59%
Training: Epoch[002/100] Iteration[230/381] Loss: 2.3162 Acc:28.51%
Training: Epoch[002/100] Iteration[240/381] Loss: 2.3734 Acc:29.27%
Training: Epoch[002/100] Iteration[250/381] Loss: 2.2984 Acc:30.05%
Training: Epoch[002/100] Iteration[260/381] Loss: 2.4258 Acc:30.66%
Training: Epoch[002/100] Iteration[270/381] Loss: 2.1726 Acc:31.49%
Training: Epoch[002/100] Iteration[280/381] Loss: 1.7624 Acc:32.48%
Training: Epoch[002/100] Iteration[290/381] Loss: 1.6427 Acc:33.37%
Training: Epoch[002/100] Iteration[300/381] Loss: 2.0505 Acc:34.05%
Training: Epoch[002/100] Iteration[310/381] Loss: 2.0345 Acc:34.66%
Training: Epoch[002/100] Iteration[320/381] Loss: 1.9756 Acc:35.19%
Training: Epoch[002/100] Iteration[330/381] Loss: 1.6461 Acc:35.92%
Training: Epoch[002/100] Iteration[340/381] Loss: 1.6840 Acc:36.54%
Training: Epoch[002/100] Iteration[350/381] Loss: 1.5651 Acc:37.29%
Training: Epoch[002/100] Iteration[360/381] Loss: 1.4196 Acc:38.01%
Training: Epoch[002/100] Iteration[370/381] Loss: 1.7578 Acc:38.63%
Training: Epoch[002/100] Iteration[380/381] Loss: 1.5084 Acc:39.28%
Training: Epoch[003/100] Iteration[010/381] Loss: 0.9593 Acc:75.31%
Training: Epoch[003/100] Iteration[020/381] Loss: 1.0992 Acc:73.59%
Training: Epoch[003/100] Iteration[030/381] Loss: 1.1105 Acc:72.71%
Training: Epoch[003/100] Iteration[040/381] Loss: 0.9457 Acc:73.28%
Training: Epoch[003/100] Iteration[050/381] Loss: 0.9672 Acc:73.38%
Training: Epoch[003/100] Iteration[060/381] Loss: 1.1202 Acc:73.39%
Training: Epoch[003/100] Iteration[070/381] Loss: 0.8428 Acc:74.15%
Training: Epoch[003/100] Iteration[080/381] Loss: 1.1171 Acc:73.71%
Training: Epoch[003/100] Iteration[090/381] Loss: 1.1492 Acc:73.23%
Training: Epoch[003/100] Iteration[100/381] Loss: 0.8611 Acc:73.72%
Training: Epoch[003/100] Iteration[110/381] Loss: 1.0165 Acc:73.92%
Training: Epoch[003/100] Iteration[120/381] Loss: 1.0002 Acc:73.91%
Training: Epoch[003/100] Iteration[130/381] Loss: 1.0132 Acc:74.01%
Training: Epoch[003/100] Iteration[140/381] Loss: 0.9127 Acc:74.06%
Training: Epoch[003/100] Iteration[150/381] Loss: 0.7601 Acc:74.54%
Training: Epoch[003/100] Iteration[160/381] Loss: 1.1375 Acc:74.45%
Training: Epoch[003/100] Iteration[170/381] Loss: 0.9581 Acc:74.58%
Training: Epoch[003/100] Iteration[180/381] Loss: 0.9984 Acc:74.55%
Training: Epoch[003/100] Iteration[190/381] Loss: 0.8659 Acc:74.61%
Training: Epoch[003/100] Iteration[200/381] Loss: 1.1224 Acc:74.48%
Training: Epoch[003/100] Iteration[210/381] Loss: 0.9311 Acc:74.60%
Training: Epoch[003/100] Iteration[220/381] Loss: 0.8669 Acc:74.72%
Training: Epoch[003/100] Iteration[230/381] Loss: 0.8601 Acc:74.86%
Training: Epoch[003/100] Iteration[240/381] Loss: 0.9418 Acc:74.87%
Training: Epoch[003/100] Iteration[250/381] Loss: 0.8451 Acc:74.91%
Training: Epoch[003/100] Iteration[260/381] Loss: 0.8413 Acc:75.04%
Training: Epoch[003/100] Iteration[270/381] Loss: 0.8917 Acc:75.07%
Training: Epoch[003/100] Iteration[280/381] Loss: 1.0628 Acc:75.00%
Training: Epoch[003/100] Iteration[290/381] Loss: 0.6117 Acc:75.32%
Training: Epoch[003/100] Iteration[300/381] Loss: 0.8254 Acc:75.54%
Training: Epoch[003/100] Iteration[310/381] Loss: 0.9644 Acc:75.43%
Training: Epoch[003/100] Iteration[320/381] Loss: 0.6995 Acc:75.59%
Training: Epoch[003/100] Iteration[330/381] Loss: 0.7688 Acc:75.62%
Training: Epoch[003/100] Iteration[340/381] Loss: 0.7831 Acc:75.69%
Training: Epoch[003/100] Iteration[350/381] Loss: 0.8760 Acc:75.71%
Training: Epoch[003/100] Iteration[360/381] Loss: 0.9275 Acc:75.76%
Training: Epoch[003/100] Iteration[370/381] Loss: 0.7300 Acc:75.96%
Training: Epoch[003/100] Iteration[380/381] Loss: 0.6852 Acc:76.09%
Valid set Accuracy:72.04%
Training: Epoch[004/100] Iteration[010/381] Loss: 0.4624 Acc:88.12%
Training: Epoch[004/100] Iteration[020/381] Loss: 0.3841 Acc:88.59%
Training: Epoch[004/100] Iteration[030/381] Loss: 0.4597 Acc:88.85%
Training: Epoch[004/100] Iteration[040/381] Loss: 0.3575 Acc:88.67%
Training: Epoch[004/100] Iteration[050/381] Loss: 0.4634 Acc:88.50%
Training: Epoch[004/100] Iteration[060/381] Loss: 0.3847 Acc:88.54%
Training: Epoch[004/100] Iteration[070/381] Loss: 0.3050 Acc:88.93%
Training: Epoch[004/100] Iteration[080/381] Loss: 0.4991 Acc:88.71%
Training: Epoch[004/100] Iteration[090/381] Loss: 0.4363 Acc:88.51%
Training: Epoch[004/100] Iteration[100/381] Loss: 0.5103 Acc:88.19%
Training: Epoch[004/100] Iteration[110/381] Loss: 0.3277 Acc:88.35%
Training: Epoch[004/100] Iteration[120/381] Loss: 0.4502 Acc:88.18%
Training: Epoch[004/100] Iteration[130/381] Loss: 0.3876 Acc:88.03%
Training: Epoch[004/100] Iteration[140/381] Loss: 0.3492 Acc:88.21%
Training: Epoch[004/100] Iteration[150/381] Loss: 0.4583 Acc:88.08%
Training: Epoch[004/100] Iteration[160/381] Loss: 0.4566 Acc:87.97%
Training: Epoch[004/100] Iteration[170/381] Loss: 0.3971 Acc:88.01%
Training: Epoch[004/100] Iteration[180/381] Loss: 0.4722 Acc:87.92%
Training: Epoch[004/100] Iteration[190/381] Loss: 0.4544 Acc:87.98%
Training: Epoch[004/100] Iteration[200/381] Loss: 0.4069 Acc:88.00%
Training: Epoch[004/100] Iteration[210/381] Loss: 0.4173 Acc:88.04%
Training: Epoch[004/100] Iteration[220/381] Loss: 0.5631 Acc:87.91%
Training: Epoch[004/100] Iteration[230/381] Loss: 0.4813 Acc:87.76%
Training: Epoch[004/100] Iteration[240/381] Loss: 0.5715 Acc:87.63%
Training: Epoch[004/100] Iteration[250/381] Loss: 0.3701 Acc:87.70%
Training: Epoch[004/100] Iteration[260/381] Loss: 0.3159 Acc:87.78%
Training: Epoch[004/100] Iteration[270/381] Loss: 0.4351 Acc:87.75%
Training: Epoch[004/100] Iteration[280/381] Loss: 0.5590 Acc:87.66%
Training: Epoch[004/100] Iteration[290/381] Loss: 0.4346 Acc:87.64%
Training: Epoch[004/100] Iteration[300/381] Loss: 0.4649 Acc:87.67%
Training: Epoch[004/100] Iteration[310/381] Loss: 0.5035 Acc:87.60%
Training: Epoch[004/100] Iteration[320/381] Loss: 0.4455 Acc:87.64%
Training: Epoch[004/100] Iteration[330/381] Loss: 0.3398 Acc:87.76%
Training: Epoch[004/100] Iteration[340/381] Loss: 0.3040 Acc:87.84%
Training: Epoch[004/100] Iteration[350/381] Loss: 0.3601 Acc:87.94%
Training: Epoch[004/100] Iteration[360/381] Loss: 0.3661 Acc:87.96%
Training: Epoch[004/100] Iteration[370/381] Loss: 0.5014 Acc:87.96%
Training: Epoch[004/100] Iteration[380/381] Loss: 0.4077 Acc:88.03%
Training: Epoch[005/100] Iteration[010/381] Loss: 0.2784 Acc:92.19%
Training: Epoch[005/100] Iteration[020/381] Loss: 0.1639 Acc:93.75%
Training: Epoch[005/100] Iteration[030/381] Loss: 0.3116 Acc:93.44%
Training: Epoch[005/100] Iteration[040/381] Loss: 0.2576 Acc:93.12%
Training: Epoch[005/100] Iteration[050/381] Loss: 0.2499 Acc:93.25%
Training: Epoch[005/100] Iteration[060/381] Loss: 0.2039 Acc:93.44%
Training: Epoch[005/100] Iteration[070/381] Loss: 0.1223 Acc:93.97%
Training: Epoch[005/100] Iteration[080/381] Loss: 0.2857 Acc:93.63%
Training: Epoch[005/100] Iteration[090/381] Loss: 0.2150 Acc:93.51%
Training: Epoch[005/100] Iteration[100/381] Loss: 0.3452 Acc:93.12%
Training: Epoch[005/100] Iteration[110/381] Loss: 0.3383 Acc:92.87%
Training: Epoch[005/100] Iteration[120/381] Loss: 0.3401 Acc:92.58%
Training: Epoch[005/100] Iteration[130/381] Loss: 0.2537 Acc:92.52%
Training: Epoch[005/100] Iteration[140/381] Loss: 0.2907 Acc:92.48%
Training: Epoch[005/100] Iteration[150/381] Loss: 0.3555 Acc:92.23%
Training: Epoch[005/100] Iteration[160/381] Loss: 0.3869 Acc:92.03%
Training: Epoch[005/100] Iteration[170/381] Loss: 0.2761 Acc:92.06%
Training: Epoch[005/100] Iteration[180/381] Loss: 0.3073 Acc:91.91%
Training: Epoch[005/100] Iteration[190/381] Loss: 0.3153 Acc:91.76%
Training: Epoch[005/100] Iteration[200/381] Loss: 0.2309 Acc:91.77%
Training: Epoch[005/100] Iteration[210/381] Loss: 0.2476 Acc:91.77%
Training: Epoch[005/100] Iteration[220/381] Loss: 0.2395 Acc:91.85%
Training: Epoch[005/100] Iteration[230/381] Loss: 0.1796 Acc:92.00%
Training: Epoch[005/100] Iteration[240/381] Loss: 0.2599 Acc:91.98%
Training: Epoch[005/100] Iteration[250/381] Loss: 0.2557 Acc:92.06%
Training: Epoch[005/100] Iteration[260/381] Loss: 0.1988 Acc:92.14%
Training: Epoch[005/100] Iteration[270/381] Loss: 0.2729 Acc:92.13%
Training: Epoch[005/100] Iteration[280/381] Loss: 0.3092 Acc:92.14%
Training: Epoch[005/100] Iteration[290/381] Loss: 0.3216 Acc:92.13%
Training: Epoch[005/100] Iteration[300/381] Loss: 0.2928 Acc:92.11%
Training: Epoch[005/100] Iteration[310/381] Loss: 0.3017 Acc:92.11%
Training: Epoch[005/100] Iteration[320/381] Loss: 0.2905 Acc:92.08%
Training: Epoch[005/100] Iteration[330/381] Loss: 0.2108 Acc:92.09%
Training: Epoch[005/100] Iteration[340/381] Loss: 0.2142 Acc:92.08%
Training: Epoch[005/100] Iteration[350/381] Loss: 0.2733 Acc:92.07%
Training: Epoch[005/100] Iteration[360/381] Loss: 0.2831 Acc:92.04%
Training: Epoch[005/100] Iteration[370/381] Loss: 0.2377 Acc:92.08%
Training: Epoch[005/100] Iteration[380/381] Loss: 0.1533 Acc:92.16%
Valid set Accuracy:79.63%
Training: Epoch[006/100] Iteration[010/381] Loss: 0.2541 Acc:92.19%
Training: Epoch[006/100] Iteration[020/381] Loss: 0.1460 Acc:93.75%
Training: Epoch[006/100] Iteration[030/381] Loss: 0.1973 Acc:93.33%
Training: Epoch[006/100] Iteration[040/381] Loss: 0.2215 Acc:93.75%
Training: Epoch[006/100] Iteration[050/381] Loss: 0.1121 Acc:94.62%
Training: Epoch[006/100] Iteration[060/381] Loss: 0.1659 Acc:94.53%
Training: Epoch[006/100] Iteration[070/381] Loss: 0.1809 Acc:94.60%
Training: Epoch[006/100] Iteration[080/381] Loss: 0.2423 Acc:94.22%
Training: Epoch[006/100] Iteration[090/381] Loss: 0.2679 Acc:93.99%
Training: Epoch[006/100] Iteration[100/381] Loss: 0.3278 Acc:93.72%
Training: Epoch[006/100] Iteration[110/381] Loss: 0.1806 Acc:93.78%
Training: Epoch[006/100] Iteration[120/381] Loss: 0.1800 Acc:93.85%
Training: Epoch[006/100] Iteration[130/381] Loss: 0.1955 Acc:93.87%
Training: Epoch[006/100] Iteration[140/381] Loss: 0.1720 Acc:93.88%
Training: Epoch[006/100] Iteration[150/381] Loss: 0.1548 Acc:94.08%
Training: Epoch[006/100] Iteration[160/381] Loss: 0.2059 Acc:94.02%
Training: Epoch[006/100] Iteration[170/381] Loss: 0.1505 Acc:94.12%
Training: Epoch[006/100] Iteration[180/381] Loss: 0.1508 Acc:94.18%
Training: Epoch[006/100] Iteration[190/381] Loss: 0.2070 Acc:94.18%
Training: Epoch[006/100] Iteration[200/381] Loss: 0.1744 Acc:94.27%
Training: Epoch[006/100] Iteration[210/381] Loss: 0.1248 Acc:94.33%
Training: Epoch[006/100] Iteration[220/381] Loss: 0.2536 Acc:94.29%
Training: Epoch[006/100] Iteration[230/381] Loss: 0.2096 Acc:94.33%
Training: Epoch[006/100] Iteration[240/381] Loss: 0.1592 Acc:94.38%
Training: Epoch[006/100] Iteration[250/381] Loss: 0.1367 Acc:94.49%
Training: Epoch[006/100] Iteration[260/381] Loss: 0.2023 Acc:94.48%
Training: Epoch[006/100] Iteration[270/381] Loss: 0.3274 Acc:94.40%
Training: Epoch[006/100] Iteration[280/381] Loss: 0.2180 Acc:94.38%
Training: Epoch[006/100] Iteration[290/381] Loss: 0.1923 Acc:94.34%
Training: Epoch[006/100] Iteration[300/381] Loss: 0.1772 Acc:94.35%
Training: Epoch[006/100] Iteration[310/381] Loss: 0.1217 Acc:94.39%
Training: Epoch[006/100] Iteration[320/381] Loss: 0.1907 Acc:94.39%
Training: Epoch[006/100] Iteration[330/381] Loss: 0.1989 Acc:94.39%
Training: Epoch[006/100] Iteration[340/381] Loss: 0.1959 Acc:94.42%
Training: Epoch[006/100] Iteration[350/381] Loss: 0.1906 Acc:94.41%
Training: Epoch[006/100] Iteration[360/381] Loss: 0.1149 Acc:94.44%
Training: Epoch[006/100] Iteration[370/381] Loss: 0.1152 Acc:94.48%
Training: Epoch[006/100] Iteration[380/381] Loss: 0.2213 Acc:94.44%
Training: Epoch[007/100] Iteration[010/381] Loss: 0.1980 Acc:93.12%
Training: Epoch[007/100] Iteration[020/381] Loss: 0.1136 Acc:95.16%
Training: Epoch[007/100] Iteration[030/381] Loss: 0.1297 Acc:95.62%
Training: Epoch[007/100] Iteration[040/381] Loss: 0.0662 Acc:96.41%
Training: Epoch[007/100] Iteration[050/381] Loss: 0.1129 Acc:96.38%
Training: Epoch[007/100] Iteration[060/381] Loss: 0.1088 Acc:96.30%
Training: Epoch[007/100] Iteration[070/381] Loss: 0.1131 Acc:96.16%
Training: Epoch[007/100] Iteration[080/381] Loss: 0.1562 Acc:96.05%
Training: Epoch[007/100] Iteration[090/381] Loss: 0.1401 Acc:96.01%
Training: Epoch[007/100] Iteration[100/381] Loss: 0.1918 Acc:96.06%
Training: Epoch[007/100] Iteration[110/381] Loss: 0.1027 Acc:96.19%
Training: Epoch[007/100] Iteration[120/381] Loss: 0.0875 Acc:96.35%
Training: Epoch[007/100] Iteration[130/381] Loss: 0.0988 Acc:96.44%
Training: Epoch[007/100] Iteration[140/381] Loss: 0.1013 Acc:96.45%
Training: Epoch[007/100] Iteration[150/381] Loss: 0.1473 Acc:96.42%
Training: Epoch[007/100] Iteration[160/381] Loss: 0.1318 Acc:96.43%
Training: Epoch[007/100] Iteration[170/381] Loss: 0.1608 Acc:96.45%
Training: Epoch[007/100] Iteration[180/381] Loss: 0.1484 Acc:96.35%
Training: Epoch[007/100] Iteration[190/381] Loss: 0.1594 Acc:96.30%
Training: Epoch[007/100] Iteration[200/381] Loss: 0.1829 Acc:96.30%
Training: Epoch[007/100] Iteration[210/381] Loss: 0.1658 Acc:96.31%
Training: Epoch[007/100] Iteration[220/381] Loss: 0.1466 Acc:96.26%
Training: Epoch[007/100] Iteration[230/381] Loss: 0.1154 Acc:96.29%
Training: Epoch[007/100] Iteration[240/381] Loss: 0.1285 Acc:96.28%
Training: Epoch[007/100] Iteration[250/381] Loss: 0.0993 Acc:96.34%
Training: Epoch[007/100] Iteration[260/381] Loss: 0.1140 Acc:96.32%
Training: Epoch[007/100] Iteration[270/381] Loss: 0.1551 Acc:96.34%
Training: Epoch[007/100] Iteration[280/381] Loss: 0.0706 Acc:96.40%
Training: Epoch[007/100] Iteration[290/381] Loss: 0.0996 Acc:96.42%
Training: Epoch[007/100] Iteration[300/381] Loss: 0.1265 Acc:96.41%
Training: Epoch[007/100] Iteration[310/381] Loss: 0.0988 Acc:96.43%
Training: Epoch[007/100] Iteration[320/381] Loss: 0.1830 Acc:96.38%
Training: Epoch[007/100] Iteration[330/381] Loss: 0.2061 Acc:96.29%
Training: Epoch[007/100] Iteration[340/381] Loss: 0.1342 Acc:96.30%
Training: Epoch[007/100] Iteration[350/381] Loss: 0.1670 Acc:96.29%
Training: Epoch[007/100] Iteration[360/381] Loss: 0.0920 Acc:96.31%
Training: Epoch[007/100] Iteration[370/381] Loss: 0.1024 Acc:96.35%
Training: Epoch[007/100] Iteration[380/381] Loss: 0.0610 Acc:96.41%
Valid set Accuracy:86.28%
Training: Epoch[008/100] Iteration[010/381] Loss: 0.0416 Acc:98.12%
Training: Epoch[008/100] Iteration[020/381] Loss: 0.0336 Acc:98.91%
Training: Epoch[008/100] Iteration[030/381] Loss: 0.0858 Acc:98.12%
Training: Epoch[008/100] Iteration[040/381] Loss: 0.0485 Acc:98.28%
Training: Epoch[008/100] Iteration[050/381] Loss: 0.0962 Acc:98.12%
Training: Epoch[008/100] Iteration[060/381] Loss: 0.0905 Acc:98.07%
Training: Epoch[008/100] Iteration[070/381] Loss: 0.1375 Acc:97.90%
Training: Epoch[008/100] Iteration[080/381] Loss: 0.1325 Acc:97.66%
Training: Epoch[008/100] Iteration[090/381] Loss: 0.0950 Acc:97.64%
Training: Epoch[008/100] Iteration[100/381] Loss: 0.1060 Acc:97.47%
Training: Epoch[008/100] Iteration[110/381] Loss: 0.0946 Acc:97.33%
Training: Epoch[008/100] Iteration[120/381] Loss: 0.1041 Acc:97.32%
Training: Epoch[008/100] Iteration[130/381] Loss: 0.1260 Acc:97.24%
Training: Epoch[008/100] Iteration[140/381] Loss: 0.1038 Acc:97.17%
Training: Epoch[008/100] Iteration[150/381] Loss: 0.1185 Acc:97.10%
Training: Epoch[008/100] Iteration[160/381] Loss: 0.1021 Acc:97.07%
Training: Epoch[008/100] Iteration[170/381] Loss: 0.0695 Acc:97.13%
Training: Epoch[008/100] Iteration[180/381] Loss: 0.0775 Acc:97.17%
Training: Epoch[008/100] Iteration[190/381] Loss: 0.0781 Acc:97.17%
Training: Epoch[008/100] Iteration[200/381] Loss: 0.1008 Acc:97.16%
Training: Epoch[008/100] Iteration[210/381] Loss: 0.1278 Acc:97.10%
Training: Epoch[008/100] Iteration[220/381] Loss: 0.1035 Acc:97.09%
Training: Epoch[008/100] Iteration[230/381] Loss: 0.1066 Acc:97.11%
Training: Epoch[008/100] Iteration[240/381] Loss: 0.0734 Acc:97.11%
Training: Epoch[008/100] Iteration[250/381] Loss: 0.0896 Acc:97.09%
Training: Epoch[008/100] Iteration[260/381] Loss: 0.1117 Acc:97.13%
Training: Epoch[008/100] Iteration[270/381] Loss: 0.0837 Acc:97.18%
Training: Epoch[008/100] Iteration[280/381] Loss: 0.1604 Acc:97.14%
Training: Epoch[008/100] Iteration[290/381] Loss: 0.1409 Acc:97.06%
Training: Epoch[008/100] Iteration[300/381] Loss: 0.0717 Acc:97.10%
Training: Epoch[008/100] Iteration[310/381] Loss: 0.1063 Acc:97.07%
Training: Epoch[008/100] Iteration[320/381] Loss: 0.1484 Acc:97.06%
Training: Epoch[008/100] Iteration[330/381] Loss: 0.0833 Acc:97.08%
Training: Epoch[008/100] Iteration[340/381] Loss: 0.0624 Acc:97.10%
Training: Epoch[008/100] Iteration[350/381] Loss: 0.0863 Acc:97.12%
Training: Epoch[008/100] Iteration[360/381] Loss: 0.1109 Acc:97.07%
Training: Epoch[008/100] Iteration[370/381] Loss: 0.1067 Acc:97.03%
Training: Epoch[008/100] Iteration[380/381] Loss: 0.1003 Acc:97.04%
Training: Epoch[009/100] Iteration[010/381] Loss: 0.0524 Acc:98.44%
Training: Epoch[009/100] Iteration[020/381] Loss: 0.0752 Acc:98.12%
Training: Epoch[009/100] Iteration[030/381] Loss: 0.0713 Acc:98.33%
Training: Epoch[009/100] Iteration[040/381] Loss: 0.0670 Acc:98.12%
Training: Epoch[009/100] Iteration[050/381] Loss: 0.0555 Acc:98.06%
Training: Epoch[009/100] Iteration[060/381] Loss: 0.0800 Acc:97.97%
Training: Epoch[009/100] Iteration[070/381] Loss: 0.0493 Acc:97.99%
Training: Epoch[009/100] Iteration[080/381] Loss: 0.0750 Acc:98.09%
Training: Epoch[009/100] Iteration[090/381] Loss: 0.0740 Acc:98.02%
Training: Epoch[009/100] Iteration[100/381] Loss: 0.0677 Acc:98.03%
Training: Epoch[009/100] Iteration[110/381] Loss: 0.0745 Acc:97.98%
Training: Epoch[009/100] Iteration[120/381] Loss: 0.0567 Acc:97.99%
Training: Epoch[009/100] Iteration[130/381] Loss: 0.0869 Acc:97.88%
Training: Epoch[009/100] Iteration[140/381] Loss: 0.0834 Acc:97.86%
Training: Epoch[009/100] Iteration[150/381] Loss: 0.1170 Acc:97.75%
Training: Epoch[009/100] Iteration[160/381] Loss: 0.0904 Acc:97.68%
Training: Epoch[009/100] Iteration[170/381] Loss: 0.1083 Acc:97.63%
Training: Epoch[009/100] Iteration[180/381] Loss: 0.1337 Acc:97.53%
Training: Epoch[009/100] Iteration[190/381] Loss: 0.0937 Acc:97.47%
Training: Epoch[009/100] Iteration[200/381] Loss: 0.0741 Acc:97.48%
Training: Epoch[009/100] Iteration[210/381] Loss: 0.0514 Acc:97.53%
Training: Epoch[009/100] Iteration[220/381] Loss: 0.0555 Acc:97.54%
Training: Epoch[009/100] Iteration[230/381] Loss: 0.0816 Acc:97.57%
Training: Epoch[009/100] Iteration[240/381] Loss: 0.0493 Acc:97.60%
Training: Epoch[009/100] Iteration[250/381] Loss: 0.0688 Acc:97.62%
Training: Epoch[009/100] Iteration[260/381] Loss: 0.0697 Acc:97.63%
Training: Epoch[009/100] Iteration[270/381] Loss: 0.0311 Acc:97.69%
Training: Epoch[009/100] Iteration[280/381] Loss: 0.0362 Acc:97.75%
Training: Epoch[009/100] Iteration[290/381] Loss: 0.1261 Acc:97.70%
Training: Epoch[009/100] Iteration[300/381] Loss: 0.1005 Acc:97.69%
Training: Epoch[009/100] Iteration[310/381] Loss: 0.1027 Acc:97.66%
Training: Epoch[009/100] Iteration[320/381] Loss: 0.0333 Acc:97.72%
Training: Epoch[009/100] Iteration[330/381] Loss: 0.0655 Acc:97.73%
Training: Epoch[009/100] Iteration[340/381] Loss: 0.0813 Acc:97.71%
Training: Epoch[009/100] Iteration[350/381] Loss: 0.0944 Acc:97.69%
Training: Epoch[009/100] Iteration[360/381] Loss: 0.0480 Acc:97.72%
Training: Epoch[009/100] Iteration[370/381] Loss: 0.0624 Acc:97.73%
Training: Epoch[009/100] Iteration[380/381] Loss: 0.0561 Acc:97.74%
Valid set Accuracy:83.36%
Training: Epoch[010/100] Iteration[010/381] Loss: 0.0454 Acc:98.44%
Training: Epoch[010/100] Iteration[020/381] Loss: 0.0462 Acc:98.44%
Training: Epoch[010/100] Iteration[030/381] Loss: 0.0768 Acc:98.02%
Training: Epoch[010/100] Iteration[040/381] Loss: 0.0929 Acc:97.81%
Training: Epoch[010/100] Iteration[050/381] Loss: 0.0419 Acc:98.00%
Training: Epoch[010/100] Iteration[060/381] Loss: 0.0897 Acc:97.92%
Training: Epoch[010/100] Iteration[070/381] Loss: 0.0456 Acc:98.04%
Training: Epoch[010/100] Iteration[080/381] Loss: 0.0999 Acc:98.01%
Training: Epoch[010/100] Iteration[090/381] Loss: 0.0329 Acc:98.09%
Training: Epoch[010/100] Iteration[100/381] Loss: 0.0650 Acc:98.12%
Training: Epoch[010/100] Iteration[110/381] Loss: 0.0757 Acc:98.07%
Training: Epoch[010/100] Iteration[120/381] Loss: 0.0514 Acc:98.10%
Training: Epoch[010/100] Iteration[130/381] Loss: 0.0609 Acc:98.03%
Training: Epoch[010/100] Iteration[140/381] Loss: 0.0380 Acc:98.10%
Training: Epoch[010/100] Iteration[150/381] Loss: 0.0760 Acc:98.10%
Training: Epoch[010/100] Iteration[160/381] Loss: 0.0585 Acc:98.09%
Training: Epoch[010/100] Iteration[170/381] Loss: 0.0538 Acc:98.12%
Training: Epoch[010/100] Iteration[180/381] Loss: 0.0501 Acc:98.19%
Training: Epoch[010/100] Iteration[190/381] Loss: 0.1263 Acc:98.11%
Training: Epoch[010/100] Iteration[200/381] Loss: 0.0501 Acc:98.09%
Training: Epoch[010/100] Iteration[210/381] Loss: 0.0506 Acc:98.11%
Training: Epoch[010/100] Iteration[220/381] Loss: 0.0775 Acc:98.10%
Training: Epoch[010/100] Iteration[230/381] Loss: 0.1264 Acc:98.02%
Training: Epoch[010/100] Iteration[240/381] Loss: 0.0753 Acc:97.99%
Training: Epoch[010/100] Iteration[250/381] Loss: 0.0601 Acc:97.97%
Training: Epoch[010/100] Iteration[260/381] Loss: 0.0917 Acc:97.97%
Training: Epoch[010/100] Iteration[270/381] Loss: 0.0996 Acc:97.93%
Training: Epoch[010/100] Iteration[280/381] Loss: 0.0960 Acc:97.92%
Training: Epoch[010/100] Iteration[290/381] Loss: 0.0779 Acc:97.93%
Training: Epoch[010/100] Iteration[300/381] Loss: 0.0789 Acc:97.92%
Training: Epoch[010/100] Iteration[310/381] Loss: 0.0389 Acc:97.95%
Training: Epoch[010/100] Iteration[320/381] Loss: 0.0623 Acc:97.96%
Training: Epoch[010/100] Iteration[330/381] Loss: 0.0218 Acc:98.00%
Training: Epoch[010/100] Iteration[340/381] Loss: 0.0750 Acc:98.01%
Training: Epoch[010/100] Iteration[350/381] Loss: 0.0472 Acc:98.03%
Training: Epoch[010/100] Iteration[360/381] Loss: 0.0936 Acc:97.99%
Training: Epoch[010/100] Iteration[370/381] Loss: 0.0586 Acc:98.02%
Training: Epoch[010/100] Iteration[380/381] Loss: 0.0851 Acc:98.01%
Training: Epoch[011/100] Iteration[010/381] Loss: 0.0292 Acc:99.06%
Training: Epoch[011/100] Iteration[020/381] Loss: 0.0263 Acc:99.22%
Training: Epoch[011/100] Iteration[030/381] Loss: 0.0454 Acc:99.17%
Training: Epoch[011/100] Iteration[040/381] Loss: 0.0466 Acc:98.98%
Training: Epoch[011/100] Iteration[050/381] Loss: 0.0458 Acc:98.88%
Training: Epoch[011/100] Iteration[060/381] Loss: 0.0602 Acc:98.75%
Training: Epoch[011/100] Iteration[070/381] Loss: 0.0472 Acc:98.66%
Training: Epoch[011/100] Iteration[080/381] Loss: 0.0536 Acc:98.59%
Training: Epoch[011/100] Iteration[090/381] Loss: 0.0681 Acc:98.61%
Training: Epoch[011/100] Iteration[100/381] Loss: 0.0327 Acc:98.62%
Training: Epoch[011/100] Iteration[110/381] Loss: 0.0528 Acc:98.64%
Training: Epoch[011/100] Iteration[120/381] Loss: 0.0561 Acc:98.59%
Training: Epoch[011/100] Iteration[130/381] Loss: 0.0322 Acc:98.65%
Training: Epoch[011/100] Iteration[140/381] Loss: 0.0538 Acc:98.62%
Training: Epoch[011/100] Iteration[150/381] Loss: 0.0559 Acc:98.56%
Training: Epoch[011/100] Iteration[160/381] Loss: 0.0430 Acc:98.55%
Training: Epoch[011/100] Iteration[170/381] Loss: 0.0808 Acc:98.51%
Training: Epoch[011/100] Iteration[180/381] Loss: 0.0667 Acc:98.49%
Training: Epoch[011/100] Iteration[190/381] Loss: 0.0657 Acc:98.50%
Training: Epoch[011/100] Iteration[200/381] Loss: 0.0370 Acc:98.52%
Training: Epoch[011/100] Iteration[210/381] Loss: 0.0850 Acc:98.50%
Training: Epoch[011/100] Iteration[220/381] Loss: 0.1018 Acc:98.47%
Training: Epoch[011/100] Iteration[230/381] Loss: 0.0939 Acc:98.41%
Training: Epoch[011/100] Iteration[240/381] Loss: 0.0614 Acc:98.44%
Training: Epoch[011/100] Iteration[250/381] Loss: 0.0317 Acc:98.45%
Training: Epoch[011/100] Iteration[260/381] Loss: 0.0432 Acc:98.46%
Training: Epoch[011/100] Iteration[270/381] Loss: 0.0255 Acc:98.48%
Training: Epoch[011/100] Iteration[280/381] Loss: 0.0854 Acc:98.52%
Training: Epoch[011/100] Iteration[290/381] Loss: 0.0373 Acc:98.53%
Training: Epoch[011/100] Iteration[300/381] Loss: 0.0269 Acc:98.55%
Training: Epoch[011/100] Iteration[310/381] Loss: 0.0090 Acc:98.60%
Training: Epoch[011/100] Iteration[320/381] Loss: 0.0152 Acc:98.62%
Training: Epoch[011/100] Iteration[330/381] Loss: 0.0279 Acc:98.63%
Training: Epoch[011/100] Iteration[340/381] Loss: 0.0310 Acc:98.64%
Training: Epoch[011/100] Iteration[350/381] Loss: 0.0149 Acc:98.66%
Training: Epoch[011/100] Iteration[360/381] Loss: 0.0336 Acc:98.68%
Training: Epoch[011/100] Iteration[370/381] Loss: 0.0512 Acc:98.69%
Training: Epoch[011/100] Iteration[380/381] Loss: 0.0130 Acc:98.72%
Valid set Accuracy:87.62%
Training: Epoch[012/100] Iteration[010/381] Loss: 0.0615 Acc:98.44%
Training: Epoch[012/100] Iteration[020/381] Loss: 0.0487 Acc:98.59%
Training: Epoch[012/100] Iteration[030/381] Loss: 0.0357 Acc:98.85%
Training: Epoch[012/100] Iteration[040/381] Loss: 0.0352 Acc:98.91%
Training: Epoch[012/100] Iteration[050/381] Loss: 0.0163 Acc:99.00%
Training: Epoch[012/100] Iteration[060/381] Loss: 0.0253 Acc:98.96%
Training: Epoch[012/100] Iteration[070/381] Loss: 0.0398 Acc:98.84%
Training: Epoch[012/100] Iteration[080/381] Loss: 0.0422 Acc:98.95%
Training: Epoch[012/100] Iteration[090/381] Loss: 0.0353 Acc:98.96%
Training: Epoch[012/100] Iteration[100/381] Loss: 0.0112 Acc:99.06%
Training: Epoch[012/100] Iteration[110/381] Loss: 0.0378 Acc:99.03%
Training: Epoch[012/100] Iteration[120/381] Loss: 0.0097 Acc:99.11%
Training: Epoch[012/100] Iteration[130/381] Loss: 0.0278 Acc:99.11%
Training: Epoch[012/100] Iteration[140/381] Loss: 0.0211 Acc:99.11%
Training: Epoch[012/100] Iteration[150/381] Loss: 0.0148 Acc:99.12%
Training: Epoch[012/100] Iteration[160/381] Loss: 0.0136 Acc:99.16%
Training: Epoch[012/100] Iteration[170/381] Loss: 0.0327 Acc:99.15%
Training: Epoch[012/100] Iteration[180/381] Loss: 0.0171 Acc:99.18%
Training: Epoch[012/100] Iteration[190/381] Loss: 0.0088 Acc:99.23%
Training: Epoch[012/100] Iteration[200/381] Loss: 0.0047 Acc:99.27%
Training: Epoch[012/100] Iteration[210/381] Loss: 0.0058 Acc:99.30%
Training: Epoch[012/100] Iteration[220/381] Loss: 0.0045 Acc:99.33%
Training: Epoch[012/100] Iteration[230/381] Loss: 0.0093 Acc:99.33%
Training: Epoch[012/100] Iteration[240/381] Loss: 0.0084 Acc:99.35%
Training: Epoch[012/100] Iteration[250/381] Loss: 0.0172 Acc:99.36%
Training: Epoch[012/100] Iteration[260/381] Loss: 0.0066 Acc:99.39%
Training: Epoch[012/100] Iteration[270/381] Loss: 0.0450 Acc:99.38%
Training: Epoch[012/100] Iteration[280/381] Loss: 0.0136 Acc:99.39%
Training: Epoch[012/100] Iteration[290/381] Loss: 0.0418 Acc:99.36%
Training: Epoch[012/100] Iteration[300/381] Loss: 0.0229 Acc:99.38%
Training: Epoch[012/100] Iteration[310/381] Loss: 0.0504 Acc:99.34%
Training: Epoch[012/100] Iteration[320/381] Loss: 0.0215 Acc:99.36%
Training: Epoch[012/100] Iteration[330/381] Loss: 0.1300 Acc:99.32%
Training: Epoch[012/100] Iteration[340/381] Loss: 0.0732 Acc:99.28%
Training: Epoch[012/100] Iteration[350/381] Loss: 0.0851 Acc:99.25%
Training: Epoch[012/100] Iteration[360/381] Loss: 0.0843 Acc:99.20%
Training: Epoch[012/100] Iteration[370/381] Loss: 0.0369 Acc:99.20%
Training: Epoch[012/100] Iteration[380/381] Loss: 0.0244 Acc:99.20%
Training: Epoch[013/100] Iteration[010/381] Loss: 0.0127 Acc:100.00%
Training: Epoch[013/100] Iteration[020/381] Loss: 0.0106 Acc:99.84%
Training: Epoch[013/100] Iteration[030/381] Loss: 0.0115 Acc:99.79%
Training: Epoch[013/100] Iteration[040/381] Loss: 0.0145 Acc:99.77%
Training: Epoch[013/100] Iteration[050/381] Loss: 0.0054 Acc:99.81%
Training: Epoch[013/100] Iteration[060/381] Loss: 0.0193 Acc:99.79%
Training: Epoch[013/100] Iteration[070/381] Loss: 0.0286 Acc:99.60%
Training: Epoch[013/100] Iteration[080/381] Loss: 0.0493 Acc:99.49%
Training: Epoch[013/100] Iteration[090/381] Loss: 0.0270 Acc:99.44%
Training: Epoch[013/100] Iteration[100/381] Loss: 0.0329 Acc:99.38%
Training: Epoch[013/100] Iteration[110/381] Loss: 0.0289 Acc:99.38%
Training: Epoch[013/100] Iteration[120/381] Loss: 0.0157 Acc:99.43%
Training: Epoch[013/100] Iteration[130/381] Loss: 0.0589 Acc:99.40%
Training: Epoch[013/100] Iteration[140/381] Loss: 0.0308 Acc:99.38%
Training: Epoch[013/100] Iteration[150/381] Loss: 0.0270 Acc:99.35%
Training: Epoch[013/100] Iteration[160/381] Loss: 0.0113 Acc:99.36%
Training: Epoch[013/100] Iteration[170/381] Loss: 0.0090 Acc:99.39%
Training: Epoch[013/100] Iteration[180/381] Loss: 0.0510 Acc:99.36%
Training: Epoch[013/100] Iteration[190/381] Loss: 0.0449 Acc:99.29%
Training: Epoch[013/100] Iteration[200/381] Loss: 0.0357 Acc:99.30%
Training: Epoch[013/100] Iteration[210/381] Loss: 0.0285 Acc:99.30%
Training: Epoch[013/100] Iteration[220/381] Loss: 0.0584 Acc:99.23%
Training: Epoch[013/100] Iteration[230/381] Loss: 0.0418 Acc:99.20%
Training: Epoch[013/100] Iteration[240/381] Loss: 0.0251 Acc:99.18%
Training: Epoch[013/100] Iteration[250/381] Loss: 0.0348 Acc:99.19%
Training: Epoch[013/100] Iteration[260/381] Loss: 0.0177 Acc:99.21%
Training: Epoch[013/100] Iteration[270/381] Loss: 0.0387 Acc:99.18%
Training: Epoch[013/100] Iteration[280/381] Loss: 0.0559 Acc:99.20%
Training: Epoch[013/100] Iteration[290/381] Loss: 0.0230 Acc:99.20%
Training: Epoch[013/100] Iteration[300/381] Loss: 0.0109 Acc:99.23%
Training: Epoch[013/100] Iteration[310/381] Loss: 0.0119 Acc:99.24%
Training: Epoch[013/100] Iteration[320/381] Loss: 0.0280 Acc:99.24%
Training: Epoch[013/100] Iteration[330/381] Loss: 0.0178 Acc:99.24%
Training: Epoch[013/100] Iteration[340/381] Loss: 0.0123 Acc:99.26%
Training: Epoch[013/100] Iteration[350/381] Loss: 0.0074 Acc:99.28%
Training: Epoch[013/100] Iteration[360/381] Loss: 0.0053 Acc:99.30%
Training: Epoch[013/100] Iteration[370/381] Loss: 0.0047 Acc:99.32%
Training: Epoch[013/100] Iteration[380/381] Loss: 0.0137 Acc:99.32%
Valid set Accuracy:90.95%
Training: Epoch[014/100] Iteration[010/381] Loss: 0.0035 Acc:100.00%
Training: Epoch[014/100] Iteration[020/381] Loss: 0.0406 Acc:99.53%
Training: Epoch[014/100] Iteration[030/381] Loss: 0.0284 Acc:99.48%
Training: Epoch[014/100] Iteration[040/381] Loss: 0.0101 Acc:99.53%
Training: Epoch[014/100] Iteration[050/381] Loss: 0.0163 Acc:99.56%
Training: Epoch[014/100] Iteration[060/381] Loss: 0.0284 Acc:99.48%
Training: Epoch[014/100] Iteration[070/381] Loss: 0.0143 Acc:99.51%
Training: Epoch[014/100] Iteration[080/381] Loss: 0.0187 Acc:99.53%
Training: Epoch[014/100] Iteration[090/381] Loss: 0.0263 Acc:99.51%
Training: Epoch[014/100] Iteration[100/381] Loss: 0.0209 Acc:99.47%
Training: Epoch[014/100] Iteration[110/381] Loss: 0.0202 Acc:99.49%
Training: Epoch[014/100] Iteration[120/381] Loss: 0.0303 Acc:99.51%
Training: Epoch[014/100] Iteration[130/381] Loss: 0.0154 Acc:99.50%
Training: Epoch[014/100] Iteration[140/381] Loss: 0.0208 Acc:99.51%
Training: Epoch[014/100] Iteration[150/381] Loss: 0.0097 Acc:99.54%
Training: Epoch[014/100] Iteration[160/381] Loss: 0.0215 Acc:99.53%
Training: Epoch[014/100] Iteration[170/381] Loss: 0.0051 Acc:99.56%
Training: Epoch[014/100] Iteration[180/381] Loss: 0.0576 Acc:99.53%
Training: Epoch[014/100] Iteration[190/381] Loss: 0.0851 Acc:99.51%
Training: Epoch[014/100] Iteration[200/381] Loss: 0.0254 Acc:99.47%
Training: Epoch[014/100] Iteration[210/381] Loss: 0.0185 Acc:99.46%
Training: Epoch[014/100] Iteration[220/381] Loss: 0.0081 Acc:99.47%
Training: Epoch[014/100] Iteration[230/381] Loss: 0.0111 Acc:99.48%
Training: Epoch[014/100] Iteration[240/381] Loss: 0.0054 Acc:99.49%
Training: Epoch[014/100] Iteration[250/381] Loss: 0.0030 Acc:99.51%
Training: Epoch[014/100] Iteration[260/381] Loss: 0.0085 Acc:99.52%
Training: Epoch[014/100] Iteration[270/381] Loss: 0.0109 Acc:99.53%
Training: Epoch[014/100] Iteration[280/381] Loss: 0.0055 Acc:99.54%
Training: Epoch[014/100] Iteration[290/381] Loss: 0.0040 Acc:99.56%
Training: Epoch[014/100] Iteration[300/381] Loss: 0.0216 Acc:99.55%
Training: Epoch[014/100] Iteration[310/381] Loss: 0.0067 Acc:99.56%
Training: Epoch[014/100] Iteration[320/381] Loss: 0.0177 Acc:99.55%
Training: Epoch[014/100] Iteration[330/381] Loss: 0.0146 Acc:99.55%
Training: Epoch[014/100] Iteration[340/381] Loss: 0.0100 Acc:99.56%
Training: Epoch[014/100] Iteration[350/381] Loss: 0.0387 Acc:99.55%
Training: Epoch[014/100] Iteration[360/381] Loss: 0.0102 Acc:99.56%
Training: Epoch[014/100] Iteration[370/381] Loss: 0.0238 Acc:99.54%
Training: Epoch[014/100] Iteration[380/381] Loss: 0.0095 Acc:99.55%
Training: Epoch[015/100] Iteration[010/381] Loss: 0.0325 Acc:99.38%
Training: Epoch[015/100] Iteration[020/381] Loss: 0.0346 Acc:99.38%
Training: Epoch[015/100] Iteration[030/381] Loss: 0.0052 Acc:99.58%
Training: Epoch[015/100] Iteration[040/381] Loss: 0.0179 Acc:99.53%
Training: Epoch[015/100] Iteration[050/381] Loss: 0.0515 Acc:99.31%
Training: Epoch[015/100] Iteration[060/381] Loss: 0.0254 Acc:99.22%
Training: Epoch[015/100] Iteration[070/381] Loss: 0.0681 Acc:99.20%
Training: Epoch[015/100] Iteration[080/381] Loss: 0.0402 Acc:99.18%
Training: Epoch[015/100] Iteration[090/381] Loss: 0.0245 Acc:99.20%
Training: Epoch[015/100] Iteration[100/381] Loss: 0.0191 Acc:99.25%
Training: Epoch[015/100] Iteration[110/381] Loss: 0.0213 Acc:99.26%
Training: Epoch[015/100] Iteration[120/381] Loss: 0.0293 Acc:99.24%
Training: Epoch[015/100] Iteration[130/381] Loss: 0.0224 Acc:99.23%
Training: Epoch[015/100] Iteration[140/381] Loss: 0.0295 Acc:99.22%
Training: Epoch[015/100] Iteration[150/381] Loss: 0.0058 Acc:99.27%
Training: Epoch[015/100] Iteration[160/381] Loss: 0.0406 Acc:99.28%
Training: Epoch[015/100] Iteration[170/381] Loss: 0.0104 Acc:99.30%
Training: Epoch[015/100] Iteration[180/381] Loss: 0.0187 Acc:99.32%
Training: Epoch[015/100] Iteration[190/381] Loss: 0.0482 Acc:99.33%
Training: Epoch[015/100] Iteration[200/381] Loss: 0.0153 Acc:99.34%
Training: Epoch[015/100] Iteration[210/381] Loss: 0.0151 Acc:99.35%
Training: Epoch[015/100] Iteration[220/381] Loss: 0.0057 Acc:99.38%
Training: Epoch[015/100] Iteration[230/381] Loss: 0.0054 Acc:99.39%
Training: Epoch[015/100] Iteration[240/381] Loss: 0.0131 Acc:99.39%
Training: Epoch[015/100] Iteration[250/381] Loss: 0.0394 Acc:99.39%
Training: Epoch[015/100] Iteration[260/381] Loss: 0.0266 Acc:99.39%
Training: Epoch[015/100] Iteration[270/381] Loss: 0.0100 Acc:99.41%
Training: Epoch[015/100] Iteration[280/381] Loss: 0.0159 Acc:99.40%
Training: Epoch[015/100] Iteration[290/381] Loss: 0.0232 Acc:99.39%
Training: Epoch[015/100] Iteration[300/381] Loss: 0.0540 Acc:99.36%
Training: Epoch[015/100] Iteration[310/381] Loss: 0.0253 Acc:99.38%
Training: Epoch[015/100] Iteration[320/381] Loss: 0.0412 Acc:99.38%
Training: Epoch[015/100] Iteration[330/381] Loss: 0.0274 Acc:99.38%
Training: Epoch[015/100] Iteration[340/381] Loss: 0.0061 Acc:99.38%
Training: Epoch[015/100] Iteration[350/381] Loss: 0.0251 Acc:99.38%
Training: Epoch[015/100] Iteration[360/381] Loss: 0.0326 Acc:99.38%
Training: Epoch[015/100] Iteration[370/381] Loss: 0.0222 Acc:99.37%
Training: Epoch[015/100] Iteration[380/381] Loss: 0.0276 Acc:99.36%
Valid set Accuracy:88.15%
Training: Epoch[016/100] Iteration[010/381] Loss: 0.0136 Acc:99.38%
Training: Epoch[016/100] Iteration[020/381] Loss: 0.0142 Acc:99.53%
Training: Epoch[016/100] Iteration[030/381] Loss: 0.0180 Acc:99.38%
Training: Epoch[016/100] Iteration[040/381] Loss: 0.0036 Acc:99.53%
Training: Epoch[016/100] Iteration[050/381] Loss: 0.0057 Acc:99.56%
Training: Epoch[016/100] Iteration[060/381] Loss: 0.0299 Acc:99.53%
Training: Epoch[016/100] Iteration[070/381] Loss: 0.0285 Acc:99.42%
Training: Epoch[016/100] Iteration[080/381] Loss: 0.0279 Acc:99.41%
Training: Epoch[016/100] Iteration[090/381] Loss: 0.0293 Acc:99.41%
Training: Epoch[016/100] Iteration[100/381] Loss: 0.0185 Acc:99.34%
Training: Epoch[016/100] Iteration[110/381] Loss: 0.0353 Acc:99.32%
Training: Epoch[016/100] Iteration[120/381] Loss: 0.0184 Acc:99.32%
Training: Epoch[016/100] Iteration[130/381] Loss: 0.1022 Acc:99.30%
Training: Epoch[016/100] Iteration[140/381] Loss: 0.0785 Acc:99.22%
Training: Epoch[016/100] Iteration[150/381] Loss: 0.0803 Acc:99.23%
Training: Epoch[016/100] Iteration[160/381] Loss: 0.0640 Acc:99.18%
Training: Epoch[016/100] Iteration[170/381] Loss: 0.0791 Acc:99.10%
Training: Epoch[016/100] Iteration[180/381] Loss: 0.0121 Acc:99.15%
Training: Epoch[016/100] Iteration[190/381] Loss: 0.0346 Acc:99.13%
Training: Epoch[016/100] Iteration[200/381] Loss: 0.0073 Acc:99.17%
Training: Epoch[016/100] Iteration[210/381] Loss: 0.0244 Acc:99.18%
Training: Epoch[016/100] Iteration[220/381] Loss: 0.0181 Acc:99.19%
Training: Epoch[016/100] Iteration[230/381] Loss: 0.0410 Acc:99.20%
Training: Epoch[016/100] Iteration[240/381] Loss: 0.0362 Acc:99.18%
Training: Epoch[016/100] Iteration[250/381] Loss: 0.0150 Acc:99.17%
Training: Epoch[016/100] Iteration[260/381] Loss: 0.0084 Acc:99.19%
Training: Epoch[016/100] Iteration[270/381] Loss: 0.0109 Acc:99.21%
Training: Epoch[016/100] Iteration[280/381] Loss: 0.0126 Acc:99.23%
Training: Epoch[016/100] Iteration[290/381] Loss: 0.0219 Acc:99.22%
Training: Epoch[016/100] Iteration[300/381] Loss: 0.0148 Acc:99.24%
Training: Epoch[016/100] Iteration[310/381] Loss: 0.0188 Acc:99.24%
Training: Epoch[016/100] Iteration[320/381] Loss: 0.0339 Acc:99.25%
Training: Epoch[016/100] Iteration[330/381] Loss: 0.0103 Acc:99.26%
Training: Epoch[016/100] Iteration[340/381] Loss: 0.0244 Acc:99.27%
Training: Epoch[016/100] Iteration[350/381] Loss: 0.0089 Acc:99.29%
Training: Epoch[016/100] Iteration[360/381] Loss: 0.0192 Acc:99.29%
Training: Epoch[016/100] Iteration[370/381] Loss: 0.0077 Acc:99.31%
Training: Epoch[016/100] Iteration[380/381] Loss: 0.0121 Acc:99.31%
Training: Epoch[017/100] Iteration[010/381] Loss: 0.0069 Acc:99.69%
Training: Epoch[017/100] Iteration[020/381] Loss: 0.0197 Acc:99.69%
Training: Epoch[017/100] Iteration[030/381] Loss: 0.0036 Acc:99.79%
Training: Epoch[017/100] Iteration[040/381] Loss: 0.0459 Acc:99.53%
Training: Epoch[017/100] Iteration[050/381] Loss: 0.0077 Acc:99.62%
Training: Epoch[017/100] Iteration[060/381] Loss: 0.0237 Acc:99.64%
Training: Epoch[017/100] Iteration[070/381] Loss: 0.0066 Acc:99.69%
Training: Epoch[017/100] Iteration[080/381] Loss: 0.0153 Acc:99.69%
Training: Epoch[017/100] Iteration[090/381] Loss: 0.0022 Acc:99.72%
Training: Epoch[017/100] Iteration[100/381] Loss: 0.0062 Acc:99.72%
Training: Epoch[017/100] Iteration[110/381] Loss: 0.0072 Acc:99.72%
Training: Epoch[017/100] Iteration[120/381] Loss: 0.0022 Acc:99.74%
Training: Epoch[017/100] Iteration[130/381] Loss: 0.0081 Acc:99.74%
Training: Epoch[017/100] Iteration[140/381] Loss: 0.0045 Acc:99.75%
Training: Epoch[017/100] Iteration[150/381] Loss: 0.0250 Acc:99.75%
Training: Epoch[017/100] Iteration[160/381] Loss: 0.0109 Acc:99.75%
Training: Epoch[017/100] Iteration[170/381] Loss: 0.0068 Acc:99.76%
Training: Epoch[017/100] Iteration[180/381] Loss: 0.0340 Acc:99.74%
Training: Epoch[017/100] Iteration[190/381] Loss: 0.0152 Acc:99.72%
Training: Epoch[017/100] Iteration[200/381] Loss: 0.0117 Acc:99.69%
Training: Epoch[017/100] Iteration[210/381] Loss: 0.0034 Acc:99.70%
Training: Epoch[017/100] Iteration[220/381] Loss: 0.0067 Acc:99.70%
Training: Epoch[017/100] Iteration[230/381] Loss: 0.0061 Acc:99.70%
Training: Epoch[017/100] Iteration[240/381] Loss: 0.0044 Acc:99.71%
Training: Epoch[017/100] Iteration[250/381] Loss: 0.0090 Acc:99.70%
Training: Epoch[017/100] Iteration[260/381] Loss: 0.0093 Acc:99.70%
Training: Epoch[017/100] Iteration[270/381] Loss: 0.0289 Acc:99.69%
Training: Epoch[017/100] Iteration[280/381] Loss: 0.0287 Acc:99.68%
Training: Epoch[017/100] Iteration[290/381] Loss: 0.0110 Acc:99.67%
Training: Epoch[017/100] Iteration[300/381] Loss: 0.0379 Acc:99.65%
Training: Epoch[017/100] Iteration[310/381] Loss: 0.0195 Acc:99.65%
Training: Epoch[017/100] Iteration[320/381] Loss: 0.0244 Acc:99.63%
Training: Epoch[017/100] Iteration[330/381] Loss: 0.0147 Acc:99.62%
Training: Epoch[017/100] Iteration[340/381] Loss: 0.0335 Acc:99.60%
Training: Epoch[017/100] Iteration[350/381] Loss: 0.0143 Acc:99.61%
Training: Epoch[017/100] Iteration[360/381] Loss: 0.0136 Acc:99.61%
Training: Epoch[017/100] Iteration[370/381] Loss: 0.0342 Acc:99.58%
Training: Epoch[017/100] Iteration[380/381] Loss: 0.0265 Acc:99.55%
Valid set Accuracy:86.82%
Training: Epoch[018/100] Iteration[010/381] Loss: 0.0400 Acc:98.75%
Training: Epoch[018/100] Iteration[020/381] Loss: 0.0467 Acc:98.75%
Training: Epoch[018/100] Iteration[030/381] Loss: 0.0370 Acc:98.96%
Training: Epoch[018/100] Iteration[040/381] Loss: 0.0284 Acc:99.06%
Training: Epoch[018/100] Iteration[050/381] Loss: 0.0321 Acc:99.12%
Training: Epoch[018/100] Iteration[060/381] Loss: 0.0121 Acc:99.17%
Training: Epoch[018/100] Iteration[070/381] Loss: 0.0373 Acc:99.20%
Training: Epoch[018/100] Iteration[080/381] Loss: 0.0158 Acc:99.26%
Training: Epoch[018/100] Iteration[090/381] Loss: 0.0123 Acc:99.31%
Training: Epoch[018/100] Iteration[100/381] Loss: 0.0138 Acc:99.34%
Training: Epoch[018/100] Iteration[110/381] Loss: 0.0193 Acc:99.38%
Training: Epoch[018/100] Iteration[120/381] Loss: 0.0091 Acc:99.40%
Training: Epoch[018/100] Iteration[130/381] Loss: 0.0023 Acc:99.45%
Training: Epoch[018/100] Iteration[140/381] Loss: 0.0502 Acc:99.42%
Training: Epoch[018/100] Iteration[150/381] Loss: 0.0350 Acc:99.38%
Training: Epoch[018/100] Iteration[160/381] Loss: 0.0095 Acc:99.39%
Training: Epoch[018/100] Iteration[170/381] Loss: 0.0113 Acc:99.41%
Training: Epoch[018/100] Iteration[180/381] Loss: 0.0064 Acc:99.43%
Training: Epoch[018/100] Iteration[190/381] Loss: 0.0038 Acc:99.46%
Training: Epoch[018/100] Iteration[200/381] Loss: 0.0087 Acc:99.47%
Training: Epoch[018/100] Iteration[210/381] Loss: 0.0101 Acc:99.48%
Training: Epoch[018/100] Iteration[220/381] Loss: 0.0038 Acc:99.50%
Training: Epoch[018/100] Iteration[230/381] Loss: 0.0020 Acc:99.52%
Training: Epoch[018/100] Iteration[240/381] Loss: 0.0266 Acc:99.51%
Training: Epoch[018/100] Iteration[250/381] Loss: 0.0106 Acc:99.51%
Training: Epoch[018/100] Iteration[260/381] Loss: 0.0163 Acc:99.52%
Training: Epoch[018/100] Iteration[270/381] Loss: 0.0357 Acc:99.51%
Training: Epoch[018/100] Iteration[280/381] Loss: 0.0396 Acc:99.49%
Training: Epoch[018/100] Iteration[290/381] Loss: 0.0581 Acc:99.45%
Training: Epoch[018/100] Iteration[300/381] Loss: 0.0172 Acc:99.45%
Training: Epoch[018/100] Iteration[310/381] Loss: 0.0085 Acc:99.47%
Training: Epoch[018/100] Iteration[320/381] Loss: 0.0059 Acc:99.47%
Training: Epoch[018/100] Iteration[330/381] Loss: 0.0079 Acc:99.49%
Training: Epoch[018/100] Iteration[340/381] Loss: 0.0049 Acc:99.50%
Training: Epoch[018/100] Iteration[350/381] Loss: 0.0025 Acc:99.52%
Training: Epoch[018/100] Iteration[360/381] Loss: 0.0079 Acc:99.52%
Training: Epoch[018/100] Iteration[370/381] Loss: 0.0107 Acc:99.53%
Training: Epoch[018/100] Iteration[380/381] Loss: 0.0141 Acc:99.53%
Training: Epoch[019/100] Iteration[010/381] Loss: 0.0188 Acc:99.38%
Training: Epoch[019/100] Iteration[020/381] Loss: 0.0618 Acc:99.38%
Training: Epoch[019/100] Iteration[030/381] Loss: 0.0057 Acc:99.48%
Training: Epoch[019/100] Iteration[040/381] Loss: 0.0046 Acc:99.61%
Training: Epoch[019/100] Iteration[050/381] Loss: 0.0084 Acc:99.69%
Training: Epoch[019/100] Iteration[060/381] Loss: 0.0081 Acc:99.69%
Training: Epoch[019/100] Iteration[070/381] Loss: 0.0043 Acc:99.73%
Training: Epoch[019/100] Iteration[080/381] Loss: 0.0026 Acc:99.77%
Training: Epoch[019/100] Iteration[090/381] Loss: 0.0221 Acc:99.72%
Training: Epoch[019/100] Iteration[100/381] Loss: 0.0140 Acc:99.72%
Training: Epoch[019/100] Iteration[110/381] Loss: 0.0505 Acc:99.63%
Training: Epoch[019/100] Iteration[120/381] Loss: 0.0103 Acc:99.66%
Training: Epoch[019/100] Iteration[130/381] Loss: 0.0444 Acc:99.62%
Training: Epoch[019/100] Iteration[140/381] Loss: 0.0050 Acc:99.62%
Training: Epoch[019/100] Iteration[150/381] Loss: 0.0113 Acc:99.62%
Training: Epoch[019/100] Iteration[160/381] Loss: 0.0037 Acc:99.65%
Training: Epoch[019/100] Iteration[170/381] Loss: 0.0053 Acc:99.67%
Training: Epoch[019/100] Iteration[180/381] Loss: 0.0432 Acc:99.60%
Training: Epoch[019/100] Iteration[190/381] Loss: 0.0318 Acc:99.56%
Training: Epoch[019/100] Iteration[200/381] Loss: 0.0170 Acc:99.53%
Training: Epoch[019/100] Iteration[210/381] Loss: 0.0101 Acc:99.54%
Training: Epoch[019/100] Iteration[220/381] Loss: 0.0223 Acc:99.53%
Training: Epoch[019/100] Iteration[230/381] Loss: 0.0066 Acc:99.54%
Training: Epoch[019/100] Iteration[240/381] Loss: 0.0204 Acc:99.53%
Training: Epoch[019/100] Iteration[250/381] Loss: 0.0499 Acc:99.51%
Training: Epoch[019/100] Iteration[260/381] Loss: 0.0082 Acc:99.53%
Training: Epoch[019/100] Iteration[270/381] Loss: 0.0051 Acc:99.55%
Training: Epoch[019/100] Iteration[280/381] Loss: 0.0294 Acc:99.54%
Training: Epoch[019/100] Iteration[290/381] Loss: 0.0100 Acc:99.55%
Training: Epoch[019/100] Iteration[300/381] Loss: 0.0153 Acc:99.55%
Training: Epoch[019/100] Iteration[310/381] Loss: 0.0186 Acc:99.56%
Training: Epoch[019/100] Iteration[320/381] Loss: 0.0032 Acc:99.57%
Training: Epoch[019/100] Iteration[330/381] Loss: 0.0345 Acc:99.57%
Training: Epoch[019/100] Iteration[340/381] Loss: 0.0093 Acc:99.58%
Training: Epoch[019/100] Iteration[350/381] Loss: 0.0040 Acc:99.59%
Training: Epoch[019/100] Iteration[360/381] Loss: 0.0075 Acc:99.59%
Training: Epoch[019/100] Iteration[370/381] Loss: 0.0023 Acc:99.60%
Training: Epoch[019/100] Iteration[380/381] Loss: 0.0050 Acc:99.61%
Valid set Accuracy:90.55%
Training: Epoch[020/100] Iteration[010/381] Loss: 0.0012 Acc:100.00%
Training: Epoch[020/100] Iteration[020/381] Loss: 0.0043 Acc:100.00%
Training: Epoch[020/100] Iteration[030/381] Loss: 0.0009 Acc:100.00%
Training: Epoch[020/100] Iteration[040/381] Loss: 0.0007 Acc:100.00%
Training: Epoch[020/100] Iteration[050/381] Loss: 0.0008 Acc:100.00%
Training: Epoch[020/100] Iteration[060/381] Loss: 0.0009 Acc:100.00%
Training: Epoch[020/100] Iteration[070/381] Loss: 0.0008 Acc:100.00%
Training: Epoch[020/100] Iteration[080/381] Loss: 0.0010 Acc:100.00%
Training: Epoch[020/100] Iteration[090/381] Loss: 0.0009 Acc:100.00%
Training: Epoch[020/100] Iteration[100/381] Loss: 0.0135 Acc:99.97%
Training: Epoch[020/100] Iteration[110/381] Loss: 0.0219 Acc:99.94%
Training: Epoch[020/100] Iteration[120/381] Loss: 0.0012 Acc:99.95%
Training: Epoch[020/100] Iteration[130/381] Loss: 0.0015 Acc:99.95%
Training: Epoch[020/100] Iteration[140/381] Loss: 0.0004 Acc:99.96%
Training: Epoch[020/100] Iteration[150/381] Loss: 0.0006 Acc:99.96%
Training: Epoch[020/100] Iteration[160/381] Loss: 0.0011 Acc:99.96%
Training: Epoch[020/100] Iteration[170/381] Loss: 0.0129 Acc:99.94%
Training: Epoch[020/100] Iteration[180/381] Loss: 0.0014 Acc:99.95%
Training: Epoch[020/100] Iteration[190/381] Loss: 0.0262 Acc:99.93%
Training: Epoch[020/100] Iteration[200/381] Loss: 0.0003 Acc:99.94%
Training: Epoch[020/100] Iteration[210/381] Loss: 0.0012 Acc:99.94%
Training: Epoch[020/100] Iteration[220/381] Loss: 0.0010 Acc:99.94%
Training: Epoch[020/100] Iteration[230/381] Loss: 0.0019 Acc:99.95%
Training: Epoch[020/100] Iteration[240/381] Loss: 0.0022 Acc:99.95%
Training: Epoch[020/100] Iteration[250/381] Loss: 0.0008 Acc:99.95%
Training: Epoch[020/100] Iteration[260/381] Loss: 0.0007 Acc:99.95%
Training: Epoch[020/100] Iteration[270/381] Loss: 0.0003 Acc:99.95%
Training: Epoch[020/100] Iteration[280/381] Loss: 0.0012 Acc:99.96%
Training: Epoch[020/100] Iteration[290/381] Loss: 0.0015 Acc:99.96%
Training: Epoch[020/100] Iteration[300/381] Loss: 0.0012 Acc:99.96%
Training: Epoch[020/100] Iteration[310/381] Loss: 0.0006 Acc:99.96%
Training: Epoch[020/100] Iteration[320/381] Loss: 0.0033 Acc:99.95%
Training: Epoch[020/100] Iteration[330/381] Loss: 0.0003 Acc:99.95%
Training: Epoch[020/100] Iteration[340/381] Loss: 0.0331 Acc:99.94%
Training: Epoch[020/100] Iteration[350/381] Loss: 0.0033 Acc:99.94%
Training: Epoch[020/100] Iteration[360/381] Loss: 0.0049 Acc:99.93%
Training: Epoch[020/100] Iteration[370/381] Loss: 0.0038 Acc:99.93%
Training: Epoch[020/100] Iteration[380/381] Loss: 0.0018 Acc:99.93%
Training: Epoch[021/100] Iteration[010/381] Loss: 0.0005 Acc:100.00%
Training: Epoch[021/100] Iteration[020/381] Loss: 0.0008 Acc:100.00%
Training: Epoch[021/100] Iteration[030/381] Loss: 0.0016 Acc:100.00%
Training: Epoch[021/100] Iteration[040/381] Loss: 0.0040 Acc:99.92%
Training: Epoch[021/100] Iteration[050/381] Loss: 0.0009 Acc:99.94%
Training: Epoch[021/100] Iteration[060/381] Loss: 0.0079 Acc:99.90%
Training: Epoch[021/100] Iteration[070/381] Loss: 0.0118 Acc:99.82%
Training: Epoch[021/100] Iteration[080/381] Loss: 0.0035 Acc:99.84%
Training: Epoch[021/100] Iteration[090/381] Loss: 0.0142 Acc:99.83%
Training: Epoch[021/100] Iteration[100/381] Loss: 0.0041 Acc:99.84%
Training: Epoch[021/100] Iteration[110/381] Loss: 0.0048 Acc:99.83%
Training: Epoch[021/100] Iteration[120/381] Loss: 0.0005 Acc:99.84%
Training: Epoch[021/100] Iteration[130/381] Loss: 0.0024 Acc:99.86%
Training: Epoch[021/100] Iteration[140/381] Loss: 0.0656 Acc:99.84%
Training: Epoch[021/100] Iteration[150/381] Loss: 0.0095 Acc:99.83%
Training: Epoch[021/100] Iteration[160/381] Loss: 0.0041 Acc:99.84%
Training: Epoch[021/100] Iteration[170/381] Loss: 0.0125 Acc:99.83%
Training: Epoch[021/100] Iteration[180/381] Loss: 0.0150 Acc:99.83%
Training: Epoch[021/100] Iteration[190/381] Loss: 0.0012 Acc:99.84%
Training: Epoch[021/100] Iteration[200/381] Loss: 0.0039 Acc:99.84%
Training: Epoch[021/100] Iteration[210/381] Loss: 0.0068 Acc:99.84%
Training: Epoch[021/100] Iteration[220/381] Loss: 0.0148 Acc:99.83%
Training: Epoch[021/100] Iteration[230/381] Loss: 0.0030 Acc:99.84%
Training: Epoch[021/100] Iteration[240/381] Loss: 0.0082 Acc:99.83%
Training: Epoch[021/100] Iteration[250/381] Loss: 0.0132 Acc:99.83%
Training: Epoch[021/100] Iteration[260/381] Loss: 0.0068 Acc:99.82%
Training: Epoch[021/100] Iteration[270/381] Loss: 0.0727 Acc:99.80%
Training: Epoch[021/100] Iteration[280/381] Loss: 0.0066 Acc:99.80%
Training: Epoch[021/100] Iteration[290/381] Loss: 0.0083 Acc:99.80%
Training: Epoch[021/100] Iteration[300/381] Loss: 0.0079 Acc:99.79%
Training: Epoch[021/100] Iteration[310/381] Loss: 0.0034 Acc:99.80%
Training: Epoch[021/100] Iteration[320/381] Loss: 0.0027 Acc:99.80%
Training: Epoch[021/100] Iteration[330/381] Loss: 0.0018 Acc:99.81%
Training: Epoch[021/100] Iteration[340/381] Loss: 0.0032 Acc:99.82%
Training: Epoch[021/100] Iteration[350/381] Loss: 0.0011 Acc:99.82%
Training: Epoch[021/100] Iteration[360/381] Loss: 0.0011 Acc:99.83%
Training: Epoch[021/100] Iteration[370/381] Loss: 0.0010 Acc:99.83%
Training: Epoch[021/100] Iteration[380/381] Loss: 0.0123 Acc:99.83%
Valid set Accuracy:90.81%
Training: Epoch[022/100] Iteration[010/381] Loss: 0.0011 Acc:100.00%
Training: Epoch[022/100] Iteration[020/381] Loss: 0.0014 Acc:100.00%
Training: Epoch[022/100] Iteration[030/381] Loss: 0.0053 Acc:99.90%
Training: Epoch[022/100] Iteration[040/381] Loss: 0.0114 Acc:99.84%
Training: Epoch[022/100] Iteration[050/381] Loss: 0.0361 Acc:99.81%
Training: Epoch[022/100] Iteration[060/381] Loss: 0.0018 Acc:99.84%
Training: Epoch[022/100] Iteration[070/381] Loss: 0.0749 Acc:99.78%
Training: Epoch[022/100] Iteration[080/381] Loss: 0.0112 Acc:99.77%
Training: Epoch[022/100] Iteration[090/381] Loss: 0.0052 Acc:99.79%
Training: Epoch[022/100] Iteration[100/381] Loss: 0.0090 Acc:99.78%
Training: Epoch[022/100] Iteration[110/381] Loss: 0.0095 Acc:99.74%
Training: Epoch[022/100] Iteration[120/381] Loss: 0.0089 Acc:99.74%
Training: Epoch[022/100] Iteration[130/381] Loss: 0.0078 Acc:99.76%
Training: Epoch[022/100] Iteration[140/381] Loss: 0.0047 Acc:99.78%
Training: Epoch[022/100] Iteration[150/381] Loss: 0.0022 Acc:99.79%
Training: Epoch[022/100] Iteration[160/381] Loss: 0.0041 Acc:99.79%
Training: Epoch[022/100] Iteration[170/381] Loss: 0.0134 Acc:99.76%
Training: Epoch[022/100] Iteration[180/381] Loss: 0.0009 Acc:99.77%
Training: Epoch[022/100] Iteration[190/381] Loss: 0.0081 Acc:99.77%
Training: Epoch[022/100] Iteration[200/381] Loss: 0.0021 Acc:99.78%
Training: Epoch[022/100] Iteration[210/381] Loss: 0.0023 Acc:99.79%
Training: Epoch[022/100] Iteration[220/381] Loss: 0.0008 Acc:99.80%
Training: Epoch[022/100] Iteration[230/381] Loss: 0.0018 Acc:99.81%
Training: Epoch[022/100] Iteration[240/381] Loss: 0.0011 Acc:99.82%
Training: Epoch[022/100] Iteration[250/381] Loss: 0.0009 Acc:99.83%
Training: Epoch[022/100] Iteration[260/381] Loss: 0.0145 Acc:99.81%
Training: Epoch[022/100] Iteration[270/381] Loss: 0.0196 Acc:99.79%
Training: Epoch[022/100] Iteration[280/381] Loss: 0.0137 Acc:99.78%
Training: Epoch[022/100] Iteration[290/381] Loss: 0.0017 Acc:99.78%
Training: Epoch[022/100] Iteration[300/381] Loss: 0.0157 Acc:99.77%
Training: Epoch[022/100] Iteration[310/381] Loss: 0.0017 Acc:99.78%
Training: Epoch[022/100] Iteration[320/381] Loss: 0.0145 Acc:99.77%
Training: Epoch[022/100] Iteration[330/381] Loss: 0.0093 Acc:99.76%
Training: Epoch[022/100] Iteration[340/381] Loss: 0.0272 Acc:99.76%
Training: Epoch[022/100] Iteration[350/381] Loss: 0.0031 Acc:99.77%
Training: Epoch[022/100] Iteration[360/381] Loss: 0.0061 Acc:99.77%
Training: Epoch[022/100] Iteration[370/381] Loss: 0.0045 Acc:99.77%
Training: Epoch[022/100] Iteration[380/381] Loss: 0.0043 Acc:99.78%
Training: Epoch[023/100] Iteration[010/381] Loss: 0.0007 Acc:100.00%
Training: Epoch[023/100] Iteration[020/381] Loss: 0.0006 Acc:100.00%
Training: Epoch[023/100] Iteration[030/381] Loss: 0.0018 Acc:100.00%
Training: Epoch[023/100] Iteration[040/381] Loss: 0.0019 Acc:100.00%
Training: Epoch[023/100] Iteration[050/381] Loss: 0.0004 Acc:100.00%
Training: Epoch[023/100] Iteration[060/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[023/100] Iteration[070/381] Loss: 0.0027 Acc:100.00%
Training: Epoch[023/100] Iteration[080/381] Loss: 0.0003 Acc:100.00%
Training: Epoch[023/100] Iteration[090/381] Loss: 0.0194 Acc:99.97%
Training: Epoch[023/100] Iteration[100/381] Loss: 0.0021 Acc:99.97%
Training: Epoch[023/100] Iteration[110/381] Loss: 0.0091 Acc:99.91%
Training: Epoch[023/100] Iteration[120/381] Loss: 0.0009 Acc:99.92%
Training: Epoch[023/100] Iteration[130/381] Loss: 0.0009 Acc:99.93%
Training: Epoch[023/100] Iteration[140/381] Loss: 0.0043 Acc:99.93%
Training: Epoch[023/100] Iteration[150/381] Loss: 0.0007 Acc:99.94%
Training: Epoch[023/100] Iteration[160/381] Loss: 0.0006 Acc:99.94%
Training: Epoch[023/100] Iteration[170/381] Loss: 0.0005 Acc:99.94%
Training: Epoch[023/100] Iteration[180/381] Loss: 0.0008 Acc:99.95%
Training: Epoch[023/100] Iteration[190/381] Loss: 0.0056 Acc:99.93%
Training: Epoch[023/100] Iteration[200/381] Loss: 0.0037 Acc:99.94%
Training: Epoch[023/100] Iteration[210/381] Loss: 0.0011 Acc:99.94%
Training: Epoch[023/100] Iteration[220/381] Loss: 0.0070 Acc:99.93%
Training: Epoch[023/100] Iteration[230/381] Loss: 0.0005 Acc:99.93%
Training: Epoch[023/100] Iteration[240/381] Loss: 0.0090 Acc:99.91%
Training: Epoch[023/100] Iteration[250/381] Loss: 0.0157 Acc:99.89%
Training: Epoch[023/100] Iteration[260/381] Loss: 0.0053 Acc:99.88%
Training: Epoch[023/100] Iteration[270/381] Loss: 0.0044 Acc:99.87%
Training: Epoch[023/100] Iteration[280/381] Loss: 0.0141 Acc:99.85%
Training: Epoch[023/100] Iteration[290/381] Loss: 0.0117 Acc:99.85%
Training: Epoch[023/100] Iteration[300/381] Loss: 0.0017 Acc:99.85%
Training: Epoch[023/100] Iteration[310/381] Loss: 0.0027 Acc:99.86%
Training: Epoch[023/100] Iteration[320/381] Loss: 0.0006 Acc:99.86%
Training: Epoch[023/100] Iteration[330/381] Loss: 0.0022 Acc:99.87%
Training: Epoch[023/100] Iteration[340/381] Loss: 0.0038 Acc:99.86%
Training: Epoch[023/100] Iteration[350/381] Loss: 0.0010 Acc:99.87%
Training: Epoch[023/100] Iteration[360/381] Loss: 0.0091 Acc:99.86%
Training: Epoch[023/100] Iteration[370/381] Loss: 0.0026 Acc:99.86%
Training: Epoch[023/100] Iteration[380/381] Loss: 0.0187 Acc:99.85%
Valid set Accuracy:90.28%
Training: Epoch[024/100] Iteration[010/381] Loss: 0.0023 Acc:100.00%
Training: Epoch[024/100] Iteration[020/381] Loss: 0.0263 Acc:99.84%
Training: Epoch[024/100] Iteration[030/381] Loss: 0.0009 Acc:99.90%
Training: Epoch[024/100] Iteration[040/381] Loss: 0.0043 Acc:99.92%
Training: Epoch[024/100] Iteration[050/381] Loss: 0.0065 Acc:99.88%
Training: Epoch[024/100] Iteration[060/381] Loss: 0.0012 Acc:99.90%
Training: Epoch[024/100] Iteration[070/381] Loss: 0.0010 Acc:99.91%
Training: Epoch[024/100] Iteration[080/381] Loss: 0.0006 Acc:99.92%
Training: Epoch[024/100] Iteration[090/381] Loss: 0.0037 Acc:99.93%
Training: Epoch[024/100] Iteration[100/381] Loss: 0.0006 Acc:99.94%
Training: Epoch[024/100] Iteration[110/381] Loss: 0.0002 Acc:99.94%
Training: Epoch[024/100] Iteration[120/381] Loss: 0.0004 Acc:99.95%
Training: Epoch[024/100] Iteration[130/381] Loss: 0.0031 Acc:99.95%
Training: Epoch[024/100] Iteration[140/381] Loss: 0.0005 Acc:99.96%
Training: Epoch[024/100] Iteration[150/381] Loss: 0.0008 Acc:99.96%
Training: Epoch[024/100] Iteration[160/381] Loss: 0.0008 Acc:99.96%
Training: Epoch[024/100] Iteration[170/381] Loss: 0.0003 Acc:99.96%
Training: Epoch[024/100] Iteration[180/381] Loss: 0.0002 Acc:99.97%
Training: Epoch[024/100] Iteration[190/381] Loss: 0.0015 Acc:99.97%
Training: Epoch[024/100] Iteration[200/381] Loss: 0.0005 Acc:99.97%
Training: Epoch[024/100] Iteration[210/381] Loss: 0.0005 Acc:99.97%
Training: Epoch[024/100] Iteration[220/381] Loss: 0.0007 Acc:99.97%
Training: Epoch[024/100] Iteration[230/381] Loss: 0.0006 Acc:99.97%
Training: Epoch[024/100] Iteration[240/381] Loss: 0.0005 Acc:99.97%
Training: Epoch[024/100] Iteration[250/381] Loss: 0.0005 Acc:99.98%
Training: Epoch[024/100] Iteration[260/381] Loss: 0.0006 Acc:99.98%
Training: Epoch[024/100] Iteration[270/381] Loss: 0.0005 Acc:99.98%
Training: Epoch[024/100] Iteration[280/381] Loss: 0.0010 Acc:99.98%
Training: Epoch[024/100] Iteration[290/381] Loss: 0.0001 Acc:99.98%
Training: Epoch[024/100] Iteration[300/381] Loss: 0.0004 Acc:99.98%
Training: Epoch[024/100] Iteration[310/381] Loss: 0.0003 Acc:99.98%
Training: Epoch[024/100] Iteration[320/381] Loss: 0.0003 Acc:99.98%
Training: Epoch[024/100] Iteration[330/381] Loss: 0.0016 Acc:99.98%
Training: Epoch[024/100] Iteration[340/381] Loss: 0.0002 Acc:99.98%
Training: Epoch[024/100] Iteration[350/381] Loss: 0.0004 Acc:99.98%
Training: Epoch[024/100] Iteration[360/381] Loss: 0.0003 Acc:99.98%
Training: Epoch[024/100] Iteration[370/381] Loss: 0.0002 Acc:99.98%
Training: Epoch[024/100] Iteration[380/381] Loss: 0.0001 Acc:99.98%
Training: Epoch[025/100] Iteration[010/381] Loss: 0.0008 Acc:100.00%
Training: Epoch[025/100] Iteration[020/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[025/100] Iteration[030/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[025/100] Iteration[040/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[025/100] Iteration[050/381] Loss: 0.0003 Acc:100.00%
Training: Epoch[025/100] Iteration[060/381] Loss: 0.0254 Acc:99.95%
Training: Epoch[025/100] Iteration[070/381] Loss: 0.0021 Acc:99.96%
Training: Epoch[025/100] Iteration[080/381] Loss: 0.0574 Acc:99.92%
Training: Epoch[025/100] Iteration[090/381] Loss: 0.0014 Acc:99.93%
Training: Epoch[025/100] Iteration[100/381] Loss: 0.0008 Acc:99.94%
Training: Epoch[025/100] Iteration[110/381] Loss: 0.0009 Acc:99.94%
Training: Epoch[025/100] Iteration[120/381] Loss: 0.0006 Acc:99.95%
Training: Epoch[025/100] Iteration[130/381] Loss: 0.0006 Acc:99.95%
Training: Epoch[025/100] Iteration[140/381] Loss: 0.0029 Acc:99.93%
Training: Epoch[025/100] Iteration[150/381] Loss: 0.0011 Acc:99.94%
Training: Epoch[025/100] Iteration[160/381] Loss: 0.0014 Acc:99.94%
Training: Epoch[025/100] Iteration[170/381] Loss: 0.0003 Acc:99.94%
Training: Epoch[025/100] Iteration[180/381] Loss: 0.0006 Acc:99.95%
Training: Epoch[025/100] Iteration[190/381] Loss: 0.0005 Acc:99.95%
Training: Epoch[025/100] Iteration[200/381] Loss: 0.0027 Acc:99.95%
Training: Epoch[025/100] Iteration[210/381] Loss: 0.0002 Acc:99.96%
Training: Epoch[025/100] Iteration[220/381] Loss: 0.0007 Acc:99.96%
Training: Epoch[025/100] Iteration[230/381] Loss: 0.0003 Acc:99.96%
Training: Epoch[025/100] Iteration[240/381] Loss: 0.0012 Acc:99.96%
Training: Epoch[025/100] Iteration[250/381] Loss: 0.0002 Acc:99.96%
Training: Epoch[025/100] Iteration[260/381] Loss: 0.0002 Acc:99.96%
Training: Epoch[025/100] Iteration[270/381] Loss: 0.0003 Acc:99.97%
Training: Epoch[025/100] Iteration[280/381] Loss: 0.0010 Acc:99.97%
Training: Epoch[025/100] Iteration[290/381] Loss: 0.0001 Acc:99.97%
Training: Epoch[025/100] Iteration[300/381] Loss: 0.0002 Acc:99.97%
Training: Epoch[025/100] Iteration[310/381] Loss: 0.0006 Acc:99.97%
Training: Epoch[025/100] Iteration[320/381] Loss: 0.0003 Acc:99.97%
Training: Epoch[025/100] Iteration[330/381] Loss: 0.0002 Acc:99.97%
Training: Epoch[025/100] Iteration[340/381] Loss: 0.0007 Acc:99.97%
Training: Epoch[025/100] Iteration[350/381] Loss: 0.0021 Acc:99.97%
Training: Epoch[025/100] Iteration[360/381] Loss: 0.0001 Acc:99.97%
Training: Epoch[025/100] Iteration[370/381] Loss: 0.0002 Acc:99.97%
Training: Epoch[025/100] Iteration[380/381] Loss: 0.0001 Acc:99.98%
Valid set Accuracy:91.34%
Training: Epoch[026/100] Iteration[010/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[026/100] Iteration[020/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[026/100] Iteration[030/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[026/100] Iteration[040/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[026/100] Iteration[050/381] Loss: 0.0411 Acc:99.94%
Training: Epoch[026/100] Iteration[060/381] Loss: 0.0009 Acc:99.95%
Training: Epoch[026/100] Iteration[070/381] Loss: 0.0006 Acc:99.96%
Training: Epoch[026/100] Iteration[080/381] Loss: 0.0006 Acc:99.96%
Training: Epoch[026/100] Iteration[090/381] Loss: 0.0194 Acc:99.93%
Training: Epoch[026/100] Iteration[100/381] Loss: 0.0004 Acc:99.94%
Training: Epoch[026/100] Iteration[110/381] Loss: 0.0004 Acc:99.94%
Training: Epoch[026/100] Iteration[120/381] Loss: 0.0009 Acc:99.95%
Training: Epoch[026/100] Iteration[130/381] Loss: 0.0002 Acc:99.95%
Training: Epoch[026/100] Iteration[140/381] Loss: 0.0005 Acc:99.96%
Training: Epoch[026/100] Iteration[150/381] Loss: 0.0006 Acc:99.96%
Training: Epoch[026/100] Iteration[160/381] Loss: 0.0001 Acc:99.96%
Training: Epoch[026/100] Iteration[170/381] Loss: 0.0006 Acc:99.96%
Training: Epoch[026/100] Iteration[180/381] Loss: 0.0004 Acc:99.97%
Training: Epoch[026/100] Iteration[190/381] Loss: 0.0003 Acc:99.97%
Training: Epoch[026/100] Iteration[200/381] Loss: 0.0003 Acc:99.97%
Training: Epoch[026/100] Iteration[210/381] Loss: 0.0003 Acc:99.97%
Training: Epoch[026/100] Iteration[220/381] Loss: 0.0002 Acc:99.97%
Training: Epoch[026/100] Iteration[230/381] Loss: 0.0004 Acc:99.97%
Training: Epoch[026/100] Iteration[240/381] Loss: 0.0001 Acc:99.97%
Training: Epoch[026/100] Iteration[250/381] Loss: 0.0002 Acc:99.98%
Training: Epoch[026/100] Iteration[260/381] Loss: 0.0453 Acc:99.96%
Training: Epoch[026/100] Iteration[270/381] Loss: 0.0003 Acc:99.97%
Training: Epoch[026/100] Iteration[280/381] Loss: 0.0003 Acc:99.97%
Training: Epoch[026/100] Iteration[290/381] Loss: 0.0005 Acc:99.97%
Training: Epoch[026/100] Iteration[300/381] Loss: 0.0011 Acc:99.97%
Training: Epoch[026/100] Iteration[310/381] Loss: 0.0393 Acc:99.96%
Training: Epoch[026/100] Iteration[320/381] Loss: 0.0007 Acc:99.96%
Training: Epoch[026/100] Iteration[330/381] Loss: 0.0008 Acc:99.96%
Training: Epoch[026/100] Iteration[340/381] Loss: 0.0009 Acc:99.96%
Training: Epoch[026/100] Iteration[350/381] Loss: 0.0006 Acc:99.96%
Training: Epoch[026/100] Iteration[360/381] Loss: 0.0004 Acc:99.97%
Training: Epoch[026/100] Iteration[370/381] Loss: 0.0004 Acc:99.97%
Training: Epoch[026/100] Iteration[380/381] Loss: 0.0003 Acc:99.97%
Training: Epoch[027/100] Iteration[010/381] Loss: 0.0005 Acc:100.00%
Training: Epoch[027/100] Iteration[020/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[027/100] Iteration[030/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[027/100] Iteration[040/381] Loss: 0.0006 Acc:100.00%
Training: Epoch[027/100] Iteration[050/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[027/100] Iteration[060/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[027/100] Iteration[070/381] Loss: 0.0006 Acc:100.00%
Training: Epoch[027/100] Iteration[080/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[027/100] Iteration[090/381] Loss: 0.0003 Acc:100.00%
Training: Epoch[027/100] Iteration[100/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[027/100] Iteration[110/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[027/100] Iteration[120/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[027/100] Iteration[130/381] Loss: 0.0003 Acc:100.00%
Training: Epoch[027/100] Iteration[140/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[027/100] Iteration[150/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[027/100] Iteration[160/381] Loss: 0.0003 Acc:100.00%
Training: Epoch[027/100] Iteration[170/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[027/100] Iteration[180/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[027/100] Iteration[190/381] Loss: 0.0003 Acc:100.00%
Training: Epoch[027/100] Iteration[200/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[027/100] Iteration[210/381] Loss: 0.0003 Acc:100.00%
Training: Epoch[027/100] Iteration[220/381] Loss: 0.0003 Acc:100.00%
Training: Epoch[027/100] Iteration[230/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[027/100] Iteration[240/381] Loss: 0.0005 Acc:100.00%
Training: Epoch[027/100] Iteration[250/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[027/100] Iteration[260/381] Loss: 0.0003 Acc:100.00%
Training: Epoch[027/100] Iteration[270/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[027/100] Iteration[280/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[027/100] Iteration[290/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[027/100] Iteration[300/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[027/100] Iteration[310/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[027/100] Iteration[320/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[027/100] Iteration[330/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[027/100] Iteration[340/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[027/100] Iteration[350/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[027/100] Iteration[360/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[027/100] Iteration[370/381] Loss: 0.0003 Acc:100.00%
Training: Epoch[027/100] Iteration[380/381] Loss: 0.0001 Acc:100.00%
Valid set Accuracy:91.88%
Training: Epoch[028/100] Iteration[010/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/100] Iteration[020/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/100] Iteration[030/381] Loss: 0.0003 Acc:100.00%
Training: Epoch[028/100] Iteration[040/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[028/100] Iteration[050/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[028/100] Iteration[060/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/100] Iteration[070/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/100] Iteration[080/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[028/100] Iteration[090/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/100] Iteration[100/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[028/100] Iteration[110/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/100] Iteration[120/381] Loss: 0.0008 Acc:100.00%
Training: Epoch[028/100] Iteration[130/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[028/100] Iteration[140/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/100] Iteration[150/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[028/100] Iteration[160/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[028/100] Iteration[170/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/100] Iteration[180/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/100] Iteration[190/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/100] Iteration[200/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/100] Iteration[210/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[028/100] Iteration[220/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[028/100] Iteration[230/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/100] Iteration[240/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/100] Iteration[250/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/100] Iteration[260/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[028/100] Iteration[270/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/100] Iteration[280/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/100] Iteration[290/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[028/100] Iteration[300/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[028/100] Iteration[310/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/100] Iteration[320/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/100] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[028/100] Iteration[340/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/100] Iteration[350/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/100] Iteration[360/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/100] Iteration[370/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[028/100] Iteration[380/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/100] Iteration[010/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/100] Iteration[020/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/100] Iteration[030/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[029/100] Iteration[040/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/100] Iteration[050/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/100] Iteration[060/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/100] Iteration[070/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[029/100] Iteration[080/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[029/100] Iteration[090/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/100] Iteration[100/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/100] Iteration[110/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[029/100] Iteration[120/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[029/100] Iteration[130/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/100] Iteration[140/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/100] Iteration[150/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/100] Iteration[160/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[029/100] Iteration[170/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[029/100] Iteration[180/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[029/100] Iteration[190/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/100] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[029/100] Iteration[210/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[029/100] Iteration[220/381] Loss: 0.0004 Acc:100.00%
Training: Epoch[029/100] Iteration[230/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/100] Iteration[240/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/100] Iteration[250/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[029/100] Iteration[260/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/100] Iteration[270/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/100] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[029/100] Iteration[290/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/100] Iteration[300/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/100] Iteration[310/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[029/100] Iteration[320/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/100] Iteration[330/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/100] Iteration[340/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/100] Iteration[350/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[029/100] Iteration[360/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[029/100] Iteration[370/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[029/100] Iteration[380/381] Loss: 0.0000 Acc:100.00%
Valid set Accuracy:92.01%
Training: Epoch[030/100] Iteration[010/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/100] Iteration[020/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/100] Iteration[030/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/100] Iteration[040/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/100] Iteration[050/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/100] Iteration[060/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/100] Iteration[070/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/100] Iteration[080/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/100] Iteration[090/381] Loss: 0.0003 Acc:100.00%
Training: Epoch[030/100] Iteration[100/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/100] Iteration[110/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/100] Iteration[120/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/100] Iteration[130/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/100] Iteration[140/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/100] Iteration[150/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/100] Iteration[160/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/100] Iteration[170/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/100] Iteration[180/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/100] Iteration[190/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/100] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/100] Iteration[210/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/100] Iteration[220/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/100] Iteration[230/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/100] Iteration[240/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/100] Iteration[250/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/100] Iteration[260/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/100] Iteration[270/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/100] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/100] Iteration[290/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/100] Iteration[300/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/100] Iteration[310/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/100] Iteration[320/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/100] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/100] Iteration[340/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/100] Iteration[350/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/100] Iteration[360/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[030/100] Iteration[370/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[030/100] Iteration[380/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/100] Iteration[010/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/100] Iteration[020/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/100] Iteration[030/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/100] Iteration[040/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/100] Iteration[050/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/100] Iteration[060/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/100] Iteration[070/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/100] Iteration[080/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/100] Iteration[090/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/100] Iteration[100/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/100] Iteration[110/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/100] Iteration[120/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/100] Iteration[130/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/100] Iteration[140/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/100] Iteration[150/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/100] Iteration[160/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/100] Iteration[170/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/100] Iteration[180/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/100] Iteration[190/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/100] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/100] Iteration[210/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/100] Iteration[220/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/100] Iteration[230/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/100] Iteration[240/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/100] Iteration[250/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/100] Iteration[260/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/100] Iteration[270/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/100] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/100] Iteration[290/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/100] Iteration[300/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/100] Iteration[310/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/100] Iteration[320/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/100] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/100] Iteration[340/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/100] Iteration[350/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/100] Iteration[360/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[031/100] Iteration[370/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[031/100] Iteration[380/381] Loss: 0.0000 Acc:100.00%
Valid set Accuracy:92.28%
Training: Epoch[032/100] Iteration[010/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[020/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[030/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[040/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[050/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[032/100] Iteration[060/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[032/100] Iteration[070/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[080/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[090/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[100/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[110/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[120/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[130/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[140/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[150/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[032/100] Iteration[160/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[032/100] Iteration[170/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[180/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[190/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[210/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[032/100] Iteration[220/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[230/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[240/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[250/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[260/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[270/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[032/100] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[290/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[300/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[310/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[320/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[340/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[350/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[360/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[032/100] Iteration[370/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[032/100] Iteration[380/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[010/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[020/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[030/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[040/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[033/100] Iteration[050/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[060/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[070/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[033/100] Iteration[080/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[090/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[100/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[110/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[120/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[130/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[140/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[150/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[160/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[170/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[033/100] Iteration[180/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[190/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[033/100] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[210/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[220/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[230/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[240/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[250/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[260/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[033/100] Iteration[270/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[290/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[300/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[310/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[320/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[340/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[350/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[360/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[033/100] Iteration[370/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[033/100] Iteration[380/381] Loss: 0.0000 Acc:100.00%
Valid set Accuracy:92.41%
Training: Epoch[034/100] Iteration[010/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[020/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[030/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[040/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[034/100] Iteration[050/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[060/381] Loss: 0.0002 Acc:100.00%
Training: Epoch[034/100] Iteration[070/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[080/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[090/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[100/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[034/100] Iteration[110/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[120/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[130/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[140/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[150/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[160/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[170/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[180/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[190/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[210/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[220/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[230/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[240/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[250/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[034/100] Iteration[260/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[034/100] Iteration[270/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[034/100] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[290/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[300/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[034/100] Iteration[310/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[320/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[340/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[350/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[360/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[370/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[034/100] Iteration[380/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[010/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[020/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[030/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[040/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[050/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[035/100] Iteration[060/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[035/100] Iteration[070/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[080/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[090/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[100/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[110/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[120/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[130/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[140/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[150/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[160/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[170/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[180/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[190/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[035/100] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[210/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[220/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[230/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[035/100] Iteration[240/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[250/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[260/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[270/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[290/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[300/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[310/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[320/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[035/100] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[340/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[350/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[360/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[370/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[035/100] Iteration[380/381] Loss: 0.0000 Acc:100.00%
Valid set Accuracy:92.28%
Training: Epoch[036/100] Iteration[010/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[020/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[030/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[040/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[050/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[060/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[070/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[080/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[090/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[100/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[110/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[120/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[130/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[140/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[150/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[160/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[170/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[180/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[190/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[210/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[220/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[230/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[240/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[036/100] Iteration[250/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[260/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[270/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[290/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[300/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[310/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[320/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[340/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[350/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[036/100] Iteration[360/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[370/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[036/100] Iteration[380/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[010/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[020/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[030/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[040/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[050/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[060/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[070/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[037/100] Iteration[080/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[090/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[100/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[110/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[120/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[130/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[037/100] Iteration[140/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[150/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[160/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[170/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[180/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[190/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[210/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[220/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[230/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[240/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[250/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[260/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[270/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[290/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[300/381] Loss: 0.0005 Acc:100.00%
Training: Epoch[037/100] Iteration[310/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[320/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[340/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[350/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[360/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[370/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[037/100] Iteration[380/381] Loss: 0.0000 Acc:100.00%
Valid set Accuracy:92.41%
Training: Epoch[038/100] Iteration[010/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[020/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[030/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[040/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[038/100] Iteration[050/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[060/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[070/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[080/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[090/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[100/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[110/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[120/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[130/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[140/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[150/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[160/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[170/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[180/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[190/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[210/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[220/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[038/100] Iteration[230/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[240/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[038/100] Iteration[250/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[260/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[270/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[290/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[038/100] Iteration[300/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[310/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[038/100] Iteration[320/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[340/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[350/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[360/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[370/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[038/100] Iteration[380/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[010/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[020/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[030/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[040/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[050/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[060/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[070/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[080/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[090/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[100/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[110/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[120/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[130/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[140/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[150/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[160/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[170/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[180/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[190/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[210/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[220/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[230/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[240/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[250/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[260/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[270/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[290/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[300/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[310/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[320/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[340/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[350/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[360/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[370/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[039/100] Iteration[380/381] Loss: 0.0000 Acc:100.00%
Valid set Accuracy:92.28%
Training: Epoch[040/100] Iteration[010/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[020/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[030/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[040/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[050/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[060/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[070/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[080/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[090/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[040/100] Iteration[100/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[110/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[120/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[130/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[140/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[150/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[160/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[170/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[180/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[190/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[210/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[220/381] Loss: 0.0004 Acc:100.00%
Training: Epoch[040/100] Iteration[230/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[240/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[250/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[260/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[270/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[290/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[300/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[310/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[320/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[340/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[350/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[360/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[370/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[040/100] Iteration[380/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[010/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[020/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[030/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[040/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[050/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[060/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[070/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[080/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[090/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[100/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[041/100] Iteration[110/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[120/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[130/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[140/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[150/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[160/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[170/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[180/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[190/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[210/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[220/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[230/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[240/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[250/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[260/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[270/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[290/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[300/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[310/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[320/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[340/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[350/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[360/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[370/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[041/100] Iteration[380/381] Loss: 0.0000 Acc:100.00%
Valid set Accuracy:92.14%
Training: Epoch[042/100] Iteration[010/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[020/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[030/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[040/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[050/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[060/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[070/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[080/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[090/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[100/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[110/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[120/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[130/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[140/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[150/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[160/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[170/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[180/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[190/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[200/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[210/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[220/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[230/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[240/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[250/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[260/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[270/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[280/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[290/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[300/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[310/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[320/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[330/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[340/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[350/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[360/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[370/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[042/100] Iteration[380/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[043/100] Iteration[010/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[043/100] Iteration[020/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[043/100] Iteration[030/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[043/100] Iteration[040/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[043/100] Iteration[050/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[043/100] Iteration[060/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[043/100] Iteration[070/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[043/100] Iteration[080/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[043/100] Iteration[090/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[043/100] Iteration[100/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[043/100] Iteration[110/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[043/100] Iteration[120/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[043/100] Iteration[130/381] Loss: 0.0001 Acc:100.00%
Training: Epoch[043/100] Iteration[140/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[043/100] Iteration[150/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[043/100] Iteration[160/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[043/100] Iteration[170/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[043/100] Iteration[180/381] Loss: 0.0000 Acc:100.00%
Training: Epoch[043/100] Iteration[190/381] Loss: 0.0000 Acc:100.00%
